<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>实时渲染中的反走样：TAA</title>
    <link href="/2022/06/11/TAA.html"/>
    <url>/2022/06/11/TAA.html</url>
    
    <content type="html"><![CDATA[<p>和之前讨论的反走样方法一样，TAA也属于空域反走样，但不同之处在于，TAA把时间维度考虑进来了，它在收集了多帧历史数据的基础上进行空域反走样。TAA不需要超采样的深度和颜色缓冲，作为后处理技术也适用于延迟渲染，TAA的另外一个显著特点是，它能处理着色走样问题，因为它有真正的子样本信息（来自多帧收集的历史数据），因此可能是目前实用反走样技术中效果最好的一种。</p><p>由于其出色的效果，TAA在过去十年得到了大规模的应用，几乎成为所有3A游戏的标配，使得<code>Temporal Antialiasing</code>从一个原本描述时域反走样（车轮效应）的术语，变得越来越成为基于时域样本进行空域反走样的专有名词。</p><h1 id="history">History</h1><p>如果说SSAA是在一帧中着色并采样子样本（或者亚像素-<code>sub-pixel</code>），那么TAA就是把子样本的着色和采样分摊到了多帧，每帧只着色一个子样本，然后和历史累积的子样本混合，得到近似SSAA的效果。</p><p><img src="/images/TAA/history.png" /></p><p>由于只有一张贴图保存前一帧的样本，因此混合公式不是平均混合，而是：<span class="math display">\[f_t(p)=\alpha \cdot s_t(p)+(1-\alpha) \cdot f_{t-1}(\pi (p))\]</span> <spanclass="math inline">\(f_t(p)\)</span>表示第t帧的像素颜色，<spanclass="math inline">\(\alpha\)</span>是混合因子，<spanclass="math inline">\(s_t(p)\)</span>是最新的着色样本，<spanclass="math inline">\(f_{t-1}(\pi(p))\)</span>是前一帧的历史样本，其中<spanclass="math inline">\(\pi\)</span>是重投影操作。在<spanclass="math inline">\(\alpha\)</span>固定的情况下，上式等价于一个指数平滑滤波器：<span class="math display">\[\begin{aligned}f_t(p)&amp;=\alpha \cdot(s_t(p)+(1-\alpha)s_{t-1}(p)+(1-\alpha)^2s_{t-2}(p)+\cdots)\\&amp;=\alpha \sum_{k=0}^{n-1}(1-\alpha)^ks_{t-k}(p)+(1-\alpha)^nf_{t-n}(p)\end{aligned}\]</span> 假设静态画面下每隔n帧采样点模式重复一次，于是<spanclass="math inline">\(s_t(p)=s_{t-n}(p)\)</span>，并且<spanclass="math inline">\(f_t(p)=f_{t-n}(p)\)</span>，上式可以变为： <spanclass="math display">\[\begin{aligned}f_t(p)&amp;=\alpha\sum_{k=0}^{n-1}(1-\alpha)^ks_{t-k}(p)+(1-\alpha)^nf_{t}(p)\\f_t(p)&amp;=\frac {\alpha}{1-(1-\alpha)^n}\sum_{k=0}^{n-1}(1-\alpha)^ks_{t-k}(p)\end{aligned}\]</span></p><p>若<span class="math inline">\(\alpha\)</span> 趋于0，则有： <spanclass="math display">\[\begin{aligned}\lim_{\alpha \to 0}f_t(p)&amp;=\lim_{\alpha \to 0}\frac {\alpha}{1-(1-\alpha)^n}\sum_{k=0}^{n-1}(1-\alpha)^ks_{t-k}(p) \\&amp;=\frac {1} {n}\sum_{k=0}^{n-1}s_{t-k}(p)\end{aligned}\]</span>也就是理论上这种方法得到的结果近似于平均取样，具体如下图所示，在<spanclass="math inline">\(\alpha\)</span>为0.1，采样周期为5时，结果近似于2.2个超采样，增大采样周期到10，结果近似于5.1个超采样。</p><p><img src="/images/TAA/appox_curve.png" /></p><h1 id="jittering">Jittering</h1><p>为了在每帧采样一个子样本，TAA在光照渲染的时候需要对像素做一个随机偏移，这些偏移后的像素就是（未抖动的）原像素的子样本。为了保证均匀散布，随机偏移一般使用<ahref="https://en.wikipedia.org/wiki/Low-discrepancy_sequence">低差异序列</a>生成而非完全随机，最常用的就是<ahref="https://en.wikipedia.org/wiki/Halton_sequence">Haltonsequence</a>，采用2和3作为XY偏移序列的生成基数，前8个子样本点的模式如下。</p><p><img src="/images/TAA/samples.png" /></p><p>抖动本质上是给相机视锥体的远平面的四个顶点加上一个偏移。</p><p><img src="/images/TAA/jitter.png" /></p><p>这可以很方便地通过修改投影矩阵实现。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-type">uint64_t</span> idx = frame_count_ % kTAASampleCount;<br><span class="hljs-type">double</span> jitter_x = halton_sequence_[idx].x / ScreenPixelWidth;<br><span class="hljs-type">double</span> jitter_y = halton_sequence_[idx].y / ScreenPixelHeight;<br>projection[<span class="hljs-number">0</span>][<span class="hljs-number">2</span>] += jitter_x;<br>projection[<span class="hljs-number">1</span>][<span class="hljs-number">2</span>] += jitter_y;<br></code></pre></td></tr></table></figure></p><p>要理解这一点，我们从相机空间开始观察，我们知道投影矩阵在相机空间下的坐标变换是：<span class="math display">\[\left(\begin{array}{cccc}\frac {n} {r} &amp; 0 &amp; 0 &amp; 0 \\0 &amp; \frac {n} {t} &amp; 0 &amp; 0 \\0 &amp; 0 &amp; \frac {f+n} {f-n} &amp; -\frac {nf} {f-n} \\0 &amp; 0 &amp; 1 &amp; 0\end{array}\right)\left(\begin{array}{c}x \\y \\z \\1\end{array}\right)=\left(\begin{array}{c}\frac {n} {r} x \\\frac {n} {t} y \\\frac {(n+f)z-nf} {f-n} \\z\end{array}\right)\]</span> 则加入抖动后是： <span class="math display">\[\left(\begin{array}{cccc}\frac {n} {r} &amp; 0 &amp; {jitter\_x} &amp; 0 \\0 &amp; \frac {n} {t} &amp; {jitter\_y} &amp; 0 \\0 &amp; 0 &amp; \frac {f+n} {f-n} &amp; -\frac {nf} {f-n} \\0 &amp; 0 &amp; 1 &amp; 0\end{array}\right)\left(\begin{array}{c}x \\y \\z \\1\end{array}\right)=\left(\begin{array}{c}\frac {n} {r} x + {jitter\_x} \cdot z \\\frac {n} {t} y + {jitter\_y} \cdot z\\\frac {(n+f)z-nf} {f-n} \\z\end{array}\right)\]</span> 此时<span class="math inline">\(x\)</span>分量多了一个<spanclass="math inline">\(jitter\_x \cdotz\)</span>项，但是后续会进行透视除法，此项就变成了<spanclass="math inline">\(jitter\_x\)</span>，刚好就是像素偏移值（<spanclass="math inline">\(y\)</span>分量同此）。</p><h1 id="velocity-buffer">Velocity Buffer</h1><p>对于静态场景，可以利用深度反算世界坐标，再利用上一帧的投影矩阵重建采样点的位置计算当前像素在上一帧的uv，从而对历史贴图采样；而对于动态场景，我们必须借助<code>Velocity Buffer</code>才能知道当前像素对应的样本在上一帧的位置，延迟渲染管线可以很方便地在GBufferPass阶段生成<code>Velocity Buffer</code>，且很多后处理也会用到它。</p><h2 id="reprojection">Reprojection</h2><p><code>Velocity Buffer</code>存储的是同一物体同一像素在前后两帧的屏幕空间坐标的变化量，为此需要保存上一帧的投影矩阵和模型矩阵，如果是蒙皮动画的物体，还要考虑用骨骼数据计算蒙皮，但有些特殊的物体，比如粒子特效、半透明物体等无法写入<code>Velocity Buffer</code>，需要特殊处理（或者干脆不处理）。最后还要特别注意，这里使用的都是未抖动的投影矩阵。</p><p>有了<code>Velocity Buffer</code>，在TAA的后处理中我们就可以根据<code>Velocity Vector</code>得到当前像素在上一帧的uv坐标。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">float2 velocity = VelocityTexture.Sample(sampler, uv).xy;<br>float2 prev_uv = uv - velocity;<br></code></pre></td></tr></table></figure> <div class="note note-info">            <p>在采样之前是否要对当前像素的uv进行unjitter？<br />这取决于你在后处理使用的投影矩阵，如果是和光照渲染时的投影矩阵一样，要unjitter，而如果是用<ahref="https://www.nickiebba.com/single-post/2017/08/23/post-processing-the-triangle-trick">大三角形优化</a>的方式则不需要。</p>          </div></p><h2 id="dilation">Dilation</h2><p>这里还有一个问题是<code>Velocity buffer</code>也是有走样的，reproject得到的<code>prev_uv</code>可能会选取到其他物体的颜色，常见的是前景物体的边缘像素，可能有一些能取到对应的历史颜色，另外一些又取不到，从而造成锯齿的问题。解决方案是在周围3x3像素内获取离相机最近的点，这样前景物体总能获取到对应的历史样本，锯齿就消失了，代价是前景物体会稍稍膨胀一些。</p><p><img src="/images/TAA/dilation.png" /></p><h1 id="ghosting">Ghosting</h1><p>我们不能立即使用<code>prev_uv</code>采样的历史颜色，因为这里的速度是样本在前后两帧都可见的情况下的变化量，而样本有可能在这一帧可见，但在上一帧不可见（因为遮挡或者镜头移动），此时采样的历史颜色很可能是其他物体的，因而不具有参考价值，这被称为<code>history mismatch</code>。不加区分的接受历史颜色的结果，就会造成<code>Ghosting</code>。</p><p><img src="/images/TAA/ghosting.png" /></p><h2 id="color-clamping">Color clamping</h2><p>解决方案就是<code>history clamp/clip</code>，也就是根据当前像素周围的数据（比如3x3像素），评估历史颜色和它们的差异，如果差异过大，则判定历史颜色应该被舍弃。理想情况下，我们应该根据3x3像素颜色生成一个3D颜色空间的凸包，然后把历史颜色截断在凸包之内，但这么做开销太大。</p><p>实现一般用到2截断方法，最简单的做法是clamp，计算周围3x3像素颜色的最大值和最小值，这等价于在颜色空间构造一个AABB，然后直接把历史颜色截断到AABB端点处。<ahref="https://www.gdcvault.com/play/1022970/Temporal-Reprojection-Anti-Aliasing-in">clip</a>复杂一点，它能在当前颜色和历史颜色的连线和AABB相交的位置截断。两者区别如下图所示，clip效果更好一些。</p><p><img src="/images/TAA/clamp.png" /></p><p>上述两种做法下，其截断的位置都离理想凸包较远，有一种<ahref="https://developer.download.nvidia.cn/gameworks/events/GDC2016/msalvi_temporal_supersampling.pdf">改进方法</a>是使用方差来优化AABB的生成，使得AABB更贴近凸包，然后再clip。</p><p><img src="/images/TAA/varclip.png" /></p><p>另外一个对AABB的<ahref="https://de45xmedrsdbp.cloudfront.net/Resources/files/TemporalAA_small-59732822.pdf">改进</a>是，让AABB的方向平行于亮度增长的方向，因为在局部区域颜色的差异可能没有对比度高，为了做到这一点我们不再在RGB颜色空间下生成AABB，而是变换到YCoCg颜色空间（YCoCg的其中一个维度就是亮度）生成AABB。</p><p><img src="/images/TAA/ycocg.png" /></p><p>结合以上做法的采样历史帧的实现代码如下： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs cpp">float3 color_min = <span class="hljs-number">10000</span>;<br>float3 color_max = <span class="hljs-number">-10000</span>;<br>float3 m1 = <span class="hljs-built_in">float3</span>(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>);<br>float3 m2 = <span class="hljs-built_in">float3</span>(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>);<br><br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> x = <span class="hljs-number">-1</span>; x &lt;= <span class="hljs-number">1</span>; x++) &#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> y = <span class="hljs-number">-1</span>; y &lt;= <span class="hljs-number">1</span>; y++) &#123;<br>        float2 neighbor_uv = uv + <span class="hljs-built_in">float2</span>(x, y) * _TexelSzie;<br>        float3 C = <span class="hljs-built_in">RGBToYCoCg</span>(_PostSourceTexture.<span class="hljs-built_in">Sample</span>(sample, neighbor_uv));<br>        neighbor_color = <span class="hljs-built_in">RGB2YCoCgR</span>(neighbor_color);<br>        color_min = <span class="hljs-built_in">min</span>(color_min, neighbor_color);<br>        color_max = <span class="hljs-built_in">max</span>(color_min, neighbor_color);<br><br>        m1 += neighbor_color;<br>        m2 += neighbor_color * neighbor_color;<br>    &#125;<br>&#125;<br><br>prev_color = <span class="hljs-built_in">RGBToYCoCg</span>(prev_color);<br><br><span class="hljs-comment">// Variance clipping.</span><br>float3 mu = m1 * kRcpSampleCount;<br>float3 sigma = <span class="hljs-built_in">sqrt</span>(<span class="hljs-built_in">abs</span>(m2 * kRcpSampleCount - mu * mu));<br>float3 minc = mu - kVarianceClipGamma * sigma;<br>float3 maxc = mu + kVarianceClipGamma * sigma;<br><br>prev_color = <span class="hljs-built_in">ClipAABB</span>(minc, maxc, <span class="hljs-built_in">clamp</span>(prev_color, color_min, color_max), mu);<br></code></pre></td></tr></table></figure></p><h1 id="bluring">Bluring</h1><h2 id="filtering">Filtering</h2><p>由于双线性滤波，对历史帧的采样有可能会引入周围（非本物体）像素的颜色，造成画面模糊的问题。在画面变化很快时，历史帧的采样点甚至<ahref="http://advances.realtimerendering.com/s2016/s16_Ke.pptx">不一定位于当前像素内</a>。由于累积历史样本的做法，错误也会跟随着累积造成进一步的模糊。</p><p>这属于<code>postaliasing</code>，因而采用更好的滤波器可以缓解这个问题，比如UE使用了一个优化的<code>Catmull–Rom Filter</code>，它会在目标点附近采样5次，根据相应权重混合，结果得到更清晰的画面。</p><blockquote><p>类似的优化也可以用于当前帧采样，比如使用<code>Mitchell fitler</code>而不是<code>Nearest Point</code>。</p></blockquote><p>当然，最后还有一个办法是增加一个pass，单独做锐化。</p><h2 id="texture-blurring">Texture blurring</h2><p>另外一个模糊来源是纹理采样，mipmapping已经自带模糊的效果了，而在屏幕空间的jitter也会附带造成纹理空间的模糊。有两个解决办法：</p><ol type="1"><li>引入一个负的mip bias，强制使用更低等级（更多细节）的mips。</li><li>利用uv的梯度信息对纹理uv进行unjitter，消除屏幕空间jitter的影响。</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">float2 <span class="hljs-title">UnjitterTextureUV</span><span class="hljs-params">(<span class="hljs-type">float</span> uv, float2 currentJitterInPixels)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-comment">// Note: We negate the y because UV and screen space run in opposite directions</span><br>    <span class="hljs-keyword">return</span> uv - <span class="hljs-built_in">ddx_fine</span>(uv) * currentJitterInPixels.x + <span class="hljs-built_in">ddy_fine</span>(uv) * currentJitterInPixels.y;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="flickering">Flickering</h1><p>这主要是由<code>Color clamping</code>带来的，高亮度的亚像素可能出现在某个历史帧，有时候这些高亮颜色被截断，有时候又不会被截断，随着采样模式的重复，这种情况一再重复，于是出现了闪烁。</p><p>一个缓解的措施是让TAA在LDR空间运行，这样就降低了亮度的影响，从而使得画面表现更稳定。做法也是和MSAA的Resolve一样，先做一次廉价的Tonemapping，然后TAA，最后再InvertTonemapping。</p><p>其次，既然闪烁来自于亮度，那么降低高亮度的亚像素的混合权重就能减缓这个问题，代价是画面稍微变暗：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs cpp">curr_weight *= <span class="hljs-number">1.0f</span> / (<span class="hljs-number">1.0f</span> + <span class="hljs-built_in">LuminanceRec709</span>(ldr_curr_color));<br>prev_weight *= <span class="hljs-number">1.0f</span> / (<span class="hljs-number">1.0f</span> + <span class="hljs-built_in">LuminanceRec709</span>(ldr_prev_color));<br> <br>float3 result = (curr_color * curr_weight + prev_color * prev_weight) / <span class="hljs-built_in">max</span>(curr_weight + prev_weight, <span class="hljs-number">0.00001</span>);<br></code></pre></td></tr></table></figure></p><p>最后，画面的快速变化也会带来闪烁，为了缓解这个因素，我们引入和<code>Velocity Vector</code>相关的系数，当画面高速运动时增大时历史帧的权重，当画面静止时增大当前帧的权重。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> kStaticBlending 0.95</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> kDynamicBlending 0.85</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> kMotionAmplify 6000</span><br><br><span class="hljs-type">float</span> prev_weight = <span class="hljs-built_in">clamp</span>(<br>        <span class="hljs-built_in">lerp</span>(kStaticBlending, kDynamicBlending, <span class="hljs-built_in">length</span>(velocity) * kMotionAmplify),<br>        kDynamicBlending, kStaticBlending<br>    );<br><span class="hljs-type">float</span> curr_weight = <span class="hljs-number">1.0</span> - prev_weight;<br></code></pre></td></tr></table></figure></p><h1 id="特点">特点</h1><p>由于jitter的存在，引入TAA需要对渲染管线做不小的改动，很多效果也都要考虑TAA的影响；此外TAA的一些artifact，也需要做针对性的调优，有很多需要注意的处理细节。但作为唯一能带来近似SSAA的实用反走样方案，以上这些代价都是值得的。</p><h1 id="参考">参考</h1><ol type="1"><li><ahref="https://www.gdcvault.com/play/1022970/Temporal-Reprojection-Anti-Aliasing-in">TemporalReprojection Anti-Aliasing in INSIDE</a></li><li><ahref="https://de45xmedrsdbp.cloudfront.net/Resources/files/TemporalAA_small-59732822.pdf">HightQuality Temporal Supersampling</a></li><li><ahref="https://diglib.eg.org/bitstream/handle/10.1111/cgf14018/v39i2pp607-621.pdf">ASurvey of Temporal Antialiasing Techniques</a></li><li><ahref="https://developer.download.nvidia.cn/gameworks/events/GDC2016/msalvi_temporal_supersampling.pdf">AnExcursion in Temporal Supersampling</a></li><li><ahref="https://www.elopezr.com/temporal-aa-and-the-quest-for-the-holy-trail/">TemporalAA and the quest for the Holy Trail</a></li><li><a href="https://alextardif.com/TAA.html">Temporal AntialiasingStarter Pack</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Rendering</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rendering</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>实时渲染中的反走样：空域滤波抗锯齿</title>
    <link href="/2022/06/05/spatial-anti-aliasing.html"/>
    <url>/2022/06/05/spatial-anti-aliasing.html</url>
    
    <content type="html"><![CDATA[<p>MSAA对几何走样有很好的表现，并且避免了SSAA成倍的着色开销，但缺点也很明显：</p><ol type="1"><li>深度和颜色缓冲的显存和带宽开销并没有减少</li><li>不适用于延迟渲染（解决成本太高）</li><li>无法解决着色走样</li></ol><p>MSAA的核心思想是解耦了覆盖和着色，通过覆盖测试找出了几何边缘的所在，并对几何边缘区域单独做混合。而找出边缘在图像处理领域也有很多办法，这种基于分析图像找出边缘再进一步处理的想法带来的一系列抗锯齿方法位于后处理，因而非常好地解决了1和2的问题。从信号处理的角度来看，它们可以看做是使用了某种重建滤波器来近似得到过采样的结果，因此可以被归类于<ahref="http://iryoku.com/aacourse/">Filtering Approach</a>。</p><p>最早是2009年由Intel的Alexander Reshetov提出的基于CPU的<ahref="http://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/readings/reshetov09_mlaa.pdf">MLAA算法</a>（<code>Morphological Anti-aliasing</code>），最初是为了解决光线追踪的抗锯齿技术，然后在2011由Jimenez给出了GPU上的<ahref="http://iryoku.com/aacourse/downloads/04-Jimenez&#39;s-MLAA-&amp;-SMAA-(Subpixel-Morphological-Anti-Aliasing).pdf">实现</a>并进一步改进为<ahref="http://www.iryoku.com/smaa/downloads/SMAA-Enhanced-Subpixel-Morphological-Antialiasing.pdf">SMAA</a>（<code>Enhanced Subpixel Morphological Antialiasing</code>），Nvidia的TimothyLottes也在2009年提出了一种简单且有效的抗锯齿算法——<ahref="https://developer.download.nvidia.cn/assets/gamedev/files/sdk/11/FXAA_WhitePaper.pdf">FXAA</a>（<code>Fast Approximate Antialiasing</code>）。目前最流行的这类抗锯齿方案是FXAA 和 SMAA，前者速度最快，但表现稍差，后者表现最好，但开销较大。</p><h1 id="fxaa">FXAA</h1><p>以下内容主要来自这篇<ahref="https://catlikecoding.com/unity/tutorials/advanced-rendering/fxaa/">文章</a>。</p><h2 id="亮度">亮度</h2><p>FXAA通过对比度来找寻图像的边缘，而对比度由亮度决定，FXAA实际上工作于只包含像素亮度的灰度图，这意味着当亮度足够接近时，即便像素本身颜色非常不一样，它们之间的过渡也不会显得很平滑。另外，FXAA需要亮度值在0~1之间，因此需要在tonemapping之后进行。</p><p>考虑到人眼对绿色是最敏感的，亮度可以直接使用g分量，当然也可以用常见的<code>dot(color, float3(0.2126729f,  0.7151522f, 0.0721750f)</code>计算。如果是后者，可以考虑单独一个pass预计算亮度并保存在alpha通道，这样就避免了每次采样都要计算亮度，还能直接使用<ahref="https://docs.microsoft.com/en-us/windows/win32/direct3dhlsl/texture2d-gather">Gather</a>函数来加速采样的过程。</p><h2 id="对比度">对比度</h2><p>FXAA 的目的是混合高对比度的像素，为此它需要：</p><ol type="1"><li>计算当前像素和周围像素的对比度。</li><li>如果有足够高的对比度，那就根据对比度选择混合因子。</li><li>考察对比度梯度，以确定混合方向。</li><li>在当前像素和它的一个邻近像素之间执行混合。</li></ol><figure><img src="/images/spatial-anti-aliasing/nesw.png"alt="FXAA使用水平和垂直方向的邻居像素以及中心像素计算对比度" /><figcaptionaria-hidden="true">FXAA使用水平和垂直方向的邻居像素以及中心像素计算对比度</figcaption></figure><p>计算对比度的代码如下： <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">LuminanceData</span> &#123;</span><br>    <span class="hljs-type">float</span> m, n, e, s, w;<br>&#125;;<br><br>LuminanceData <span class="hljs-title function_">SampleLuminanceNeighborhood</span> <span class="hljs-params">(float2 uv)</span> &#123;<br>    LuminanceData l;<br>    …<br><br>    l.highest = max(max(max(max(l.n, l.e), l.s), l.w), l.m);<br>    l.lowest = min(min(min(min(l.n, l.e), l.s), l.w), l.m);<br>    l.contrast = l.highest - l.lowest;<br>    <span class="hljs-keyword">return</span> l;<br>&#125;<br></code></pre></td></tr></table></figure>我们只关心高于一定阈值的对比度，除了绝对阈值<code>_ContrastThreshold</code>，FXAA还引入了相对阈值<code>_RelativeThreshold</code>——基于邻居像素的最大亮度值缩放而来，邻居越亮，阈值越高。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c">float4 <span class="hljs-title function_">ApplyFXAA</span> <span class="hljs-params">(float2 uv)</span> &#123;<br>    LuminanceData l = SampleLuminanceNeighborhood(uv);<br>    <span class="hljs-keyword">if</span> (l.contrast &gt;= max(_ContrastThreshold, _RelativeThreshold * l.highest)) &#123;<br>        ...<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></p><p>结果就是只有高对比度的像素才会进入下一个阶段。</p><p><img src="/images/spatial-anti-aliasing/fxaa_threshold.png" /></p><h2 id="混合因子">混合因子</h2><p>有了对比度，我们还需要混合因子。如何混合取决于中心像素和它的邻居的亮度的比较，这次我们还需要对角线的邻居。</p><p><img src="/images/spatial-anti-aliasing/nesw2.png" /></p><p>考虑到对角线像素离中心更远一点，它们应该有更低的权重，结果有点类似<code>tent filter</code>。</p><p><img src="/images/spatial-anti-aliasing/nesw_weight.png" /></p><p>接着找出中心像素亮度和期望亮度的差，取绝对值，此时结果类似<code>high-pass filter</code>，然后再根据NESW的亮度范围进行归一化。结果就是，中间像素亮度与期望亮度差值越大，混合因子越趋向于1。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> <span class="hljs-title function_">DeterminePixelBlendFactor</span> <span class="hljs-params">(LuminanceData l)</span> &#123;<br>    <span class="hljs-comment">//tent filter</span><br>    <span class="hljs-type">float</span> filter = <span class="hljs-number">2</span> * (l.n + l.e + l.s + l.w);<br>    filter += l.ne + l.nw + l.se + l.sw;<br>    filter *= <span class="hljs-number">1.0</span> / <span class="hljs-number">12</span>;<br>    <span class="hljs-comment">//high-pass</span><br>    filter = <span class="hljs-built_in">abs</span>(filter - l.m); <br>    filter = saturate(filter / l.contrast);<br>    <span class="hljs-keyword">return</span> filter;<br>&#125;<br></code></pre></td></tr></table></figure>这个结果是线性的，作为混合因子还不够平滑，我们使用smoothstep处理一下，为了让它下降的更慢一些，我们再进行一次平方。</p><p><img src="/images/spatial-anti-aliasing/smooth.png" /></p><p>最终实现： <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> <span class="hljs-title function_">DeterminePixelBlendFactor</span> <span class="hljs-params">(LuminanceData l)</span> &#123;<br>    <span class="hljs-comment">//tent filter</span><br>    <span class="hljs-type">float</span> filter = <span class="hljs-number">2</span> * (l.n + l.e + l.s + l.w);<br>    filter += l.ne + l.nw + l.se + l.sw;<br>    filter *= <span class="hljs-number">1.0</span> / <span class="hljs-number">12</span>;<br>    <span class="hljs-comment">//high-pass</span><br>    filter = <span class="hljs-built_in">abs</span>(filter - l.m); <br>    filter = saturate(filter / l.contrast);<br>    <br>    <span class="hljs-type">float</span> blendFactor = smoothstep(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, filter);<br>    <span class="hljs-keyword">return</span> blendFactor * blendFactor;<br>&#125;<br></code></pre></td></tr></table></figure></p><h2 id="混合方向">混合方向</h2><p>FXAA把中心像素和NESW的某个邻居像素混合，选取哪一个取决于亮度的梯度。在水平边的情况下，它必须是S或者N，取决于中心是低于还是高于这个边。否则，就必须是E或者W，取决于中心是在边的左边还是右边。</p><figure><img src="/images/spatial-anti-aliasing/fxaa_direction.png"alt="混合方向-红色表示亮度更暗或更亮" /><figcaptionaria-hidden="true">混合方向-红色表示亮度更暗或更亮</figcaption></figure><p>边缘并不总是刚好水平或者垂直，我们要选取一个最好的近似。为此，我们要比较水平和垂直方向的亮度。当它是水平边缘的情况，那么就应该有更强烈的垂直对比度，可能高于或低于中心，我们通过加上北和南，减去中心两次，取绝对值<spanclass="math inline">\(|n+s-2m|\)</span>。同样的逻辑也可以应用于垂直边缘。</p><p>我们还可以引入对角线像素来增强我们判断方向的正确性。对于左对角和右对角的各三个像素，分别做上述的计算，然后累加起来，这就得到了最终公式<spanclass="math inline">\(2|n+s-2m| +|ne+se-2e|+|nw+sw-2w|\)</span>。垂直边缘也是类似的算法，最后我们只关心谁的值更大。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">EdgeData</span> &#123;</span><br>    <span class="hljs-type">bool</span> isHorizontal;<br>&#125;;<br><br>EdgeData <span class="hljs-title function_">DetermineEdge</span> <span class="hljs-params">(LuminanceData l)</span> &#123;<br>    EdgeData e;<br>    <span class="hljs-type">float</span> horizontal =<br>        <span class="hljs-built_in">abs</span>(l.n + l.s - <span class="hljs-number">2</span> * l.m) * <span class="hljs-number">2</span> +<br>        <span class="hljs-built_in">abs</span>(l.ne + l.se - <span class="hljs-number">2</span> * l.e) +<br>        <span class="hljs-built_in">abs</span>(l.nw + l.sw - <span class="hljs-number">2</span> * l.w);<br>    <span class="hljs-type">float</span> vertical =<br>        <span class="hljs-built_in">abs</span>(l.e + l.w - <span class="hljs-number">2</span> * l.m) * <span class="hljs-number">2</span> +<br>        <span class="hljs-built_in">abs</span>(l.ne + l.nw - <span class="hljs-number">2</span> * l.n) +<br>        <span class="hljs-built_in">abs</span>(l.se + l.sw - <span class="hljs-number">2</span> * l.s);<br>    e.isHorizontal = horizontal &gt;= vertical;<br>    <span class="hljs-keyword">return</span> e;<br>&#125;<br></code></pre></td></tr></table></figure>接下来，我们要决定该和正还是负方向混合。我们通过比较对比度——亮度梯度——在中心两边的亮度值来决定。如果我们有一个水平边缘，那么N是正，S是负，如果我们有一个垂直边缘，那么E是正，W是负。如果正方向有最高的梯度，那么我们使用默认像素大小，否则像素大小取反。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> pLuminance = e.isHorizontal ? l.n : l.e;<br><span class="hljs-type">float</span> nLuminance = e.isHorizontal ? l.s : l.w;<br><span class="hljs-type">float</span> pGradient = <span class="hljs-built_in">abs</span>(pLuminance - l.m);<br><span class="hljs-type">float</span> nGradient = <span class="hljs-built_in">abs</span>(nLuminance - l.m);<br><br>e.pixelStep =<br>    e.isHorizontal ? _MainTex_TexelSize.y : _MainTex_TexelSize.x;<br><br><span class="hljs-keyword">if</span> (pGradient &lt; nGradient) &#123;<br>    e.pixelStep = -e.pixelStep;<br>&#125;<br></code></pre></td></tr></table></figure> ## 基于3x3的混合知道了混合因子和混合方向，混合操作就很简单了。 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> pixelBlend = DeterminePixelBlendFactor(l);<br>EdgeData e = DetermineEdge(l);<br><br><span class="hljs-keyword">if</span> (e.isHorizontal) &#123;<br>    uv.y += e.pixelStep * pixelBlend;<br>&#125;<br><span class="hljs-keyword">else</span> &#123;<br>    uv.x += e.pixelStep * pixelBlend;<br>&#125;<br><span class="hljs-keyword">return</span> float4(Sample(uv).rgb, l.m);<br></code></pre></td></tr></table></figure></p><p>结果是一个FXAA亚像素混合的抗锯齿图像。它影响高对比度的边缘，但一些低对比度的细节也被影响到了，这导致模糊的有点太过了。</p><p><img src="/images/spatial-anti-aliasing/fxaa_result1.png" /></p><p>可以加一个参数<code>_SubpixelBlending</code>人工调整混合因子。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> <span class="hljs-title function_">DeterminePixelBlendFactor</span> <span class="hljs-params">(LuminanceData l)</span> &#123;<br>    …<br>    <span class="hljs-keyword">return</span> blendFactor * blendFactor * _SubpixelBlending;<br>&#125;<br></code></pre></td></tr></table></figure> ## 基于边的混合现在的混合方案只对像素周围3X3的区域进行判断和混合，而很多锯齿是长条状的，对这些边来讲当前做法的效果并不好。</p><figure><img src="/images/spatial-anti-aliasing/fxaa_edge.png"alt="从上到下：无抗锯齿、当前效果、期望的效果" /><figcaptionaria-hidden="true">从上到下：无抗锯齿、当前效果、期望的效果</figcaption></figure><p>我们必须知道更多的信息才能知道当前处理的边是什么形状。我们已经知道当前像素在边的哪一侧，混合的像素在另一侧，为了确定边有多长，我们还需要知道它的梯度。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">EdgeData</span> &#123;</span><br>    <span class="hljs-type">bool</span> isHorizontal;<br>    <span class="hljs-type">float</span> pixelStep;<br>    <span class="hljs-type">float</span> oppositeLuminance, gradient;<br>&#125;;<br><br>EdgeData <span class="hljs-title function_">DetermineEdge</span> <span class="hljs-params">(LuminanceData l)</span> &#123;<br>    …<br>    <br>    <span class="hljs-keyword">if</span> (pGradient &lt; nGradient) &#123;<br>        e.pixelStep = -e.pixelStep;<br>        e.oppositeLuminance = nLuminance;<br>        e.gradient = nGradient;<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        e.oppositeLuminance = pLuminance;<br>        e.gradient = pGradient;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> e;<br>&#125;<br></code></pre></td></tr></table></figure></p><p>我们要计算出当前像素在这个边上的相对位置。为此需要沿着边的两个方向搜索，直到碰到端点——我们可以通过判断像素对的亮度梯度是否和起始像素对的亮度梯度不同来得知这一点。</p><p><img src="/images/spatial-anti-aliasing/edge_gradient.png" /></p><p>这里我们可以利用双线性过滤，在两像素中间的点进行一次采样得到两个像素的平均亮度。</p><figure><img src="/images/spatial-anti-aliasing/edge_search.png"alt="黄色是采样点" /><figcaption aria-hidden="true">黄色是采样点</figcaption></figure><p>我们先确定采样点的UV坐标，它位于中心像素uv再偏移一半图素大小的地方，后续的采样方向取决于它的朝向，要么水平要么垂直。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c">float2 uvEdge = uv;<br>float2 edgeStep;<br><span class="hljs-keyword">if</span> (e.isHorizontal) &#123;<br>    uvEdge.y += e.pixelStep * <span class="hljs-number">0.5</span>;<br>    edgeStep = float2(_MainTex_TexelSize.x, <span class="hljs-number">0</span>);<br>&#125;<br><span class="hljs-keyword">else</span> &#123;<br>    uvEdge.x += e.pixelStep * <span class="hljs-number">0.5</span>;<br>    edgeStep = float2(<span class="hljs-number">0</span>, _MainTex_TexelSize.y);<br>&#125;<br></code></pre></td></tr></table></figure></p><p>我们把当前像素点和待混合像素点的平均亮度乘以0.25（一个经验值）作为边缘的梯度阈值，在搜索时，对比采样的亮度和平均亮度得到一个亮度梯度，把这个梯度和梯度阈值做比较，如果两者相近，那么说明我们还没碰到端点，否则我们找到了边的端点。<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs csharp"><span class="hljs-built_in">float</span> edgeLuminance = (l.m + e.oppositeLuminance) * <span class="hljs-number">0.5</span>;<br><span class="hljs-built_in">float</span> gradientThreshold = e.gradient * <span class="hljs-number">0.25</span>;<br><br>float2 puv = uvEdge + edgeStep;<br><span class="hljs-built_in">float</span> pLuminanceDelta = SampleLuminance(puv) - edgeLuminance;<br><span class="hljs-built_in">bool</span> pAtEnd = abs(pLuminanceDelta) &gt;= gradientThreshold;<br></code></pre></td></tr></table></figure></p><p>我们必须在两侧持续搜索才能找到端点，因此我们需要一个循环，比如最多往两侧步进10次。</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs csharp"><span class="hljs-comment">//正方向</span><br>float2 puv = uvEdge + edgeStep;<br><span class="hljs-built_in">float</span> pLuminanceDelta = SampleLuminance(puv) - edgeLuminance;<br><span class="hljs-built_in">bool</span> pAtEnd = abs(pLuminanceDelta) &gt;= gradientThreshold;<br><br><span class="hljs-keyword">for</span> (<span class="hljs-built_in">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">9</span> &amp;&amp; !pAtEnd; i++) &#123;<br>    puv += edgeStep;<br>    pLuminanceDelta = SampleLuminance(puv) - edgeLuminance;<br>    pAtEnd = abs(pLuminanceDelta) &gt;= gradientThreshold;<br>&#125;<br><br><span class="hljs-comment">//负方向</span><br>float2 nuv = uvEdge - edgeStep;<br><span class="hljs-built_in">float</span> nLuminanceDelta = SampleLuminance(nuv) - edgeLuminance;<br><span class="hljs-built_in">bool</span> nAtEnd = abs(nLuminanceDelta) &gt;= gradientThreshold;<br><br><span class="hljs-keyword">for</span> (<span class="hljs-built_in">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">9</span> &amp;&amp; !nAtEnd; i++) &#123;<br>    nuv -= edgeStep;<br>    nLuminanceDelta = SampleLuminance(nuv) - edgeLuminance;<br>    nAtEnd = abs(nLuminanceDelta) &gt;= gradientThreshold;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>搜索步进能很大程度影响FXAA的表现，同时也影响性能，除了固定的步长，原版FXAA算法包含了一系列质量定义。Unity的posteffect stackv2使用质量等级28作为默认值。它的步进次数为10，第二步进距离为1.5而不是1，后续所有的步进长度是2，最后一个是4。如果还找不到端点，还有一个猜测步进长度是8。</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> EDGE_STEPS 1, 1.5, 2, 2, 2, 2, 2, 2, 2, 4</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> EDGE_GUESS 8</span><br></code></pre></td></tr></table></figure><blockquote><p>相对于单像素的步进，混合因子的块状更明显一点，质量因此稍微受损。但是它只需要更少的循环就能找到短边，更长的边也更容易找到。</p></blockquote><p>现在我们知道了当前像素离两个端点的距离，我们就可以利用它来计算混合因子，我们取最靠近端点的一侧计算混合因子。但在此之前，我们要先判断当前像素是否在属于最近端点那一侧，只有和最近端点同侧的像素才进行混合。判断依据就是，当前亮度和平均亮度的差的符号，和最近端点亮度和平均亮度的差的符号，是否一致。如果不在同一侧，那么就不混合（算法保证这个混合操作最终会在处理相对边的像素时进行）。</p><p><img src="/images/spatial-anti-aliasing/edge_side.png" /></p><p>如果需要混合，那么混合因子为0.5减去离最近端点距离除以总边长。这意味着越靠近端点就混合越多其他像素颜色，但在中点不做任何混合。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> shortestDistance;<br><span class="hljs-type">bool</span> deltaSign;<br><span class="hljs-keyword">if</span> (pDistance &lt;= nDistance) &#123;<br>    shortestDistance = pDistance;<br>    deltaSign = pLuminanceDelta &gt;= <span class="hljs-number">0</span>;<br>&#125;<br><span class="hljs-keyword">else</span> &#123;<br>    shortestDistance = nDistance;<br>    deltaSign = nLuminanceDelta &gt;= <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-keyword">if</span> (deltaSign == (l.m - edgeLuminance &gt;= <span class="hljs-number">0</span>)) &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-number">0.5</span> - shortestDistance / (pDistance + nDistance);<br></code></pre></td></tr></table></figure></p><p>最后，我们使用基于3x3区域的混合因子以及基于边算出的混合因子中的最大值，作为最终的混合因子。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> pixelBlend = DeterminePixelBlendFactor(l);<br>EdgeData e = DetermineEdge(l);<br><span class="hljs-type">float</span> edgeBlend = DetermineEdgeBlendFactor(l, e, uv);<br><span class="hljs-type">float</span> finalBlend = max(pixelBlend, edgeBlend);<br><br><span class="hljs-keyword">if</span> (e.isHorizontal) &#123;<br>    uv.y += e.pixelStep * finalBlend;<br>&#125;<br><span class="hljs-keyword">else</span> &#123;<br>    uv.x += e.pixelStep * finalBlend;<br>&#125;<br><span class="hljs-keyword">return</span> float4(Sample(uv).rgb, l.m);<br></code></pre></td></tr></table></figure></p><p><img src="/images/spatial-anti-aliasing/fxaa_result2.png" /></p><h2 id="特点">特点</h2><p>在表现上FXAA很接近MSAA，但由于它是基于像素来分析几何边缘的模式，因而其覆盖测试本质上不会超过一个像素的精度。在变动的画面中，三角形覆盖的像素是突然出现和消失的，因此不可避免地存在一种称为闪烁(<code>flicking</code>)的artifact。</p><p><img src="/images/spatial-anti-aliasing/triangle_fxaa1.gif" /></p><p><img src="/images/spatial-anti-aliasing/triangle_msaa1.gif" /></p><p><em>旋转三角形的两种动画：上面启用了 FXAA，下面启用了MSAAx4。注意：MSAA在三角形的边缘处对可见性测试进行了超采样，在MSAA中三角形覆盖的像素通过对子样本采样使得运动时的覆盖测试也有平滑过渡。而FXAA缺乏这种特性，尽管它的确沿着边缘产生了平滑的渐变，但这个渐变会突然消失或者出现。</em></p><h1 id="mlaa">MLAA</h1><p>SMAA基于MLAA优化改进而来，核心理念还是来自MLAA，为此先介绍MLAA。MLAA分成3个大的步骤分别对应3个Pass：第一步生成边缘信息图，第二步生成混合权重图，第三步做混合。</p><p><img src="/images/spatial-anti-aliasing/MLAA.png" /></p><h2 id="边缘检测">边缘检测</h2><p>有2种方法做边缘检测，一种是深度图，一种是像FXAA一样使用亮度。单纯使用深度图对深度接近而颜色差异大的边缘效果不好，而深度再加上instaceid+normal是最精确的，但开销太大，综合来讲使用亮度是最合适的。</p><p>MLAA将图像的边缘划分为垂直和水平两类，每次都对当前像素与左边和上边相邻的像素做对比，当差别大于某个阈值时认为此像素和邻居像素构成边界，论文中提到对于颜色域是<spanclass="math inline">\([0,1]\)</span>的图像来说,0.1的阈值是比较实用的选择，代码实现如下： <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c">    <span class="hljs-type">float</span> L = dot(colorGammaTex.SampleLevel(PointSampler, texcoord, <span class="hljs-number">0</span>).rgb, weights);<br><br>    <span class="hljs-type">float</span> Lleft = dot(colorGammaTex.SampleLevel(PointSampler, texcoord, <span class="hljs-number">0</span>, -int2(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>)).rgb, weights);<br>    <span class="hljs-type">float</span> Ltop  = dot(colorGammaTex.SampleLevel(PointSampler, texcoord, <span class="hljs-number">0</span>, -int2(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)).rgb, weights);<br>    <span class="hljs-type">float</span> Lright = dot(colorGammaTex.SampleLevel(PointSampler, texcoord, <span class="hljs-number">0</span>, int2(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>)).rgb, weights);<br>    <span class="hljs-type">float</span> Lbottom  = dot(colorGammaTex.SampleLevel(PointSampler, texcoord, <span class="hljs-number">0</span>, int2(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)).rgb, weights);<br><br>    float4 delta = <span class="hljs-built_in">abs</span>(L.xxxx - float4(Lleft, Ltop, Lright, Lbottom));<br>    float4 edges = step(threshold.xxxx, delta);<br><br>    <span class="hljs-keyword">if</span> (dot(edges, <span class="hljs-number">1.0</span>) == <span class="hljs-number">0.0</span>)<br>        discard;<br>    <span class="hljs-keyword">return</span> edges;<br></code></pre></td></tr></table></figure></p><p>一开始会初始化一张全为0的纹理保存边缘信息，如果边界出现在当前像素左边，则R为1（存在垂直边缘），如果边界出现在上边则G为1（存在水平边缘），也可以同时出现两个边界，于是边缘信息图将会由红黄绿三色构成。</p><h2 id="混合权重">混合权重</h2><p>为了找出边缘的模式，我们要在边缘可能出现的地方做搜索，上一步生成的R和G分量为1的像素就是搜索开始的地方。</p><p><img src="/images/spatial-anti-aliasing/MLAA_blend.png" /></p><p>假设在G为1的地方搜索水平边缘，目的就是要找出当前像素离左右端点的距离<spanclass="math inline">\(d_{left},d_{right}\)</span>，，以及边界<spanclass="math inline">\(e_{left},e_{right}\)</span>，然后根据<spanclass="math inline">\(d\)</span>和<spanclass="math inline">\(e\)</span>计算当前像素的覆盖率。</p><p>和FXAA类似，在这里我们可以利用双线性滤波来减少采样次数，假设从绿色五角星出发向左搜索到红色圆圈所在的位置，我们需要判断G值的不同，为此我们在两个像素中间（菱形）位置一次采样，就获能得两个像素的G平均值。如果值为1，说明两个点都有上边界；为0.5，说明只有一个点有上边界；为0，说明两个点都没有上边界。</p><p><img src="/images/spatial-anti-aliasing/MLAA_search.png" /></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">float</span> <span class="hljs-title function_">SearchXLeft</span><span class="hljs-params">(float2 texcoord)</span> &#123;<br>    texcoord -= float2(<span class="hljs-number">1.5</span>, <span class="hljs-number">0.0</span>) * PIXEL_SIZE;<br>    <span class="hljs-type">float</span> e = <span class="hljs-number">0.0</span>;<br><br>    <span class="hljs-comment">// We offset by 0.5 to sample between edgels, thus fetching two in a row</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; maxSearchSteps; i++) &#123;<br>        e = edgesTex.SampleLevel(LinearSampler, texcoord, <span class="hljs-number">0</span>).g;<br>        <span class="hljs-comment">// We compare with 0.9 to prevent bilinear access precision problems</span><br>        [flatten] <span class="hljs-keyword">if</span> (e &lt; <span class="hljs-number">0.9</span>) <span class="hljs-keyword">break</span>;<br>        texcoord -= float2(<span class="hljs-number">2.0</span>, <span class="hljs-number">0.0</span>) * PIXEL_SIZE;<br>    &#125;<br><br>    <span class="hljs-comment">// When we exit the loop without founding the end, we want to return</span><br>    <span class="hljs-comment">// -2 * maxSearchSteps</span><br>    <span class="hljs-keyword">return</span> max(<span class="hljs-number">-2.0</span> * i - <span class="hljs-number">2.0</span> * e, <span class="hljs-number">-2.0</span> * maxSearchSteps);<br>&#125;<br></code></pre></td></tr></table></figure><p>而对于边界形状的检测也可以做类似的优化，不过需要在垂直方向偏移0.25个像素。比如在向右查找边缘的端点时，向下偏移0.25个像素采样，会获得4种可能的值对应4种形状，根据返回值我们马上就能判断边界形状：</p><p><img src="/images/spatial-anti-aliasing/MLAA_search2.png" /></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c">        <span class="hljs-comment">// Now fetch the crossing edges. Instead of sampling between edgels, we</span><br>        <span class="hljs-comment">// sample at -0.25, to be able to discern what value has each edgel:</span><br>        float4 coords = mad(float4(d.x, <span class="hljs-number">-0.25</span>, d.y + <span class="hljs-number">1.0</span>, <span class="hljs-number">-0.25</span>),<br>                            PIXEL_SIZE.xyxy, texcoord.xyxy);<br>        <span class="hljs-type">float</span> e1 = edgesTex.SampleLevel(LinearSampler, coords.xy, <span class="hljs-number">0</span>).r;<br>        <span class="hljs-type">float</span> e2 = edgesTex.SampleLevel(LinearSampler, coords.zw, <span class="hljs-number">0</span>).r;<br></code></pre></td></tr></table></figure><p>确定了边的长度和形状，就可以计算当前像素的覆盖率，也就是混合权重。理论上要根据重矢量化线计算像素覆盖面积，但是Jimenez在这里引入事先计算好权重的LUT纹理，避免了动态分支和复杂的面积计算过程。由于计算步数的限制，边缘长度最大为8，而边缘端点处形状则限制为4种，故所有长度和形状的边缘对应的权重值，都可以保存在一张纹理中。</p><p><img src="/images/spatial-anti-aliasing/MLAA_lut.png" /></p><p>纹理中的R通道表示是将下面像素颜色混合到上面，G通道与此相反，B通道表示将左边像素混合到当前像素的系数，A通道与此相反。此外还有选择性的不处理某些模式以及简化某些模式，因为这些模式的重矢量化会引入artifact。各个维度对应的参数如下：</p><p><img src="/images/spatial-anti-aliasing/MLAA_lut2.png" /></p><p>实现代码： <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c">float2 <span class="hljs-title function_">Area</span><span class="hljs-params">(float2 distance, <span class="hljs-type">float</span> e1, <span class="hljs-type">float</span> e2)</span> &#123;<br>     <span class="hljs-comment">// * By dividing by areaSize - 1.0 below we are implicitely offsetting to</span><br>     <span class="hljs-comment">//   always fall inside of a pixel</span><br>     <span class="hljs-comment">// * Rounding prevents bilinear access precision problems</span><br>    <span class="hljs-type">float</span> areaSize = MAX_DISTANCE * <span class="hljs-number">5</span>;<br>    float2 pixcoord = MAX_DISTANCE * round(<span class="hljs-number">4.0</span> * float2(e1, e2)) + distance;<br>    float2 texcoord = pixcoord / (areaSize - <span class="hljs-number">1.0</span>);<br>    <span class="hljs-keyword">return</span> areaTex.SampleLevel(PointSampler, texcoord, <span class="hljs-number">0</span>).rg;<br>&#125;<br></code></pre></td></tr></table></figure> ## 混合颜色这里再次利用了双线性过滤器，一次性混合4个方向的颜色。</p><p><img src="/images/spatial-anti-aliasing/MLAA_weight.png" /></p><p>实现代码： <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs c">float4 <span class="hljs-title function_">NeighborhoodBlendingPS</span><span class="hljs-params">(float4 position : SV_POSITION,</span><br><span class="hljs-params">                              float2 texcoord : TEXCOORD0)</span> : SV_TARGET &#123;<br>    <span class="hljs-comment">// Fetch the blending weights for current pixel:</span><br>    float4 topLeft = blendTex.SampleLevel(PointSampler, texcoord, <span class="hljs-number">0</span>);<br>    <span class="hljs-type">float</span> bottom = blendTex.SampleLevel(PointSampler, texcoord, <span class="hljs-number">0</span>, int2(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)).g;<br>    <span class="hljs-type">float</span> right = blendTex.SampleLevel(PointSampler, texcoord, <span class="hljs-number">0</span>, int2(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>)).a;<br>    float4 a = float4(topLeft.r, bottom, topLeft.b, right);<br><br>    <span class="hljs-comment">// Up to 4 lines can be crossing a pixel (one in each edge). So, we perform</span><br>    <span class="hljs-comment">// a weighted average, where the weight of each line is &#x27;a&#x27; cubed, which</span><br>    <span class="hljs-comment">// favors blending and works well in practice.</span><br>    float4 w = a * a * a;<br><br>    <span class="hljs-comment">// There is some blending weight with a value greater than 0.0?</span><br>    <span class="hljs-type">float</span> sum = dot(w, <span class="hljs-number">1.0</span>);<br>    <span class="hljs-keyword">if</span> (sum &lt; <span class="hljs-number">1e-5</span>)<br>        discard;<br><br>    float4 color = <span class="hljs-number">0.0</span>;<br><br>    <span class="hljs-comment">// Add the contributions of the possible 4 lines that can cross this</span><br>    <span class="hljs-comment">// pixel:</span><br>    float4 coords = mad(float4( <span class="hljs-number">0.0</span>, -a.r, <span class="hljs-number">0.0</span>,  a.g), PIXEL_SIZE.yyyy, texcoord.xyxy);<br>    color = mad(colorTex.SampleLevel(LinearSampler, coords.xy, <span class="hljs-number">0</span>), w.r, color);<br>    color = mad(colorTex.SampleLevel(LinearSampler, coords.zw, <span class="hljs-number">0</span>), w.g, color);<br>    coords = mad(float4(-a.b,  <span class="hljs-number">0.0</span>, a.a,  <span class="hljs-number">0.0</span>), PIXEL_SIZE.xxxx, texcoord.xyxy);<br>    color = mad(colorTex.SampleLevel(LinearSampler, coords.xy, <span class="hljs-number">0</span>), w.b, color);<br>    color = mad(colorTex.SampleLevel(LinearSampler, coords.zw, <span class="hljs-number">0</span>), w.a, color);<br><br>    <span class="hljs-comment">// Normalize the resulting color and we are finished!</span><br>    <span class="hljs-keyword">return</span> color / sum;<br><br>&#125;<br></code></pre></td></tr></table></figure> ## Linear Space还需要注意的一点是，MLAA需要在线性空间下进行 （和FXAA不同）。</p><p><img src="/images/spatial-anti-aliasing/MLAA_gamma.png" /></p><figure><img src="/images/spatial-anti-aliasing/MLAA_linear.png"alt="明显下面的结果更接近MSAA 8x" /><figcaption aria-hidden="true">明显下面的结果更接近MSAA 8x</figcaption></figure><h1 id="smaa">SMAA</h1><p>SMAA是对MLAA的改进和优化，主要包括以下内容。</p><h2 id="边缘检测-1">边缘检测</h2><p>人眼主观视觉倾向于在高对比边缘出现时，忽略附近低对比度的边缘。因此基于局部亮度查找的边缘，会生成（人眼主观忽略的）伪边缘。下图，最左边的图中红色是伪边缘，绿色是期望的边缘，MLAA会生成中间的结果，而SMAA会生成最右边的结果，更符合人眼直觉。</p><p><img src="/images/spatial-anti-aliasing/smaa_edge1.png" /></p><p>为了找出高对比度边缘，SMAA引入了自适应的双阈值判定来达到两个目的：</p><ol type="1"><li>防止搜索在伪边界停止。</li><li>当像素有两个平行的边缘时，选择占主导地位（高对比度）的边缘。</li></ol><p>以左边界搜索为例，首先和MLAA一样用当前像素和左侧像素的亮度差做边界判定：<spanclass="math inline">\(e_l = |L - L_l| &gt; T\)</span> （<spanclass="math inline">\(e_l\)</span>是个布尔值，<spanclass="math inline">\(T\)</span>是阈值），接着我们还会再往左考虑一个像素的亮度，做第二次判定：<span class="math display">\[\begin{aligned}c_{max} &amp;= max(c_t, c_r, c_b, c_l, c_{2l})\\e_l\ &amp;= e_l \wedge c_l &gt; 0.5 \cdot c_{max}\end{aligned}\]</span>结果就如下图，灰点是当前像素，橙色是伪边界，蓝色是主导边界。最终算法会舍弃橙色边界，留下蓝色边界（最右边）。</p><p><img src="/images/spatial-anti-aliasing/smaa_edge2.png" /></p><h2 id="模式识别">模式识别</h2><h3 id="保留正常的几何轮廓">保留正常的几何轮廓</h3><p>MLAA倾向于把任何棱角磨圆，比如对一个正方形进行MLAA，会得到下图中间的结果，而SMAA会得到右边的结果。</p><p><img src="/images/spatial-anti-aliasing/smaa_cube.png" /></p><p>SMAA的做法是在原边界检测的基础上再向外扩展一个像素做边界检测，如果依然存在边界，则说明有可能是几何棱角（这里的假设是几何轮廓边界总是大于一个像素）。以下图左边为例，原来检测到的（水平）边界是红色，向外扩展一个像素的边界是橙色<spanclass="math inline">\(e_1,e_2,e_3,e_4\)</span>，<spanclass="math inline">\(e3\)</span>依然存在边界，说明原边界可能是几何轮廓的一部分，而<spanclass="math inline">\(e_4\)</span>不存在边界，说明不是几何轮廓。</p><p><img src="/images/spatial-anti-aliasing/smaa_geometric.png" /></p>如果边界可能是几何轮廓，那么原来的混合权重需要再乘以一个系数<spanclass="math inline">\(r\)</span>，否则就用原来的混合权重。以上图为例，<spanclass="math inline">\(r\)</span>取1.0，0.5和0.0得到的重矢量化线分别是：蓝色（不变），黄色和粉红色。设<spanclass="math inline">\(a_t\)</span>和<spanclass="math inline">\(a_b\)</span>是原边界检测得到的混合权重，则调整后的计算方式如下：$$<span class="math display">\[\begin{array}ca&#39;_t=\begin{cases}r \cdot a_t  \qquad \text{if} \ d_l \lt d_r \ \wedge \ e_1\\r \cdot a_t  \qquad \text{if} \ d_l \ge d_r \ \wedge \ e_2\\a_t \qquad \qquad \text{otherwise}\end{cases}\\a&#39;_b=\begin{cases}r \cdot a_b  \qquad \text{if} \ d_l \lt d_r \ \wedge \ e_3\\r \cdot a_b  \qquad \text{if} \ d_l \ge d_r \ \wedge \ e_4\\a_b \qquad \qquad \text{otherwise}\end{cases}\end{array}\]</span><p>$$</p><h3 id="对角线模式">对角线模式</h3><p>MLAA中只有垂直和水平两个方向的边缘检测，SMAA引入了对角线方向的边缘检测。下图左边为MLAA的重矢量化线（蓝色），右边为SMAA的重矢量化线（蓝色）。</p><p><img src="/images/spatial-anti-aliasing/smaa_diagnal.png" /></p><p>同样针对这些对角线模式，也引入了预计算的LUT纹理加速混合权重的计算。</p><p><img src="/images/spatial-anti-aliasing/smaa_diagnal_lut.png" /></p><h3 id="精确边界搜索">精确边界搜索</h3><p>MLAA利用的双线性滤波还不够完美，一次只能检测两个像素，且存在错失边界的可能，而SMAA通过在xy轴取不同的偏移，来达到一次检测4个像素的目的，且不会错失边界。</p><p><img src="/images/spatial-anti-aliasing/smaa_search.png" /></p><p>上图以搜索水平边缘的左端点为例：</p><ul><li>左上：起始像素为灰点。</li><li>右上：MLAA的采样点是橙色点，它只检测到橙色线标记的边，而SMAA的采样点是绿色，它还可能检测到绿色线标记的边。</li><li>左下：MLAA采样的点和一次采样能检测到两个像素<spanclass="math inline">\(b_1,b_2\)</span>，以及最终会错失的端点（蓝色）。</li><li>右下：SMAA采样的点和一次采样能检测到四个像素<spanclass="math inline">\(b_1,b_2,b_3,b_4\)</span>，最终所有可能的端点都会被检测到。</li></ul><h2 id="特点-1">特点</h2><p>SMAA对几何边缘形态的处理非常精细，几乎达到了重建滤波器所能做到的极限，效果比FXAA要更好，很接近MSAA，但代价是3次PASS。此外，它也有滤波方案不可避免的问题：闪烁。</p><h1 id="参考">参考</h1><ol type="1"><li><a href="http://iryoku.com/aacourse/">Filtering Approaches forReal-Time Anti-Aliasing</a></li><li><ahref="http://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/readings/reshetov09_mlaa.pdf">MLAA</a></li><li><ahref="http://iryoku.com/aacourse/downloads/04-Jimenez&#39;s-MLAA-&amp;-SMAA-(Subpixel-Morphological-Anti-Aliasing).pdf">Jimenez'sMLAA&amp;SMAA</a></li><li><ahref="http://www.iryoku.com/smaa/downloads/SMAA-Enhanced-Subpixel-Morphological-Antialiasing.pdf">SMAA</a></li><li><ahref="https://developer.download.nvidia.cn/assets/gamedev/files/sdk/11/FXAA_WhitePaper.pdf">FXAAWhitePaper</a></li><li><ahref="https://catlikecoding.com/unity/tutorials/advanced-rendering/fxaa/">Advance-renderingFXAA</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Rendering</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rendering</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>实时渲染中的反走样：MSAA</title>
    <link href="/2022/05/29/MSAA.html"/>
    <url>/2022/05/29/MSAA.html</url>
    
    <content type="html"><![CDATA[<h1 id="原理">原理</h1><p>如上一篇<ahref="https://luxaviar.github.io/post/20220528-%E6%B8%B2%E6%9F%93%E4%B8%AD%E7%9A%84%E9%87%87%E6%A0%B7%E7%90%86%E8%AE%BA/">文章</a>所述，在实时渲染中走样不可避免，虽然SSAA能同时解决着色和几何走样，但由于高昂的性能开销注定无法成为主流，于是各种<code>Anti-Aliasing</code>（反走样）技术应运而生。</p><p>早期的渲染由于技术限制，比如简单的Phong模型，着色结果基本依赖于纹理采样，而后者引入的走样已经由mipmap较好地解决了，因此着色走样并不是主要问题。相反，由于低下的屏幕分辨率，几何走样的artifact更为凸显，于是MSAA被发明了出来以解燃眉之急。</p><p>决定几何图元（三角形）是否显示在屏幕上，取决于两个因素：覆盖（<em>coverage</em>）和遮挡（<em>occlusion</em>）。覆盖由图元是否包含了某个屏幕像素的几何中心来决定：</p><figure><img src="/images/MSAA/geometry_aliasing.png"alt="只有像素中心（红色）被覆盖的像素才通过覆盖测试" /><figcaptionaria-hidden="true">只有像素中心（红色）被覆盖的像素才通过覆盖测试</figcaption></figure><p>遮挡告诉我们被覆盖的像素是否也被其他图元覆盖，一般通过z-buffer处理：每个像素存储一个离相机最近的覆盖图元的深度值，光栅化时图元的深度值和z值做比较，从而判断图元是否被遮挡，只有离相机更近的图元会更新z值。理论上深度测试在着色之后发生，但现代GPU都会在着色前执行深度测试，以减少不必要的着色开销作为一种优化手段（除非z值延迟到像素着色器才决定）。</p><p>只有通过了<code>Coverage Test</code>和<code>Occlusion Test</code>，一个三角形才可以在屏幕上的某个像素被看见。可见性其实是一种关于x和y的2D信号函数，从信号处理的视角出发，我们观察到：</p><ol type="1"><li>屏幕分辨率等价于可见性采样频率；</li><li>图元本身自带不连续性（三角形的出现和断开可以是突然的），这意味着可见性信号具有无限带宽，因此欠采样一定会导致走样。</li></ol><p>既然走样由欠采样导致，那么提高采样频率肯定能一定程度上减少走样，这就导向了SSAA：以高于屏幕分辨率的像素渲染，然后用重建滤波器降采样到屏幕分辨率。代价是显存、带宽、像素着色计算量都成倍增大，代价往往不可接受。是否存在一种方案，既能获得SSAA的部分优点，同时又不用承担如此高的成本呢？</p><p>MSAA就是这样一种方案，它只关注于几何走样的部分，和SSAA相同的地方在于，覆盖和遮挡测试都在高于屏幕分辨率下进行，一个像素内有多个亚像素对应多个采样点（子样本）。深度测试需要针对每个亚像素执行，图元是否覆盖某个像素将由亚像素的覆盖情况决定，因此z-buffer的大小依然需要增大N倍（取决于子样本数）。</p><figure><img src="/images/MSAA/msaa_pattern.png" alt="经典的MSAA 4x采样模式" /><figcaption aria-hidden="true">经典的MSAA 4x采样模式</figcaption></figure><p>和SSAA不同的地方在于，着色器不需要在每个亚像素执行一遍，一旦某个图元通过了覆盖和遮挡测试，表明它占据至少一个子样本，那么像素着色器只会执行一次（顶点属性依然插值到像素的中心位置，而非亚像素位置，但也不一定，比如像素中心不在三角形内部时，也可以选择位于三角形内的子样本位置），然后赋给各个被占据的子样本，也因此渲染目标的颜色缓冲大小相比SSAA也没有减小。</p><p><img src="/images/MSAA/subsample.png" /></p><p>如果多个图元占据了同一像素的不同子样本，那么着色器依然会计算多次。这种情况只在图元边缘发生，虽然总体着色开销依然要高于原始分辨率下的渲染，但却大大低于SSAA（考虑到屏幕中边缘区域是不断变化的，MSAA的实际性能开销并不是一个恒定值）。</p><figure><img src="/images/MSAA/subsample2.png"alt="不同图元覆盖了各自的子样本需要各自执行一次像素着色" /><figcaptionaria-hidden="true">不同图元覆盖了各自的子样本需要各自执行一次像素着色</figcaption></figure><h1 id="resolve">Resolve</h1><p>将过采样的信号重新输出到屏幕分辨率的过程称为<code>Resolve</code>。早期GPU在这个阶段会自动使用1像素宽的<code>box filter</code>对这些子样本取平均值，作为最终屏幕像素的颜色。结果是，如果一个像素完全被一个图元覆盖，那么结果与非MSAA渲染一样，而处于图元边缘的像素，将得到了一个渐变的颜色，其渐变阶数等于子样本数。而对于z-buffer，简单地使用Min、Max甚至第1个子样本值即可，因为对深度/模板做平均没有意义。</p><p><img src="/images/MSAA/resolve.png" /></p><p>当然早期硬件在Resolve阶段也可以使用不同的滤波器，比如Nvidia 的“Quincunx”AA，它使用一个2像素宽的<code>tent filter</code>，以2倍 MSAA模式中的一个样本为中心。由于滤波器更宽，与<code>box filter</code>相比，走样是减少了，但也引入了高频的不必要衰减，使得画面看起来更模糊了。</p><p>MSAA的核心思想是解耦覆盖和着色，基于这个原理进一步挖掘，硬件厂商又引入了MSAA的改进版本来提高MSAA的质量，同时提高性能。比如Nvidia的CSAA和AMD的EQAA。其基本原理是，用于覆盖测试的子样本比颜色子样本更多，通过更精细的覆盖率测试以及每个覆盖子样本的权重，计算出一个更精确的颜色子样本的值。</p><p><img src="/images/MSAA/eqaa.png" /></p><p>同时每个颜色子样本还可以不再记录颜色，而是记录颜色列表的索引，这样可以减少子样本的存储和带宽开销。</p><p><img src="/images/MSAA/eqaa2.png" /></p><p>随着GPU可编程管线的发展，现代硬件支持自定义的Resolve，而且完全有可能比硬件默认设置做的更好，这就是<code>Custom Resolve</code>。在<ahref="https://mynameismjp.wordpress.com/2012/10/28/msaa-resolve-filters/">这里</a>可以找到非常全面的<code>Custom Resolve</code>在选用不同滤波器时的质量表现情况。</p><h1 id="hdr">HDR</h1><p>如果不考虑HDR，在Resolve之后我们就可以应用各种后处理，但这里有个隐含前提：使用<code>box filter</code>进行Resolve之后，三角形边缘的渐变颜色在人眼感官上是平滑的。而当HDR、曝光和色调映射引入到渲染管线时，每个像素的（着色）颜色和它实际在屏幕上的颜色不再有任何线性的关系，因此如果还是使用类似LDR下做MSAA的流程，三角形边缘的渐变颜色将不再平滑，特别是如果边缘存在极端的对比度时，最终结果就好像没有使用MSAA。</p><figure><img src="/images/MSAA/hdr_msaa.png"alt="在MSAA Resolve之后应用tone mapping" /><figcaption aria-hidden="true">在MSAA Resolve之后应用tonemapping</figcaption></figure><figure><img src="/images/MSAA/ldr_msaa.png"alt="在MSAA Resolve之前应用tone mapping" /><figcaption aria-hidden="true">在MSAA Resolve之前应用tonemapping</figcaption></figure><p>出现这种差别的根本原因在于，在两种情况下MSAA过采样的颜色信号是不同的，前者是对HDR颜色信号进行过采样，后者是对屏幕上的LDR颜色信号进行过采样，而我们想要的是后者。一般来讲后处理需要在Resolve之后，而有些后处理又需要在HDR颜色下进行，为了解决Resolve和后处理的顺序问题，我们可以这样做：</p><ol type="1"><li>在HDR渲染目标的MSAAResolve前，对每个子样本应用一个简单（低性能）版本的色调映射和曝光。</li><li>执行Resolve</li><li>应用1中的色调映射和曝光的逆操作，还原到HDR颜色空间。</li></ol><p>由此，在Resolve之后我们依然可以进行HDR的后处理，同时也不会大幅影响性能。</p><h1 id="延迟渲染">延迟渲染</h1><p>总体来讲，MSAA并不适合延迟渲染。首先MSAA是解决几何走样的问题，而延迟渲染在光照阶段就已经丢失了几何信息（只是一个后处理），因此在此阶段开启MSAA毫无意义。其次，在GBuffer阶段，对深度、法线这些信息Resolve毫无意义，因为加权后光照和单独光照后再加权的结果并不一致。</p><p>基于以上原因，唯一正确的做法只能是GBuffer必须带着这些子样本进入光照阶段，然后为每个子样本进行光照计算，最后Resolve，但这么做显然代价太大，首先GBuffer膨胀为N倍（取决于子样本数量，而且MRT也要支持Multisample），其次着色计算开销也膨胀为N倍。考虑到MSAA其实只对三角形边缘起作用，一种改进方案是先标记出像素属于三角形内部还是边缘（使用一个模板缓冲），然后只在边缘进行多个子样本的着色计算，具体可以参考<ahref="https://diaryofagraphicsprogrammer.blogspot.com/2009/06/multisample-anti-aliasing.html">这里</a>。</p><h1 id="alpha-to-coverage">Alpha-To-Coverage</h1><p>在渲染基于mask的透明物体时（镂空），一般有两种做法：Alpha Test和AlphaBlend，前者在镂空的边缘容易引入锯齿，这属于着色走样，MSAA对此无能为力（它只在几何边缘制造平滑的渐变，而镂空在三角形内部）；后者虽然可以有平滑的边缘，但要得到正确结果需要正确的顺序。为了解决这个问题，基于MSAA的<code>Alpha-To-Coverage</code>技术被发明出来了，使用它不仅可以有平滑的边缘，而且也不依赖半透排序，具体做法可以参考<ahref="https://bgolus.medium.com/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f">这里</a>。</p><p><img src="/images/MSAA/atc.png" /></p><p><code>Alpha-To-Coverage</code>的原理很简单，MSAA的覆盖率除了由子样本的深度和模板值决定外，还会额外基于alpha生成一个coveragemask，再和原来的结果做一个AND操作，最终影响要更新的样本数。比如有两个子样本通过了覆盖测试，在写入子样本颜色之前，读取到alpha值为0.5，那么只会有一个子样本颜色被写入，这样就实现了50%的半透明效果，具体实现是硬件相关的。某种程度上可以把<code>Alpha to Coverage</code>可解为基于亚像素级别的AlphaTest，把Alpha转成mask来实现平滑过渡。</p><h1 id="on-chip-msaa">On-Chip MSAA</h1><p>移动设备GPU一般是TBR/TBDR的架构，它将需要渲染的画面分成一个个的tile（比如32x32大小），tile内包含相应的framebuffer/depth buffer/stencilbuffer等数据。在渲染每个tile时，GPU可以把整个tile放进一个片上高速缓存（on-chipmemory），这样GPU就只要直接读写本地缓存，不需要访问外部内存，当tile渲染完成后，再整片写回systemmemory，整个过程极大减少了带宽消耗。</p><p>理论上可以将整个MSAA放在on-chipmemory上高效的完成，子样本需要的所有数据，都存储在tile内，然后在tile写回内存时进行Resolve，这就不会有带宽的额外消耗。</p><h1 id="参考">参考</h1><ol type="1"><li><ahref="https://mynameismjp.wordpress.com/2012/10/24/msaa-overview/">MSAAOverview</a></li><li><ahref="https://mynameismjp.wordpress.com/2012/10/28/msaa-resolve-filters/">EXPERIMENTINGWITH RECONSTRUCTION FILTERS FOR MSAA RESOLVE</a></li><li><ahref="https://bgolus.medium.com/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f">Anti-aliasedAlpha Test: The Esoteric Alpha To Coverage</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Rendering</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rendering</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>渲染中的采样理论</title>
    <link href="/2022/05/28/sampling-theory.html"/>
    <url>/2022/05/28/sampling-theory.html</url>
    
    <content type="html"><![CDATA[<h1 id="采样定理">采样定理</h1><p>采样是将一个信号（例如时间或空间上连续的函数）转换为离散序列（时间或空间上离散的函数）的过程。信号可以是任何维度的连续函数，最常见的是一维的声音信号，它可以被表示成时间的函数，在时域处理信号也被称为时域分析；图像也是一种连续信号，处于平面空间域，在平面空间中处理图像信号，被称为空域分析。</p><p>信号也可以用频率来描述，所谓频率可以粗略理解为信号在其原来的域中的变化速度。真实世界中一个信号可以有不止一个频率，而是包含了很多不同的频率，这些频率组成一个频谱。一个信号可以通过<ahref="https://en.wikipedia.org/wiki/Fourier_transform">傅里叶变换</a>从它的原始表示（时域或空域）转换到它的频谱表示（称为频域），适用于傅里叶变换的函数可以分解为一系列正弦曲线的加权和，正弦函数的频率分布对应于原函数的频率分布。</p><p>下图展示了两个变化率不一样的函数，a变化相对较慢，b较快。</p><p><img src="/images/sampling-theory/change_functions.png" /></p><p>他们在频域的图像如下，其中x轴是频率，y轴是振幅，图表展示了频率的分布情况。</p><p><img src="/images/sampling-theory/frequency_funtions.png" /></p><p>一旦进入频域，我们就可以确定这个信号是否有一个最高频率（高于此频率的信号强度都为0）。如果有这样一个最高频率，那么称此信号是有限带宽（<code>bandlimited</code>），因此存在一个带宽（<code>bandwidth</code>）。根据奈奎斯特-香农采样定理（<ahref="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Nyquist–Shannonsamplingtheorem</a>），假设信号的最大带宽是B，那么我们的采样频率大于2B的时候就可以根据样本无损还原出原始信号。</p><h1 id="信号重建">信号重建</h1><p>所谓信号重建（reconstruction）就是从离散的信号样本中，获得原始连续信号函数的近似。有了这个近似，我们就可以在一组新的采样点上对其进行离散采样，也就是重采样（resampling）。还原的过程就是利用局部离散值，计算它们中间的某个近似值，因此也可以说是对样本的插值（interpolation）。</p><p>从奈奎斯特-香农采样定理我们知道，高频信号需要高频采样才能不失真。</p><p><img src="/images/sampling-theory/sample.png" /></p><p>如上图所示，使用线性插值法，在相同采样频率下，对于低频的<spanclass="math inline">\(f_1(x)\)</span>，还原效果很接近原函数；而对于频率最高的<spanclass="math inline">\(f_5(x)\)</span>，还原的结果最差。</p><p>插值所用的函数也称为滤波函数（或者滤波器），信号重建的过程就是对一组离散样本应用某种重建滤波器，得到原始连续信号的近似值。通常这些滤波器是关于<spanclass="math inline">\(x=0\)</span>对称的函数，并且只在0附近有非零值（一般来说越远的样本对中心样本的影响越少）。</p><p><img src="/images/sampling-theory/filters.png" /></p><p><em>以上分别是<code>box function</code>、<code>tent function</code>和<code>sinc function</code>。</em></p><p>应用滤波器的操作被称为卷积（<code>convolution</code>），本质上就是围绕采样点按权重进行算术加和（插值）。使用上述三种滤波函数对离散采样的信号进行重构的过程如下图所示：</p><p><img src="/images/sampling-theory/box_filter.png" /></p><p><img src="/images/sampling-theory/tent_filter.png" /></p><p><img src="/images/sampling-theory/sinc_filter.png" /></p><p>在所有滤波器中，<code>sinc function</code>最特别，它的频谱是无限的，理论上只要信号被充分采样，它就可以精确地重构原始信号。</p><h2 id="频域的观点">频域的观点</h2><p>根据奈奎斯特-香农采样定理，采样不足的时候我们无法完美重建原信号，要深入了解为何是这样，我们必须从频域的角度去考察采样是怎么一回事。假设一个带宽为B的函数<spanclass="math inline">\(f\)</span>，它的频域表示如下</p><p><img src="/images/sampling-theory/fx.png" /></p><p>按照采样频率<spanclass="math inline">\(f_s&gt;2B\)</span>对它进行采样，这些采样对应的信号在频域的表示会是这样的：</p><p><img src="/images/sampling-theory/sample_spectrum.png" /></p><div class="note note-info">            <p>采样在频域的表示为何是重复的呢？</p><p>时域采样得到的离散信号并不只代表这个时域信号，而是有无数多个频率不同的信号的采样结果是一样的，也就导致了频域上的周期延拓，这些频谱副本以采样频率的倍数重复。这里有详细的<ahref="https://www.projectrhea.org/rhea/index.php/2015_Fall_ECE_438_Boutin_A_visual_explanation_of_aliasing_and_repetition_with_the_DTFT_Erik_Swan">解释</a>。</p><p>一句话，采样就是重复原始信号的频谱。<br /><img src="/images/sampling-theory/repeat_spectrum.png" /></p><p>以下两者等价：</p><ol type="1"><li>原始信号(a)和冲激函数(c)相乘，得到离散的点(e)。</li><li>(a)的频谱(b)和(c)的傅里叶变换(d)，得到重复的频谱(f)。</li></ol>          </div><p>所谓信号重建就是要从这无数个频谱副本中选出一个正确的，然后变换到时域的过程。为了排除多出来的频谱副本，只留下原始信号对应的副本，我们可以在频域中应用一个宽度为B的<code>box function</code>，因为超出边框的部分直接为0，于是其他副本的影响就被消除了。<img src="/images/sampling-theory/hf.png" /></p><div class="note note-info">            <p>从这个角度看，滤波(filtering)就是滤掉特定频率的信息。</p><p>考虑如下原始图像及其频谱图。<br /><img src="/images/sampling-theory/origin.png" /></p><figure><img src="/images/sampling-theory/high_pass.png"alt="过滤低频信息(边缘)" /><figcaption aria-hidden="true">过滤低频信息(边缘)</figcaption></figure><figure><img src="/images/sampling-theory/low_pass.png"alt="过滤高频信息(模糊)" /><figcaption aria-hidden="true">过滤高频信息(模糊)</figcaption></figure>          </div><h2 id="走样的产生">走样的产生</h2><p>而采样不足时，会发生什么情况呢？前面提到，频谱副本以采样倍数的频率出现，于是采样率越高，它们之间的距离越远，采样率越低，它们之间的距离越近。当<spanclass="math inline">\(f_s&lt;2B\)</span>时，采样得到的信号在频域下的表示是这样的：</p><p><img src="/images/sampling-theory/aliasing.png" /></p><p>也就是频谱副本发生了重叠，这种情况发生之后我们再也无法完美隔离原信号的频谱，因此这种现象被形象地称为“混叠”（<code>Aliasing</code>），结果就是部分高频信号重叠在一起，并形成错误的低频信号。</p><p><img src="/images/sampling-theory/aliasing2.png" /></p><p>在计算机图形学中，我们从图像的直观表现来理解，<code>Aliasing</code>也称为走样/失真。</p><p>采样不足导致走样的后果就是，我们无法根据样本正确地还原出原始信号。特别的，对于没有有限带宽的信号，无论以多大的频率采样，总是会有走样产生，于是都不可能完美重构原始信号。</p><p>回过头来看3D渲染的整个过程，其实也可以看做是一个关于空间的连续函数，只是它更加复杂，包括场景的几何信息、阴影遮挡、光照、后处理等等，屏幕的像素点是对这个连续信号函数的离散采样，我们寄希望于屏幕显示出来的这些离散的像素点能忠实地还原连续世界的原貌。然而坏消息是，这个复杂的连续函数不是有限带宽函数，于是走样不可避免，而这本质上是一个欠采样的问题。</p><p>欠采样造成的<code>Aliasing</code>被称为<code>prealiasing</code>，因为它发生在重构之前，而重构本身也有可能引入artifacts。想象一下，如果我们在应用重建过滤器时使用一个过宽的<code>box function</code>，结果会是混入本不应存在高频信号：</p><p><img src="/images/sampling-theory/postaliasing.png" /></p><p>滤波器选择不当引入的Aliasing被称为<code>postaliasing</code>。</p><h2 id="反走样">反走样</h2><p>任何修正<code>prealiasing</code>和<code>postaliasing</code>的尝试都被广泛地归类为反走样，反走样技术大体分为三类。</p><p><strong>非均匀采样(Nonuniform Sampling)</strong></p><p>虽然图像函数具有无限带宽，因此不能从离散样本完全重建，但是通过以不均匀的方式改变样本之间的间距可以减少<code>Aliasing</code>的视觉影响。</p><p>对于不足以捕获原始信号函数的固定采样频率，均匀采样和非均匀采样都会产生不正确的重构信号。然而，非均匀采样倾向于将常规的<code>Aliasing</code>转化为噪声，这对人类视觉系统的干扰较小。在频域中，采样频谱的副本最终也是随机移动的，因此重构时的结果是一种随机误差而不是混叠。</p><p><strong>自适应采样(Adaptive Sampling)</strong></p><p>另一种反走样的方法是自适应超采样：如果我们能够识别出频率高于奈奎斯特极限的信号区域，我们就可以在这些区域采样额外的样本，而不是在任何地方都增加采样的计算开销。在实践中这种方法很难很好地工作，因为很难找到所有需要超采样的地方。大多数这样做的技术是基于检查相邻的样本值，并找到两者之间值有显著变化的地方，从而假设信号在该区域有高频率。</p><p>一般来说，相邻的样本值不能确切地告诉我们它们之间是否存在高频变化：即使这些值是相同的，函数也有可能在这些值之间存在巨大的变化。或者反之，即便相邻的样本实际上就是不同的值，但也并不意味着一定会发生<code>Aliasing</code>。</p><p><strong>预滤波(Prefiltering)</strong></p><p>另一种消除<code>Aliasing</code>的方法是滤波(即模糊)原始函数，消除给定采样率下无法被正确捕获的那些高频信号。这个方法在纹理采样中得到广泛的应用，虽然这种技术通过去除信息来改变被采样函数的特性，但模糊通常不如<code>Aliasing</code>那么令人反感。</p><h2 id="理解滤波函数">理解滤波函数</h2><p>当然在现实中，我们不会在频域进行滤波，而是在时域(或空域)，这意味着我们需要频域的<code>box function</code>在时域(或空域)的等价物，以下是几组时域滤波函数和它在频域的等价函数：</p><p><img src="/images/sampling-theory/box_to_sinc.png" /></p><p><em>Box Function -&gt; Sinc Function</em></p><p><img src="/images/sampling-theory/tent_to_sinc.png" /></p><p><em>Tent Function -&gt; (Sinc Function)^2</em></p><p><img src="/images/sampling-theory/gaussian.png" /></p><p><em>Gaussian Function -&gt; Gaussian Function</em></p><p><img src="/images/sampling-theory/sinc2_to_tent.png" /></p><p><em>(Sinc Function)^2 -&gt; Tent Function</em></p><p><img src="/images/sampling-theory/sinc_to_box.png" /></p><p><em>Sinc Function -&gt; Box Function</em></p><p>通过观察空域滤波函数在频域的等价函数，我们可以大致了解它将如何保持我们感兴趣的频率范围，并过滤掉无关的频谱副本。滤波器的设计主要是分析滤波器的频域谱，并用频域谱来评估或估计滤波器的整体性能。从上述图像我们可以看到，非<code>sinc function</code>都会以某种方式衰减基带频率，而频域的等价函数在频域上没有最大值，这意味着频域上的周期延拓会不可避免地渗入到重构的信号中（因为周期延拓是无限的），从而导致<code>Aliasing</code>。</p><p>通过观察空域滤波函数及其频域等价函数的图形，我们可以观察到一个普遍的模式，即二者的变化率存在着反比关系。考虑一下空域的<code>box function</code>，它在某个值处不连续，从而导致无限的变化率，因此它的频域等价函数是<code>sinc function</code>，后者延伸到整个x轴，这就是<code>box function</code>的不连续性带来的无限变化率（高频）。同样，空域的<code>sinc function</code>相当于频域的<code>box function</code>，因为它们之间的关系是互为倒数。高斯函数是一个特例，其中空域和频域的等价函数是一样的。由于这个原因，高斯函数代表了在空域和频域中处于缓慢变化和急剧变化的函数中间的一个折中（中庸函数）。</p><div class="note note-info">            <p>由于这种相反的关系，在时域做卷积等价于在频域做乘法。 两种做法：</p><ul><li>选项1：在时域做卷积</li><li>选项2<ol type="1"><li>变换到频域（傅里叶变换）</li><li>乘以卷积核的傅里叶变换形式</li><li>变换回时域（逆傅里叶变换）<br /><img src="/images/sampling-theory/transform.png" /></li></ol></li></ul>          </div><p>空域和频域的这种互为相反的关系带来了一个重要的特性，我们可以通过让滤波函数更宽，使得该函数得到的频谱更窄（直观理解就是时域中变化越平缓，频域中高频部分越少）。作为一个例子，看一下1.0宽度和4.0宽度的<code>box function</code>在频域下的区别：</p><p><img src="/images/sampling-theory/box1.png" /><br /><em>Frequency spectrum of a box function with width of 1.0</em></p><p><img src="/images/sampling-theory/box4.png" /><br /><em>Frequency spectrum of a box function with width of 4.0</em></p><p>滤波器设计的一个难点是，我们不仅要考虑滤波器的频域表示，还要考虑其空域表示对重构信号的影响。特别是，我们必须小心使用具有负波瓣的滤波器，例如<code>sinc filter</code>。这样的滤波器在应用于尖锐的不连续性时可以产生<ahref="https://en.wikipedia.org/wiki/Ringing_artifacts">ringingatrifact</a>（也称为<em>Gibb‘s</em>现象），即重建的信号在被采样的信号周围振荡。</p><h1 id="纹理映射">纹理映射</h1><p>采样理论一个最直观的应用就是图像缩放。图像或位图，是在二维网格上均匀分布的离散像素点对颜色信号进行采样的结果。为了缩放图像，我们需要在不同于原图像的采样点重新计算一个新的颜色。这个过程就是前面提到的重采样，或者说插值。最常见的插值模式是point（<code>nearest-neighbor</code>）和linear（<code>bilinear</code>），两种模式的背后都是应用了某种重建滤波器，point模式使用<code>box function</code>，bilinear模式使用<code>tent function</code>。</p><p><img src="/images/sampling-theory/texture_filtering.png" /></p><p><code>box function</code>的频域等效函数(<code>sinc function</code>)比<code>tent function</code>的频域等效函数(<spanclass="math inline">\(sinc^2 \spacefunction\)</span>)更平滑、更宽，这导致了更多的<code>postaliasing</code>。## cubic filter在3D渲染领域，缩放图像时也常用<code>cubic filter</code>（或者说<code>bicubic filters</code>）。<code>cubic filter</code>不是一个单一的滤波函数，而是包含了一组3次多项式插值滤波函数族。这些3次样条函数的特殊之处在于它们是<spanclass="math inline">\(C^1\)</span>连续的，因此也是<spanclass="math inline">\(C^0\)</span>连续的，作为平滑的连续函数，它们有利于减少<code>postaliasing</code>。另外，它们在过了某一点之后是0值，因此卷积的范围是有限的，通常<code>cubic filter</code>是在<spanclass="math inline">\([-2,2]\)</span>范围定义的函数，这是<code>tent function</code>的两倍宽度。最后，它们是在两个维度的卷积是可以分离计算的，因此减少了卷积需要采样的样本数，提高了性能。</p><p>在1988年这这篇论文<ahref="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.99.6947&amp;rep=rep1&amp;type=pdf">ReconstructionFilters in Computer Graphics</a>中，Don Mitchell 和 Arun Netravali系统地研究了<code>cubic filter</code>，并给出了基于两个参数B和C的广义定义形式。个函数族产生的滤波函数总是<spanclass="math inline">\(C^1\)</span>连续的，并且被归一化，使得曲线下面积等于1。</p><p><img src="/images/sampling-theory/cubic_function.png" /></p><p>以下是一些常见的3次曲线图：</p><p><img src="/images/sampling-theory/curves.png" /><br /><em>分别是：cubic(1, 0) AKA cubic B-spline, cubic(1/3, 1/3) AKA Mitchellfilter, cubic(0, 0.75) AKA Photoshop bicubic filter, and cubic(0, 0.5)AKA Catmull-Rom spline</em></p><p>使用这些函数对前面的棋盘图进行放大的效果如下：</p><p><img src="/images/sampling-theory/magnification.png" /></p><p>Mitchell论文中提到的一个关键点是，<code>sinc function</code>通常不适用于图像缩放，因为从本质上讲，图像的像素结构（离散值）会导致不连续性，从而导致无界频率。因此，理想的重建是不可能的，而且由于 <code>Gibb’s</code>现象，<code>ringing artifacts</code>将会发生。还有另外三种使用立方滤波器可能产生的负面效应是：<strong>混叠</strong>、<strong>模糊</strong>和<strong>各向异性</strong>。模糊被认为是由于高频衰减过多而造成的细节损失，通常是由于过宽的滤波器核引起；各向异性效应是由于将函数作为一个可分离的滤波器应用而产生的artifacts，其中得到的二维滤波函数最终并不是径向对称的。</p><p>Mitchell认为，单纯聚焦于频域不足以设计出一个良好的滤波器以产生符合人眼主观直觉的重建信号，而是强调在之前提到的4种artifacts中进行权衡取舍，而非仅关注<code>postaliasing</code>的量，只有这样才能设计一个高质量的滤波器用于图像缩放。</p><p>最终，Mitchell将B和C参数的范围划分为他所谓的“regions of dominantsubjectivebehavior”。在他的论文中，包括了下面的图表，显示了哪些artifacts与B和C参数的取值范围有关:</p><p><img src="/images/sampling-theory/cubic_area.png" /></p><p>根据他的分析，Mitchell确定(1/3,1/3)产生了最高质量的结果。由于这个原因，通常将这个函数称为<code>Mitchell filter</code>。</p><h2 id="mipmapping">mipmapping</h2><p>3D渲染经常会采样纹理然后在屏幕显示出来，但这些纹理不一定还保持原来的大小（像素数），而是经常被缩放、旋转以及投影，如何显示这些纹理在屏幕上占据的像素就是一个重采样问题。纹理采样最常见的滤波器是<code>linear filter</code>，当降采样时（缩小），源图像的高频信息会泄漏到降采样的版本中，表现为<code>temporal artifacts</code>：随着相机移动，纹理的内容会出现闪烁。在图像处理中，这个问题可以通过加大滤波器宽度来解决。但对于实时渲染来说，滤波器宽度增大带来的后果是，要访问的临近像素数量也会增大(<spanclass="math inline">\(O(N^2)\)</span>)，于是为了性能，我们选择了另外一条道路：mipmapping。</p><p>mipmaps由一系列预滤波的纹理组成，这些纹理被一个足够宽的能够防止降采样<code>Aliasing</code>的滤波核所采样，每个后续的mipmap是前一个mimap的一半宽度和高度，如下图所示。</p><p><img src="/images/sampling-theory/mipmaps.png" /></p><p>在运行时像素着色器通过计算纹理坐标的梯度，来选择一个合适的mipmap等级。梯度越小，说明样本挨得越近，因此需要较高的采样率，反之则需要较低的采样率。</p><div class="note note-info">            <p><code>mipmap level</code>需要在屏幕空间计算纹理坐标相对于x和y的导数，即相邻像素之间对应纹素的差距。计算过程是将屏幕坐标的点映射到uv平面上，然后计算出距离。取出最大的一个距离L，并计算<spanclass="math inline">\(log_2L\)</span>作为level，原图是0级，后面是1级，以此类推。</p><p><img src="/images/sampling-theory/mipmap_level.png" /></p><ol type="1"><li><p>考察相邻的纹理坐标，计算它们的距离。<br /><span class="math inline">\(\frac {du} {dx}=u_{10}-u_{00}\)</span> <spanclass="math inline">\(\frac {dv} {dx}=v_{10}-v_{00}\)</span><br /><span class="math inline">\(\frac {du} {dy}=u_{01}-u_{00}\)</span> <spanclass="math inline">\(\frac {dv} {dy}=v_{01}-v_{00}\)</span><br /><img src="/images/sampling-theory/mipmap_level2.png" /><br /></p></li><li><p>任取垂直或者水平的最大距离，取<spanclass="math inline">\(log_2\)</span>就得到了mipmap层级。<br />其含义就是如果uv平面中采样点离的很远，相应的<spanclass="math inline">\(\frac {du}{dx}\)</span>或其他的梯度就比较大，<spanclass="math inline">\(L\)</span>也相应的比较大。这种情况说明Minification了，单个像素覆盖了多个纹素。于是一个高级别的mipmap(更模糊的）就可以用来消除Aliasing，因为高级的单个纹素包括了低级的多个纹素（高频信息）。</p></li><li><p>然后就可以根据Lodlevel进行三线性插值，在两个mipmap层级间插值<br /><img src="/images/sampling-theory/mipmap_filter.png" /></p></li></ol><p>另外，为了自动获得梯度值，3D硬件总是以2x2像素(<code>quad-fragments</code>)为一组并行计算。<br /><img src="/images/sampling-theory/quad_fragment.png" /></p>          </div><p>使用 <code>mipmapping</code>并不能解决全部问题，还有一个常见问题是，当一个图像在一个维度中比在另一个维度中缩小更多时怎么办？这种情况被称为各向异性，因为纹理的u 轴和 v轴采样率不同。当一个轴的梯度大于另一个轴的梯度时，3D硬件将使用较大的梯度作为<code>mip level</code>，因为很显然，使用较小的梯度会由于欠采样而导致<code>Aliasing</code>，但对另外一个轴来说会有<code>over-filtering</code>的问题导致模糊。为了缓解这个问题，图形硬件支持各向异性异性采滤波（ <code>anisotropic filtering</code>）。当这个模式被激活时，硬件将沿着更大的梯度轴采样一定数量的“额外”纹理样本。</p><blockquote><p>各项异性采样在普通的mipmap计算基础上，还要考虑对角线的距离。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp">diag0 = (ddx - ddy).length;<br>diag1 = (ddx + ddy).length;<br><br>long_axis = <span class="hljs-built_in">max</span>(ddx, ddy, diag0, diag1);<br>minor_axis = <span class="hljs-built_in">min</span>(ddx, ddy, diag0, diag1);<br>ratio = long_axis / minor_axis;<br>lod = <span class="hljs-built_in">log2</span>(minor_axis);<br></code></pre></td></tr></table></figure> 按照长轴方向，采样ratio次，再累加平均。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs cpp">color = <span class="hljs-number">0</span>;<br>uv_i = <span class="hljs-number">0</span>;<br>long_axis_step = long_axis / ratio;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; ratio; ++i) &#123;<br>    uv_i += pixel.uv + i * long_axis_step;<br>    color += tex.<span class="hljs-built_in">SampleLevel</span>(lod, uv_i);<br>&#125;<br>color /= ratio;<br></code></pre></td></tr></table></figure></p></blockquote><h1 id="geometric-aliasing">Geometric Aliasing</h1><p>3D渲染中的第二种类型的<code>Aliasing</code>是几何走样，当一个由三角形组成的三维场景被栅格化时，这些三角形的可见性采样是像素离散化的。三角形可见性就像其他信号一样，当采样率不足时(在这种情况下，采样率由屏幕分辨率决定)，重构信号会产生<code>Aliasing</code>。不幸的是，三角形数据总是有不连续性，这意味着信号永远不会受到带宽限制，因此没有采样率可以足够高来防止走样。在实践中，这些artifacts表现为常见的锯齿状线条（简称“锯齿”），所谓抗锯齿指的就是这个问题。</p><p><img src="/images/sampling-theory/jaggies.png" /></p><p>既然锯齿来源于欠采样，那么加大采样率就可以解决这个问题，这相当于渲染的分辨率高于输出分辨率，然后再将渲染结果缩小到显示大小，这个方法被称为超级采样抗锯齿（<code>Supersampling Anti-Aliasing</code>，简称SSAA）。不过这个方法性能代价非常大，想象一下当今的3A游戏，中端甜点卡能在1080p分辨率下满特效流畅运行，而如果想在2160p下流畅运行，那么最高端的显卡也可能非常吃力。因此，一个简化版的SSAA被发明了出来，这就是多重采样抗锯齿（<code>MultiSampling Anti-Aliasing</code>，简称MSAA）。</p><h1 id="shading-aliasing">Shading Aliasing</h1><p>第三种类型的<code>Aliasing</code>被称为着色走样（<code>shading aliasing</code>），因为着色器是逐像素运行的，并且采样率固定（屏幕大小）。虽然着色器运行的程序可以是基于数学的平滑连续函数的解析解，但是采样却是离散的。最常见的一种欠采样是低粗糙度表面的镜面高光，较低的粗糙值导致较窄的波瓣，这使镜面高光成为高频信号，因此更容易欠采样，表现出来就是高光闪烁。</p><p>下面的图像包含了不同粗糙度的 <code>Blinn-Phong BRDF</code> 的 <spanclass="math inline">\(N \cdotH\)</span>（法线和半角向量的点积）响应图，展示了了它在低粗糙度下变得更高的频率:</p><p><img src="/images/sampling-theory/ndoth.png" /></p><p>着色走样最有可能发生在法线贴图使用时，因为它为法线带来了高频表现，从而导致镜面高光在表面上迅速变化。HDR渲染和基于物理的渲染模型可以进一步加剧这个问题，因为它们允许的亮度值范围更大。着色走样可能是最难解决的一种走样，目前为止还没有银弹解决方案，除了SSAA，但代价高昂。MSAA对此毫无帮助，因为像素着色采样率实际并没有增加。</p><h1 id="temporal-aliasing">Temporal Aliasing</h1><p>到目前为止，我们已经讨论了渲染中2D图像信号的采样。然而，我们还需要关注第三个维度，也就是时间。我们渲染的结果随着时间流逝表现为一个动画视频，也就说我们其实也在时域中进行采样，因为图像信号会随着时间的推移而完全改变。因此，我们必须考虑沿时间维度采样的问题，以及它如何产生走样。</p><p>在视频的情况下，我们仍然使用离散的样本，其中每个样本是一个代表某个时刻的场景的2D图像。这种采样与我们在空域的采样类似：我们采样的信号有一定的频率，如果我们采样不足，走样就会发生。时间走样的一个典型例子是所谓的”<ahref="https://en.wikipedia.org/wiki/Wagon-wheel_effect">车轮效应</a>”，是指在采样不足的视频流中，旋转的车轮转动看起来似乎较慢(甚至向后)的现象。</p><p><img src="/images/sampling-theory/wagonwheeleffect.gif" /></p><p>在游戏中，时间采样的artifacts通常表现为“断断续续”的动作和动画。帧率的增加相当于沿时域采样率的增加，这样可以更好地采样移动更快的内容。</p><p>时间走样最常用的反走样技术是运动模糊。运动模糊实际上是指一种摄影技术造成的效果，这是由于相机的快门打开后不马上关闭，而是刻意停留了一段时间，于是这段时间累积的光线都被记录了下来，如果有物体在运动，表现的结果就是模糊。</p><p>在3D渲染中，默认情况下我们得到的图像代表一个无限小的时刻。为了准确地模拟这种效果，我们可以在时域上进行超采样，通过渲染多帧，并对多帧图像进行滤波得到结果，当然这种做法需要对场景进行多次渲染才输出一帧，代价堪比SSAA。因此我们往往采用后处理方案来达到近似的效果：为当前帧产生每像素的速度缓冲，然后使用来自附近像素的多个纹理样本执行模糊操作，近似达到过采样的结果。这种做法的一个明显的artifact来源于几何遮挡信息的丢失，因为我们实际上还是在采样一个静态的画面，真正运动的画面，其几何遮挡信息是每时每刻都在变化的。</p><h1 id="参考">参考</h1><ol type="1"><li><ahref="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.99.6947&amp;rep=rep1&amp;type=pdf">ReconstructionFilters in Computer Graphics</a></li><li><ahref="https://mynameismjp.wordpress.com/2012/10/15/signal-processing-primer/">SIGNALPROCESSING PRIMER</a></li><li><ahref="https://mynameismjp.wordpress.com/2012/10/21/applying-sampling-theory-to-real-time-graphics/">APPLYINGSAMPLING THEORY TO REAL-TIME GRAPHICS</a></li><li><ahref="https://pbr-book.org/3ed-2018/Sampling_and_Reconstruction/Sampling_Theory">SamplingTheory</a></li><li><ahref="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Nyquist–Shannonsampling theorem</a></li><li><ahref="https://sites.cs.ucsb.edu/~lingqi/teaching/resources/GAMES101_Lecture_09.pdf">GAMES101:Shading3 (Texture Mapping cont.)</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Rendering</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rendering</tag>
      
      <tag>Math</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>刚体物理引擎实现之约束算解</title>
    <link href="/2022/04/04/constraint-resolve.html"/>
    <url>/2022/04/04/constraint-resolve.html</url>
    
    <content type="html"><![CDATA[<h1 id="约束constraints">约束(Constraints)</h1><p>约束就是模拟过程中必须遵守的规则，三维空间中的自由刚体有6个自由度：3个位置和3个转动;二维空间中的刚体有3个自由度：2个位置和1个转动，约束等于从这些自由度中做了一些削减。例如，将空间中的一个物体固定在其质心的约束使该物体的自由度减少了3：所有的位置自由度都被移除，因此该物体现在只能以3自由度旋转。</p><p>在一个基于约束的物理引擎中，我们将所有东西都建模为约束：包括碰撞触点、摩擦、弹簧、滑轮等等。</p><p>约束被定义为<strong>behavior function</strong>或者<strong>constraintfunction</strong>，用符号<spanclass="math inline">\(C\)</span>表示。它接收一个或者两个刚体的状态(位置、朝向等)作为输入，输出一个标量值。如果返回值在一个可接受的范围，那么约束就得到满足。在每一步模拟中，我们都要保证<spanclass="math inline">\(C\)</span>的返回值是可接受的。</p><h2 id="相等约束equality-constraints">相等约束(EqualityConstraints)</h2><p>相等约束就是<spanclass="math inline">\(C\)</span>的返回值只有0才是可接受的。</p><p>例子：假设在2D空间中有一个粒子，它的位置是<spanclass="math inline">\(p\)</span>，它的约束是和原点保持一个固定的距离<spanclass="math inline">\(l\)</span>，那么<spanclass="math inline">\(C\)</span>就是： <span class="math display">\[C(p)=\left \| p  \right \| - l\]</span></p><p>在这个例子中<spanclass="math inline">\(C\)</span>是一个包含两个变量(<spanclass="math inline">\(p_x,p_y\)</span>)的函数，假设<spanclass="math inline">\(l\)</span>为2，我们可以很容易画出<spanclass="math inline">\(C\)</span>的图像。</p><p><imgsrc="/images/constraint-resolve/constraint-hypersurface.png" /></p><p>显然，只有蓝色圈上的点才满足<spanclass="math inline">\(C=0\)</span>的约束条件，所有这些满足约束的点构成一个约束超平面(<strong>constrainthypersurface</strong>)。</p><p>绿色的箭头，显示了<spanclass="math inline">\(C\)</span>的梯度，它指向了<spanclass="math inline">\(C \neq0\)</span>的区域，不论沿着箭头前进还是后退都会导致约束不满足。</p><p>约束超平面的参数往往有多个，很多时候无法直观的画出图像，但是它们在本质上是一样的。</p><h2 id="非相等约束inequality-constraints">非相等约束(InequalityConstraints)</h2><p>常见的例子是刚体之间的<strong>non-penetrationconstraint</strong>，这个约束用来做刚体的碰撞算解，保证两个刚体不会相交。</p><p>考虑如下两个刚体</p><p><img src="/images/constraint-resolve/contact-constraint.png" /></p><p>假设碰撞点是<span class="math inline">\(P_A\)</span>和<spanclass="math inline">\(P_B\)</span>，则约束公式为： <spanclass="math display">\[C(p_A,\alpha_A,p_B,\alpha_B)=(P_B - P_A) \cdotn=(p_B+R(\alpha_B)r_B-p_A-R(\alpha_A)r_A) \cdot n\]</span></p><p>其中<spanclass="math inline">\(r_x\)</span>表示物体中心到碰撞点的向量，<spanclass="math inline">\(R(\theta)\)</span>表示旋转矩阵。公式右边是将两个碰撞点的向量转换到世界空间，相减之后再投影到碰撞法线<spanclass="math inline">\(n\)</span>，如果投影的长度<spanclass="math inline">\(\ge 0\)</span>，也就是说<spanclass="math inline">\(A\)</span>和<spanclass="math inline">\(B\)</span>依然保持分离的状态，没有撞到一起。</p><h1 id="force-based-dynamics">Force-Based dynamics</h1><p>直接修改<span class="math inline">\(p\)</span>的位置使得<spanclass="math inline">\(C=0\)</span>，往往会导致不真实的表现，有一种直观的算解是基于力的动力学(<strong>force-baseddynamics</strong>)，它计算出额外施加约束力使得物体满足约束的同时不打破牛顿定律。</p><p>因为对任意的自变量<spanclass="math inline">\(C=0\)</span>总是成立，所以<spanclass="math inline">\(C\)</span>的一阶导数（对时间<spanclass="math inline">\(t\)</span>求导）<spanclass="math inline">\(C&#39;=0\)</span>，进一步<spanclass="math inline">\(C\)</span>的二阶导数<spanclass="math inline">\(C&#39;&#39;=0\)</span>也成立。回到最开始的相等约束那个例子，我们先用距离的平方的形式改写<spanclass="math inline">\(C\)</span>： <span class="math display">\[C=\frac 1 2 (p \cdot p-l^2)\]</span> 这个新函数依然满足位置和原点的距离是<spanclass="math inline">\(l\)</span>的约束，同时它的一阶导数是： <spanclass="math display">\[\begin{align}C&#39;=&amp;(\frac 1 2 (p_xp_y+p_xp_y))&#39;\\=&amp; \frac 1 2 (p_xp_y)&#39;+ \frac 1 2 (p_xp_y)&#39;\\=&amp; \frac 1 2 (p_x&#39;p_y+p_xp_y&#39;)+\frac 1 2(p_x&#39;p_y+p_xp_y&#39;)\\=&amp; p_x&#39;p_y+p_xp_y&#39;\\=&amp; p \cdot p&#39;\\\end{align}\]</span></p><p>其中<span class="math inline">\(p&#39;\)</span>是位置对时间<spanclass="math inline">\(t\)</span>求导，也就是速度<spanclass="math inline">\(v\)</span>，任何满足<span class="math inline">\(p\cdot v=0\)</span>的<spanclass="math inline">\(v\)</span>都是合法的速度。在这个例子中，只有和超平面(圆环)相切的速度才是合法值。<spanclass="math inline">\(C\)</span>的二阶导数是： <spanclass="math display">\[C&#39;&#39;=p&#39;&#39; \cdot p + p&#39; \cdot p&#39;\]</span></p><p><span class="math inline">\(p&#39;&#39;\)</span>就是加速度<spanclass="math inline">\(a\)</span>，所有满足<spanclass="math inline">\(C&#39;&#39;\)</span>的<spanclass="math inline">\(a\)</span>都是合法加速度。在这个例子中，只有相对原点朝内或者朝外的加速度才是合法值。</p><p>我们可以用力来表示加速度。假设所有的外力是<spanclass="math inline">\(f_{ext}\)</span>，为了保证约束，我们需要额外施加的约束力是<spanclass="math inline">\(f_C\)</span>，同时粒子有质量<spanclass="math inline">\(m\)</span>，那么加速度是： <spanclass="math display">\[a=p&#39;&#39;=\frac {f_{ext}+f_C} m\]</span> 代换到<span class="math inline">\(C&#39;&#39;\)</span>之中：<span class="math display">\[\frac {f_{ext}+f_C} m \cdot p + p&#39; \cdot p&#39;=0\]</span></p><p>整理一下可得： <span class="math display">\[f_C \cdot p=-f_{ext} \cdot p - mp&#39; \cdot p&#39;\]</span></p><p>这是一个包含两个未知量（<spanclass="math inline">\(f_C\)</span>的<spanclass="math inline">\(x\)</span>和<spanclass="math inline">\(y\)</span>分量）的方程，为了解这个方程，我们还需要引入另外一个条件。</p><p>直观上我们知道，为了保证物体和原点的距离是<spanclass="math inline">\(l\)</span>，它在这个方向的速度分量必须是<spanclass="math inline">\(0\)</span>，同时约束力总是和圆的运动轨迹垂直，因此约束力和速度必然是垂直的，于是：<span class="math display">\[f_C \cdot p&#39;=0\]</span></p><p><span class="math inline">\(C\)</span>的一阶导告诉我们<spanclass="math inline">\(p \cdot p&#39;=0\)</span>，现在又有了<spanclass="math inline">\(f_C \cdot p&#39;=0\)</span>，因此<spanclass="math inline">\(f_C\)</span>和<spanclass="math inline">\(p\)</span>都和<spanclass="math inline">\(p&#39;\)</span>是正交的，从而<spanclass="math inline">\(f_C\)</span>和<spanclass="math inline">\(p\)</span>平行，于是我们可以得到一个简洁的公式：<span class="math display">\[f_C=\lambda p\]</span> <spanclass="math inline">\(\lambda\)</span>就是约束力的强度，只要我们额外施加这么大的力那么就能保证约束<spanclass="math inline">\(C\)</span>得到满足。将<spanclass="math inline">\(\lambda\)</span>带入二阶导推出的公式可得： <spanclass="math display">\[\lambda = \frac {-f_{ext} \cdot p - mp&#39; \cdot p&#39;} {p \cdot p}\]</span></p><p><spanclass="math inline">\(\lambda\)</span>被称为拉格朗日乘子(<strong>Lagrangemultiplier</strong>)，对于任何的约束算解都包含了一个力方向和它的<spanclass="math inline">\(\lambda\)</span>。</p><h2 id="施加约束力的步骤">施加约束力的步骤</h2><p>回顾一下前面的推导过程，我们可以总结出一般的计算约束力的步骤：</p><ol type="1"><li>计算外力<span class="math inline">\(f_{ext}\)</span>。</li><li>计算约束力<span class="math inline">\(f_C\)</span>。</li><li>应用所有的力，按照牛顿力学模拟。</li></ol><h2 id="约束系统">约束系统</h2><p>真实的物理模拟必须考虑许多对象的多个约束同时得到满足，约束不能单独处理，因为一个约束施加的力可能会影响另一个约束施加的力。在<strong>force-basedynamics</strong>下我们必须使用向量和矩阵一次性算解所有的约束，而且包括平动和转动。</p><h3 id="状态向量">状态向量</h3><p>假设<span class="math inline">\(q\)</span>表示所有刚体的状态向量：<span class="math display">\[q=\begin{bmatrix} p_1 \\ \alpha_1 \\ p_2 \\ \alpha_2 \\ \vdots \\ p_n \\\alpha_n \end{bmatrix}=\begin{bmatrix} q_1 \\ q_2 \\ \vdots \\ q_n\end{bmatrix}\]</span> 其中，<span class="math inline">\(p\)</span>是位置，<spanclass="math inline">\(\alpha\)</span>是旋转（2D情况下是<spanclass="math inline">\(2 \times 1\)</span>的列向量，3D情况下是<spanclass="math inline">\(3\times 1\)</span>的列向量）。<spanclass="math inline">\(q\)</span>是关于时间<spanclass="math inline">\(t\)</span>的函数，对其求一阶导就得到一个包含线速度和角速度的速度矢量：<span class="math display">\[\overrightarrow v=\frac{\partial q }{\partial t}=\begin{bmatrix}\overrightarrow v_1 \\ \overrightarrow \omega_1 \\ \overrightarrow v_2\\ \overrightarrow \omega_2 \\ \vdots \\ \overrightarrow v_n \\\overrightarrow \omega_n \end{bmatrix}\]</span> 其二阶导就是加速度<span class="math inline">\(a\)</span>。</p><h3 id="牛顿第二定律">牛顿第二定律</h3><p><spanclass="math inline">\(M\)</span>是质量矩阵，它是如下的对角矩阵： <spanclass="math display">\[M=\begin{bmatrix} M_1 &amp; &amp; &amp; &amp; &amp; &amp; \\ &amp; I_1&amp; &amp; &amp; &amp; &amp; \\ &amp; &amp; M_2 &amp; &amp; &amp; &amp;\\ &amp; &amp; &amp; I_2 &amp; &amp; &amp; \\  &amp; &amp; &amp; &amp;\ddots &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; M_n &amp;\\ &amp;&amp; &amp; &amp; &amp; &amp; I_n \end{bmatrix}\]</span></p><p>其中<span class="math inline">\(I_n\)</span>是转动惯量，<spanclass="math inline">\(M_n\)</span>是质量（2D情况下每个<spanclass="math inline">\(M_n\)</span>都是2x2的对角矩阵，比如<spanclass="math inline">\(M_1 = {\left[ {\begin{array}{ccc} m_1 &amp; 0 \\ 0&amp; m_1 \\ \end{array} } \right]}\)</span>，3D以此类推）。<spanclass="math inline">\(M\)</span>的逆矩阵是： <spanclass="math display">\[M=\begin{bmatrix} M_1^{-1} &amp; &amp; &amp; &amp; &amp; &amp; \\ &amp;I_1^{-1} &amp; &amp; &amp; &amp; &amp; \\ &amp; &amp; M_2^{-1} &amp;&amp; &amp; &amp; \\ &amp; &amp; &amp; I_2^{-1} &amp; &amp; &amp;\\  &amp; &amp; &amp; &amp; \ddots &amp; &amp; \\ &amp; &amp; &amp;&amp; &amp; M_n^{-1} &amp;\\ &amp; &amp; &amp; &amp; &amp; &amp;I_n^{-1} \end{bmatrix}\]</span></p><p><span class="math inline">\(F\)</span>是合力 <spanclass="math display">\[F=F_{ext}+F_C=\begin{bmatrix} f_1 \\ \tau_1 \\ f_2 \\ \tau_2 \\ \vdots\\ f_n \\ \tau_n \end{bmatrix}\]</span> 其中<span class="math inline">\(\tau\)</span>是力矩。</p><p>根据牛顿第二定律，可得： <span class="math display">\[a=q&#39;&#39;=M^{-1}F=M^{-1}(F_{ext}+F_C)\]</span></p><h3 id="约束">约束</h3><p>假设约束有<span class="math inline">\(m\)</span>个，则约束函数<spanclass="math inline">\(C(q)\)</span>为： <span class="math display">\[C(q)=\begin{bmatrix} C_1(q) \\ C_2(q) \\ \vdots \\ C_m(q) \end{bmatrix}\]</span></p><p>我们希望<spanclass="math inline">\(C(q)\)</span>的输出，越接近0越好。</p><h3 id="c的导数">C的导数</h3><p><span class="math inline">\(C\)</span>对时间<spanclass="math inline">\(t\)</span>求导，根据链式法则我们有： <spanclass="math display">\[\frac{\mathrm{d} C }{\mathrm{d} t}=\frac{\mathrm{d} C}{\mathrm{d}q}\overrightarrow v\]</span></p><p>我们定义<spanclass="math inline">\(C\)</span>的雅克比矩阵(<strong>JacobianMatrix</strong>)为： <span class="math display">\[J=\frac{\mathrm{d} C}{\mathrm{d} q}\]</span> 雅克比矩阵是梯度的推广，它告诉我们针对每个状态的改变，<spanclass="math inline">\(C\)</span>会如何变化： <spanclass="math display">\[J=\begin{bmatrix} \frac{\partial C_1}{\partial q_1} &amp; \frac{\partialC_1}{\partial q_2} &amp; \cdots &amp; \frac{\partial C_1}{\partial q_n}\\  \frac{\partial C_2}{\partial q_1} &amp; \frac{\partial C_2}{\partialq_2} &amp; \cdots &amp; \frac{\partial C_2}{\partial q_n}\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\ \frac{\partial C_m}{\partial q_1} &amp; \frac{\partial C_m}{\partialq_2} &amp; \cdots &amp; \frac{\partial C_m}{\partial q_n}\end{bmatrix}\]</span></p><p><span class="math inline">\(J\)</span>的每一行就是<spanclass="math inline">\(\overrightarrow v\)</span>的各个分量的系数： <spanclass="math display">\[\frac{\mathrm{d} C }{\mathrm{d} t}={J}\overrightarrow v\]</span></p><p>在只考虑碰撞约束的例子中<spanclass="math inline">\(J\)</span>是一个稀疏矩阵，因为每个约束最多包含两个刚体（两两碰撞）。</p><p><span class="math inline">\(C\)</span>的二阶导是： <spanclass="math display">\[C&#39;&#39;=J&#39;q&#39;+Jq&#39;&#39;\]</span> 根据牛顿第二定律（加速度<span class="math inline">\(a=\frac FM\)</span>)，我们有： <span class="math display">\[C&#39;&#39;=J&#39;q&#39;+JM^{-1}(F_{ext}+F_C)\]</span></p><h3 id="计算约束力">计算约束力</h3><p>我们希望<span class="math inline">\(C&#39;&#39;=0\)</span>，因此：<span class="math display">\[JM^{-1}F_C=-J&#39;q&#39;-JM^{-1}F_{ext}\]</span></p><p>我们知道约束力和速度正交，因此： <span class="math display">\[F^T_C q&#39;=0\]</span></p><p>我们同样希望<span class="math inline">\(\frac{\mathrm{d} C}{\mathrm{d} t}=0\)</span>，因此： <span class="math display">\[Jq&#39;=0\]</span> 于是我们得到： <span class="math display">\[F_C=J^T \lambda\]</span></p><p><span class="math inline">\(\lambda\)</span>有<spanclass="math inline">\(m\)</span>个分量，设为<spanclass="math inline">\(\lambda_i\)</span>，<spanclass="math inline">\(J\)</span>的行向量设为<spanclass="math inline">\(\Delta C_i\)</span>，则： <spanclass="math display">\[F_C=J^T \lambda=\Delta C_1 \lambda_1 + \Delta C_2 \lambda_2 + \cdots +\Delta C_m \lambda_m\]</span> <span class="math inline">\(F_C\)</span>是<spanclass="math inline">\(J\)</span>矩阵的行向量的线性组合，而<spanclass="math inline">\(J\)</span>的行向量是约束函数的梯度。虽然这个公式比较复杂，但本质上和之前那个简单例子一样：梯度正交于约束超平面，并且是不允许移动的方向。也就是说，这个线性组合的向量，指向被禁止的方向，额外的约束力将只存在于这些方向，最终使得系统满足各种约束。</p><p>现在我们还不知道<spanclass="math inline">\(\lambda\)</span>各个分量的大小，我们需要把<spanclass="math inline">\(J^T\lambda\)</span>带入之前的公式： <spanclass="math display">\[JM^{-1}F_C=-J&#39;q&#39;-JM^{-1}F_{ext}\]</span> 得到一个关于<spanclass="math inline">\(\lambda\)</span>线性方程组，线性方程组有很多解法，一旦我们得到了<spanclass="math inline">\(\lambda_i\)</span>我们就解算出了约束力<spanclass="math inline">\(F_C\)</span>。 # Sequential Impulses冲量(<strong>Impulse</strong>)是力对时间的积分： <spanclass="math display">\[P=\int F dt\]</span> 等价于动量的变化量。</p><p>一个常量的力<span class="math inline">\(F\)</span>，累计作用<spanclass="math inline">\(h\)</span>时间的冲量为： <spanclass="math display">\[P = hF\]</span>当两个刚体碰撞时，接触时间非常短暂（无限接近于0），在此期间有一个互斥的力，使得它们的速度剧烈变化。</p><p>顺序冲量(<strong>SequentialImpulses</strong>)通过找出满足约束的冲量从而直接改变速度，而非通过添加约束力的方式来满足约束，这个方案由著名的Box2D 的作者 Erin Catto提出并推广。和<code>Force-Based dynamics</code>不同，它属于<code>Impluse-Based Dynamics</code>，它不需要构造一个一次性的解决方案（一个巨大的线性方程组）。它只要每次处理一个单独的约束，并遍历全部的约束，如此循环下去，直到<spanclass="math inline">\(C&#39;\)</span>接近0或者循环次数到达上限。</p><p>相对于基于力的方法，它最大的优点是算法相对简单，也更容易直观地理解。在大多数情况下，它还具有更高的计算效率，这使得它比基于力的方法得到更广泛的应用。</p><p>步骤：</p><ol type="1"><li>使用semi-implicit欧拉积分模拟，得到速度，这些速度可能违反约束条件。</li><li>顺序应用冲量到每个约束，使得约束条件满足，直到冲量足够小或者最大迭代次数到达上限。</li><li>使用新的速度模拟。</li></ol><h2 id="计算速度">计算速度</h2><p>设<span class="math inline">\(\overrightarrowv_f\)</span>是要求的当前时刻的速度矢量，<spanclass="math inline">\(\overrightarrowv_{i}\)</span>是前一时刻的速度矢量，则未约束的速度为： <spanclass="math display">\[\overrightarrow v^*_f=\overrightarrow v_{i}+\Delta tM^{-1}F_{ext}\]</span></p><p>设<spanclass="math inline">\(P_C\)</span>是约束冲量，将其除以质量，我们可以得到速度的变化量，然后将这个变化量加到未约束的速度上，得到满足约束的速度。<span class="math display">\[\begin{align}\overrightarrow v_f=&amp;{\overrightarrow v^*_f} + M^{-1}P_C\\=&amp;\overrightarrow v_{i}+\Delta tM^{-1}F_{ext}+M^{-1}P_C\end{align}\]</span></p><p>如何得到<spanclass="math inline">\(P_C\)</span>呢？我们知道冲量和瞬时的力的方向一致，我们再次利用约束力必须和<spanclass="math inline">\(C\)</span>的梯度平行的事实，于是： <spanclass="math display">\[P_C=J^T\lambda\]</span> 我们知道冲量是力对时间的累积，因此也可以写成<spanclass="math inline">\(P_C=\Delta t M^{-1} F_C\)</span>，于是： <spanclass="math display">\[\begin{align}\overrightarrow v_f&amp;=\overrightarrow v_i+ \Delta t M^{-1} F_{ext} +\Delta t {M}^{-1} F_C\\&amp;=\overrightarrow v_i+ \Delta t M^{-1}( F_{ext} + F_C)\end{align}\]</span> 因为<spanclass="math inline">\(F_C\)</span>是我们要设定的一个值，我们可以完全把<spanclass="math inline">\(F_{ext}\)</span>的影响包含在<spanclass="math inline">\(F_C\)</span>内，因此不妨把<spanclass="math inline">\(F_{ext}\)</span>去掉，只用<spanclass="math inline">\(F_C\)</span>代替，于是： <spanclass="math display">\[\begin{align}\overrightarrow v_f&amp;=\overrightarrow v_i+ \Delta t M^{-1} F_C\\&amp;=\overrightarrow v_i+ M^{-1} P_C\\&amp;=\overrightarrow v_i+ M^{-1} J^T \lambda\end{align}\]</span></p><p>基于冲量的方案，略过了牛顿第二定律对力和加速度的计算，它会直接产生一个瞬时速度，有可能会让模拟失真。为了解决这个问题，我们引入一个bias，来减少影响：<span class="math display">\[\frac{\mathrm{d} C }{\mathrm{d} t}=J\overrightarrow v_f+b=0\]</span></p><p>将之前的公式带入这个等式，可得： <span class="math display">\[\begin{align}J(\overrightarrow v_i+ M^{-1} J^T \lambda) + b &amp;= 0\\JM^{-1}J^T\lambda &amp;= -(J{\overrightarrow v_i}+b) \\\lambda &amp;=\frac {-(J{\overrightarrow v_i}+b)} {JM^{-1}J^T}\end{align}\]</span></p><p>其中<spanclass="math inline">\(JM^{-1}J^T\)</span>被称为有效质量（<code>Effective Mass</code>）。</p><p>不妨把<span class="math inline">\(M^{-1} J^T\lambda\)</span>看做是一个速度的变化量<spanclass="math inline">\(\overrightarrow \Delta v\)</span>，于是<spanclass="math inline">\(J(\overrightarrow v_i+ \overrightarrow \Delta v) +b = 0\)</span>，而<span class="math inline">\(\overrightarrow \Deltav\)</span>和<spanclass="math inline">\(M^{-1}J^T\)</span>成比例，比例系数就是<spanclass="math inline">\(\lambda\)</span>（<strong>拉格朗日乘子</strong>）。只要解开<spanclass="math inline">\(\lambda\)</span>，我们就可以通过<spanclass="math inline">\(P_C=J^T\lambda\)</span>得到约束冲量，从而更新速度<spanclass="math inline">\(\overrightarrow v_f\)</span>。</p><p>如果我们在物理系统中有多个约束，那么我们只需在所有约束条件下迭代重复这个过程，系统就会收敛到一个全局解。</p><h2 id="同时解决多个约束">同时解决多个约束</h2><p>为了稳定性考虑，有时候多个约束也可以被同时解决，比如<code>prismatic joint</code>，我们需要一次性解决距离和旋转约束，而不能分开处理。</p><p>这个时候雅克比行列式就变成了一个2x12的矩阵，而<spanclass="math inline">\(\lambda\)</span>求值公式就变成了: <spanclass="math display">\[\lambda = (JM^{-1}J^T)^{-1}(-J\overrightarrow v_i-b)\]</span> 此时<spanclass="math inline">\(JM^{-1}J^T\)</span>不是一个标量，而是一个2x2矩阵，而<spanclass="math inline">\(\lambda\)</span>也不是标量，它变成了一个2x1的矩阵。</p><p>不过<span class="math inline">\(\Deltav\)</span>的维度还是不变，因为<spanclass="math inline">\(M^{-1}J^T\lambda\)</span>依然是一个12x1矩阵。</p><h2 id="直观理解">直观理解</h2><h3 id="投影的类比">投影的类比</h3><p>应用约束的迭代过程，有点像把某个点（状态）移动到给定的平面（约束超平面）的过程。我们知道平面方程：<span class="math display">\[ax+by+cz+d=0\]</span> 如果点<spanclass="math inline">\(P\)</span>在平面外，那么<spanclass="math inline">\(ax+by+cz+d \neq 0\)</span>，将<spanclass="math inline">\(P\)</span>点带回到平面的最快方式是，让<spanclass="math inline">\(P\)</span>沿着平面法线<spanclass="math inline">\((a,b,c)\)</span>投影到平面上。从线性方程的角度看，平面方程可以写成：<span class="math display">\[NP+d=0\]</span> <span class="math inline">\(N\)</span>表示平面法线，<spanclass="math inline">\(P\)</span>是任意点。</p><p>为了让<spanclass="math inline">\(P\)</span>投影（回）到平面上，我们对<spanclass="math inline">\(P\)</span>施加改变量<spanclass="math inline">\(\Delta P\)</span>，这个改变量和法线<spanclass="math inline">\(N^T\)</span>是成比例的（方向一致，大小不确定，可正可负）。</p><p>这等价于速度矢量的改变量<span class="math inline">\(\Deltav\)</span>，它是沿着<spanclass="math inline">\(J^T\)</span>（约束超平面的法线）的。但是，不同的刚体有不同的质量和转动惯量，我们不能统一的应用这个改变量到所有的刚体上，因此<spanclass="math inline">\(J^T\)</span>需要被质量矩阵<spanclass="math inline">\(M\)</span>修正：<spanclass="math inline">\(M^{-1}J^T\)</span>。</p><p>应用<code>Sequential Impulse</code>的过程就是不断将<spanclass="math inline">\(\overrightarrowv\)</span>投影到约束超平面的过程，如果各个约束没有矛盾，那么我们会到的一个全局解。反过来，如果存在矛盾的约束，那么我们永远不可能得到一个全局解，就好比多个平面如果没有公共交点，那我们永远也找不到那个公共交点。</p><h3 id="空间变换的类比">空间变换的类比</h3><p>把雅克比矩阵看做坐标变换矩阵：</p><ul><li>类似旋转矩阵</li><li>但是少了一些行，因此它将某些维度变成0</li><li>转置少了一些列，因此某些维度被加了进来</li></ul><h4 id="速度变换">速度变换</h4><p><span class="math inline">\(\frac{\mathrm{d} C }{\mathrm{d}t}=Jv\)</span>等价于把速度<spanclass="math inline">\(v\)</span>从笛卡尔空间的速度变换到约束空间的速度</p><p><img src="/images/constraint-resolve/jv-trans.png" /></p><h4 id="力变换">力变换</h4><p><span class="math inline">\(F_C=J^T\lambda\)</span>等价于把<spanclass="math inline">\(\lambda\)</span>从约束空间的力变换到笛卡尔空间的力</p><p><img src="/images/constraint-resolve/fc-trans.png" /></p><h2 id="碰撞约束">碰撞约束</h2><h3 id="推导j">推导J</h3><p><img src="/images/constraint-resolve/contact.png" /></p><p>考虑如上的碰撞，碰撞点是<spanclass="math inline">\(P_A\)</span>和<spanclass="math inline">\(P_B\)</span>，刚体的质心是<spanclass="math inline">\(C_A\)</span>和<spanclass="math inline">\(C_B\)</span>，这两个都应该被看做连续变化的量。除了位移以外，我们还要考虑旋转，为此引入<spanclass="math inline">\(r_A\)</span>和<spanclass="math inline">\(r_B\)</span>，它们是质心到碰撞点的向量，这也是连续变化的量（被转动影响）。<spanclass="math inline">\(n\)</span>是从<spanclass="math inline">\(A\)</span>指向<spanclass="math inline">\(B\)</span>的碰撞法线，<spanclass="math inline">\(t_1\)</span>和<spanclass="math inline">\(t_2\)</span>是碰撞切线，其中<spanclass="math inline">\(t_2\)</span>指向屏幕内。</p><p>刚体碰撞约束就是要让穿透深度为0，于是存在一个位置约束：从<spanclass="math inline">\(P_A\)</span>指向<spanclass="math inline">\(P_B\)</span>的向量必须和<spanclass="math inline">\(n\)</span>的方向一致(两个向量的点积就是穿透深度，必须&gt;=0)。我们有：<span class="math display">\[\begin{align}P_A=&amp;C_A+\overrightarrow r_A\\P_B=&amp;C_B+\overrightarrow r_B\end{align}\]</span></p><p>所以位置约束<span class="math inline">\(C\)</span>是： <spanclass="math display">\[\begin{align}C:&amp;(P_B-P_A) \cdot \overrightarrow n \ge 0 \\C:&amp;(C_B+\overrightarrow r_B-C_A-\overrightarrow r_A) \cdot\overrightarrow n \ge 0\end{align}\]</span></p><p><span class="math inline">\(C\)</span>对时间<spanclass="math inline">\(t\)</span>求导得到： <span class="math display">\[C&#39;:(-\overrightarrow V_A-\overrightarrow \omega_A \times\overrightarrow r_A + \overrightarrow V_B+\overrightarrow \omega_B\times \overrightarrow r_B) \cdot \overrightarrow n \ge 0\]</span></p><p>利用三重积，整理公式，我们可以得到 <span class="math display">\[C&#39;:JV+b \ge 0\]</span> 其中 $$ <span class="math display">\[\begin{align}J&amp;=\begin{bmatrix} -\overrightarrow n^T &amp; (-\overrightarrow r_A\times \overrightarrow n)^T &amp; \overrightarrow n^T &amp;(\overrightarrow r_B \times \overrightarrow n)^T \end{bmatrix}\\V&amp;=\begin{bmatrix} \overrightarrow{V_A} \\ \overrightarrow{\omega_A}\\ \overrightarrow{V_B} \\ \overrightarrow{\omega_B}  \end{bmatrix} \\b&amp;=0\end{align}\]</span> $$</p><p>注意我们得到的是<span class="math inline">\(JV+b \ge0\)</span>，而非<span class="math inline">\(JV+b =0\)</span>。这意味着当两个刚体没有穿透的时候约束显然得到保证，当发生穿透的时候，要保证<spanclass="math inline">\(JV+b=0\)</span>。</p><p>上述推导的速度约束在几何上的解释是：<strong>两个碰撞点的相对速度在碰撞法线上的投影长度为0</strong>。因此只要我们解决了这个约束，两个碰撞点就不会穿透得更深了。</p><h3 id="计算λ">计算λ</h3><p>我们现在要求的是速度的约束增量<span class="math inline">\(\DeltaV=M^{-1}J^T\lambda\)</span>，其中<spanclass="math inline">\(\lambda\)</span>是: <span class="math display">\[\lambda=\frac {-(JV+b)} {JM^{-1}J^T}\]</span> 展开<span class="math inline">\({JM^{-1}J^T}\)</span>： <spanclass="math display">\[\begin{align}JM^{-1}J^T=&amp;\begin{bmatrix} -\overrightarrow n^T &amp;(-\overrightarrow r_A \times \overrightarrow n)^T &amp; \overrightarrown^T &amp; (\overrightarrow r_B \times \overrightarrow n)^T \end{bmatrix}\begin{bmatrix}M_A^{-1} &amp; 0 &amp; 0 &amp; 0 \\0 &amp; I_A^{-1} &amp; 0 &amp; 0 \\0 &amp; 0 &amp; M_B^{-1} &amp; 0 \\0 &amp; 0 &amp; 0 &amp; I_B^{-1}\end{bmatrix}\begin{bmatrix} -\overrightarrow n \\ (-\overrightarrow r_A \times\overrightarrow n) \\ \overrightarrow n \\ (\overrightarrow r_B \times\overrightarrow n) \end{bmatrix}  \\=&amp;\begin{bmatrix} -\overrightarrow n^T &amp; (-\overrightarrow r_A\times \overrightarrow n)^T &amp; \overrightarrow n^T &amp;(\overrightarrow r_B \times \overrightarrow n)^T \end{bmatrix}\begin{bmatrix}-M_A^{-1} \overrightarrow n \\-I_A^{-1} (\overrightarrow r_A \times \overrightarrow n) \\-M_B^{-1} \overrightarrow n \\-I_B^{-1} (\overrightarrow r_B \times \overrightarrow n)\end{bmatrix} \\=&amp;\overrightarrow n^T M_A^{-1} \overrightarrow n +(\overrightarrow r_A \times \overrightarrow n)^T I_A^{-1}(\overrightarrow r_A \times \overrightarrow n) +\overrightarrow n^T M_B^{-1} \overrightarrow n +(\overrightarrow r_B \times \overrightarrow n)^T I_B^{-1}(\overrightarrow r_B \times \overrightarrow n)\\=&amp;m_a^{-1}+ I_A^{-1} (\overrightarrow r_A \times \overrightarrow n)\cdot (\overrightarrow r_A \times \overrightarrow n) + m_b^{-1}+I_B^{-1} (\overrightarrow r_B \times \overrightarrow n) \cdot(\overrightarrow r_B \times \overrightarrow n)\end{align}\]</span> 对于<spanclass="math inline">\(JV\)</span>，利用三重积变换公式，最终得到的就是<spanclass="math inline">\(B\)</span>和<spanclass="math inline">\(A\)</span>在法线的相对速度。 <spanclass="math display">\[\begin{align}JV=&amp;\begin{bmatrix} -\overrightarrow n^T &amp; (-\overrightarrow r_A\times \overrightarrow n)^T &amp; \overrightarrow n^T &amp;(\overrightarrow r_B \times \overrightarrow n)^T \end{bmatrix}\begin{bmatrix} \overrightarrow{V_A} \\ \overrightarrow{\omega_A} \\\overrightarrow{V_B} \\ \overrightarrow{\omega_B}  \end{bmatrix} \\=&amp;-V_A \cdot n - (r_A \times n)\cdot \omega_A + V_B \cdot n + (r_B\times n)\cdot \omega_B \\=&amp;-V_A \cdot n - (\omega_A \times r_A)\cdot n + V_B \cdot n +(\omega_B \times r_B)\cdot n \\=&amp;( V_B + (\omega_B \times r_B) - (V_A + (\omega_A \timesr_A)))\cdot n\end{align}\]</span></p><p>记住在循环中，我们每次只处理一个约束，然后立即修改刚体的速度，这个修改会影响同一个刚体后续的算解，某些情况下单次算解的速度反而会让这个刚体和其他刚体碰撞的更深。因此，我们需要对算解的速度差做一个截断，也就是我们要保证在整个算解过程中下述不等式得到满足：<span class="math display">\[\sum \lambda_i \ge 0\]</span></p><p><span class="math inline">\(\lambda_i\)</span>是第<spanclass="math inline">\(i\)</span>次循环的拉格朗日乘子。</p><p>每次我们对一个碰撞计算出<spanclass="math inline">\(\lambda\)</span>，我们先拷贝一份之前的值，然后将<spanclass="math inline">\(\lambda\)</span>加到旧值，并截取到<spanclass="math inline">\([0,+\infty]\)</span>，然后计算它和拷贝值的差，这个差值才是我们实际要用来解决约束的<spanclass="math inline">\(\lambda\)</span>。</p><h3 id="baumgarte-stabilization">Baumgarte Stabilization</h3><p>只是算解出速度约束还不够，它只能避免碰撞不再继续深入，但不能分开两个已经有碰撞穿透的刚体，累积的误差还会导致“位置抖动”问题。</p><p>我们需要引入<code>Baumgarte Stabilization</code>。基本想法是把穿透深度(可以看做是一个位置错误的量)，作为一个bias塞回速度约束中，可以直观理解为引入了额外的能量。</p><p>在之前的公式中<spanclass="math inline">\(b\)</span>是0，现在不再是0了。我们已知穿透深度:<span class="math display">\[d=(P_B-P_A) \cdot \overrightarrow n\]</span> 我们取<span class="math inline">\(b\)</span>为（<spanclass="math inline">\(d\)</span>是负值，因此前面取负号）: <spanclass="math display">\[b=-\frac {\beta} {\Delta t} \cdot d\]</span></p><p><span class="math inline">\(\beta\)</span>取<spanclass="math inline">\([0,1]\)</span>（一般接近0），这个值没有正确答案。一个经验做法是，从0开始增加直到你的物理系统变得不稳定，然后取一半的值作为<spanclass="math inline">\(\beta\)</span>。</p><h3 id="restitution">Restitution</h3><p>仅仅把刚体分开是不够的，碰撞往往伴随着弹性形变，因此有一个反弹的力还需要模拟，我们还要继续加一个bias到<spanclass="math inline">\(b\)</span>中。</p><p>刚体发生正碰撞时，碰撞前后的速度大小之比几乎是不变的，等于一个常数，它表示物体在碰撞前后速度的恢复程度和物体变形的恢复程度，也反映了碰撞中机械能损失的程度。</p><p>我们称为<code>restitution</code>系数，记为<spanclass="math inline">\(C_R\)</span>，它被定义为两个刚体碰撞后分离的速度和两个刚体碰撞前接近速度的比率，一般取<spanclass="math inline">\([0, 1]\)</span>。<spanclass="math inline">\(C_R\)</span>越小，动能损失越大；反之，动能损失越小。</p><p><code>restitution</code>对bias的贡献，就是将它乘以两个碰撞点的（相对）接近速度在法线的投影，注意这个投影也是负值，因此取负。<span class="math display">\[-C_R(-\overrightarrow V_A-\overrightarrow \omega_A \times\overrightarrow r_A + \overrightarrow V_B+\overrightarrow \omega_B\times \overrightarrow r_B) \cdot \overrightarrow n\]</span></p><p>所以，最终的<spanclass="math inline">\(b\)</span>项包含了<code>Baumgarte Term</code>和<code>Restitution Term</code>。<span class="math display">\[b=-\frac {\beta} {\Delta t} \cdot d - C_R(-\overrightarrowV_A-\overrightarrow \omega_A \times \overrightarrow r_A +\overrightarrow V_B+\overrightarrow \omega_B \times \overrightarrow r_B)\cdot \overrightarrow n\]</span></p><h3 id="摩擦">摩擦</h3><p>目前为止，我们只处理了法线方向上的碰撞部分，现在来处理切线部分。摩擦力和法线压力成比例，因此它们取决于法线部分的处理结果。</p><p>法线部分的碰撞约束倾向于让相对速度在法线方向的投影为0（不考虑<spanclass="math inline">\(b\)</span>项）。切线部分与此类似：它尝试让相对速度在（由两个切线构造的）切平面上的投影为0。</p><p>切线部分和法线部分基本处理流程是一样的，只是投影的目标不同。因此，毫不奇怪，两条切线的雅可比矩阵看起来与法线的雅可比矩阵非常相似。让我们加入下标来区分这些雅克比矩阵。<span class="math display">\[\begin{align}J_{\overrightarrow n}=&amp;\begin{bmatrix} -\overrightarrow n^T &amp;(-\overrightarrow r_A \times \overrightarrow n)^T &amp; \overrightarrown^T &amp; (\overrightarrow r_B \times \overrightarrow n)^T\end{bmatrix}\\J_{\overrightarrow t_1}=&amp;\begin{bmatrix} -\overrightarrow t_1^T&amp; (-\overrightarrow r_A \times \overrightarrow t_1)^T &amp;\overrightarrow t_1^T &amp; (\overrightarrow r_B \times \overrightarrowt_1)^T \end{bmatrix} \\J_{\overrightarrow t_2}=&amp;\begin{bmatrix} -\overrightarrow t_2^T&amp; (-\overrightarrow r_A \times \overrightarrow t_2)^T &amp;\overrightarrow t_2^T &amp; (\overrightarrow r_B \times \overrightarrowt_2)^T \end{bmatrix}\end{align}\]</span></p><p>同样类似的还有，拉格朗日乘子的截取，但是不同之处在于，这次我们不再简单截取到<spanclass="math inline">\([0,+\infty]\)</span>，而是取决于法线累积冲量（记为<spanclass="math inline">\(\lambda_{\overrightarrown_{sum}}\)</span>），整个过程类似于<spanclass="math inline">\(\lambda\)</span>的截取。</p><h3 id="penetration-slop">Penetration Slop</h3><p>为了让碰撞更稳定，我们要引入slop，让约束对碰撞更宽容。</p><p><code>Baumgarte Stabilization</code>引入额外的能量让两个碰撞的物体分离，如果没有slop，两个物体如果只有一点碰撞穿透，这些额外的冲量也会立即作用上去，这很可能会导致抖动，结果就是物体应该静止时却很难保持不动。</p><p>这个情况可以通过容许物体穿透非常小的深度，而不实际应用<code>Baumgarte Stabilization</code>得到缓解。我们允许一个微小的穿透slop，记为<spanclass="math inline">\(Slop_P\)</span>，那么Baumgarte项变为： <spanclass="math display">\[\frac \beta {\Delta t} \cdot max(-d-Slop_P,0)\]</span></p><p>如果穿透深度小于一定的值，那么不应用Baumgarte。</p><h3 id="restitution-slop">Restitution Slop</h3><p>同样的思想也可以应用到restitution上。考虑一个restitution为0.3的弹性球和地板的碰撞，如果没有额外的措施它将一直和地板弹跳下去，即使它的高度已经非常低了，这是因为当它撞击地板时，总是获得一个非零的冲量反弹回去。</p><p>有了<code>restitution slop</code>，我们可以在接近速度足够小时，不应用restitution，这和现实也是一致的（如果速度足够小，两个弹性球会碰在一起而不会弹开）。</p><p>我们知道b的restitution项是： <span class="math display">\[C_RV_C\]</span> 其中 <span class="math display">\[V_C=C_R(-\overrightarrow V_A-\overrightarrow \omega_A \times\overrightarrow r_A + \overrightarrow V_B+\overrightarrow \omega_B\times \overrightarrow r_B) \cdot \overrightarrow n\]</span> 加上<code>restitution slop</code>，记为<spanclass="math inline">\(Slop_R\)</span>，我们得到： <spanclass="math display">\[C_Rmax(-V_C-Slop_R,0)\]</span></p><p>如此一来，如果接近速度足够小，那么restitution项就是0。最终，b项变为：<span class="math display">\[b=\frac \beta {\Delta t} \cdot max(-d-Slop_P,0) + C_Rmax(-V_C-Slop_R,0)\]</span></p><h2 id="实现优化">实现优化</h2><h3 id="warm-starting">Warm starting</h3><p>为了加速计算，我们可以猜测一个合理<spanclass="math inline">\(\lambda\)</span>开始迭代，因为物理模拟有很高的时间和空间相关性，也称为高帧相关性（<code>Frame Coherence</code>），所以这个预估的值可以使用上一帧计算缓存的<spanclass="math inline">\(\lambda\)</span>，由于高帧相关性，它有很大概率能帮助迭代更快的到达收敛，这就是所谓的暖启动。为了避免过拟合，我们通常不直接使用缓存的值，而是使用它的一个比例值。</p><p>当然这么做也是有代价的，如果前后两帧发生突变，反而会使收敛过程变慢。</p><h3 id="island">Island</h3><p>在约束物理模拟中，我们可以观察到一些物体会影响其他物体的运动，而另一些物体则不会。</p><p><img src="/images/constraint-resolve/island.png" /></p><p>基于这个简单的观察，我们可以将这些物体分组成不同的<code>Island</code>，在<code>Island</code>内部这些物体通过约束力/冲动影响彼此的运动，但不会影响其他<code>Island</code>的物体的运动。这种分离使我们能够解决更小的约束组，为整个物理世界创造更小的系统而不是一个单一的大系统。这就消除了大量潜在的无用工作。</p><h3 id="sleeping">Sleeping</h3><p>当一个物体在模拟过程中停止运动时，它的位置在模拟的后续步骤中自然保持不变，直到某种外力使它再次运动。这使我们注意到另一个可能的优化：当<code>Island</code>中所有物体的线性和角速度保持在一个给定的公差以下的一小段时间后，我们可以停止模拟整个<code>Island</code>，这种状态被称为<code>Sleeping</code>。</p><p>如果<code>Island</code>外的一个物体与<code>Island</code>上的任何一个物体发生碰撞，这个<code>Island</code>就会“苏醒”，再次进入模拟状态。如果任何其他外力或冲量作用在它的任何一个物体上，它也会苏醒。</p><h1 id="参考">参考</h1><ol type="1"><li><ahref="https://box2d.org/files/ErinCatto_UnderstandingConstraints_GDC2014.pdf">UnderstandingConstraints</a></li><li><ahref="https://www.toptal.com/game/video-game-physics-part-iii-constrained-rigid-body-simulation">ConstrainedRigid Body Simulation</a></li><li><a href="http://allenchou.net/game-physics-series/">Game PhysicsSeries</a></li><li><ahref="https://ubm-twvideo01.s3.amazonaws.com/o1/vault/gdc09/slides/04-GDC09_Catto_Erin_Solver.pdf">Modelingand Solving Constraints</a></li><li><ahref="http://www.cs.cmu.edu/~baraff/sigcourse/index.html">PhysicallyBased Modeling: Principles and Practice</a></li><li><a href="https://dyn4j.org/2010/07/equality-constraints/">EqualityConstraints</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Physics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Math</tag>
      
      <tag>Algorithm</tag>
      
      <tag>Physics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>刚体物理引擎实现之刚体动力学</title>
    <link href="/2022/04/04/rigidbody-dynamics.html"/>
    <url>/2022/04/04/rigidbody-dynamics.html</url>
    
    <content type="html"><![CDATA[<h1 id="物理模拟">物理模拟</h1><p>为了模拟真实世界的物理碰撞反馈，我们需要一些基于牛顿运动定律的动力学知识，来模拟碰撞反馈。物理引擎执行模拟的流程如下：</p><p><img src="/images/rigidbody-dynamics/loop.png" /></p><p>假设时间是<span class="math inline">\(t\)</span>，刚体的位置是<spanclass="math inline">\(p\)</span>，朝向是<spanclass="math inline">\(o\)</span>，线速度是<spanclass="math inline">\(v\)</span>，角速度是<spanclass="math inline">\(\omega\)</span>，那么在每一帧的循环中，所谓模拟就是要计算刚体最新的位置和朝向：<span class="math display">\[\begin{align}p(t+\Delta t) =&amp; p(t) + v(t)\Delta t \\o(t+\Delta t) =&amp; o(t) + \omega (t)\Delta t\end{align}\]</span></p><p>我们总是可以把刚体运动分解为相对独立的两部分：随质心的平动和绕质心的转动，平动相对比较简单，下面我们重点讨论转动。</p><h1 id="质心">质心</h1><p>质心是物体质量分布的中点，刚体会围绕其质心旋转，质心的位置就是刚体的位置。假设刚体质量为<spanclass="math inline">\(M\)</span>，把它细分成无数个质点，每个质点的质量为<spanclass="math inline">\(m\)</span>，每个质点在内部的位置为<spanclass="math inline">\(r\)</span>，那么质心为： <spanclass="math display">\[\frac{\Sigma m_{i} \mathbf{r}_{i}}{M}\]</span> 写成积分的形式： <span class="math display">\[\frac{1}{M} \int_{V} \rho (\boldsymbol{r}) \boldsymbol{r} d V\]</span> 其中<spanclass="math inline">\(\rho\)</span>是每个点的密度函数。</p><h1 id="力和力矩">力和力矩</h1><p>对刚体施加一个力，会改变它的速度<spanclass="math inline">\(v\)</span>，可能也会改变它的角速度<spanclass="math inline">\(\omega\)</span>，分别对应平动和转动，转动对应的力称为力矩（或扭矩）。</p><p>如果力矩非零，那么角速度就会改变，力矩定义为从质心到作用点的矢量和力矢量的叉积：<span class="math display">\[\tau=r \times F\]</span> 在2D下，力矩退化成一个标量： <span class="math display">\[\tau = \left \| r \right \| \left \| F \right \| \sin \theta=r_x F_y -r_y F_x\]</span></p><h1 id="转动惯量">转动惯量</h1><p>刚体<strong>定轴转动</strong>中的转动惯量（<code>Moment of Inertia</code>），可以类比于刚体平动中的质量，是衡量刚体抵抗旋转运动的惯性的物理量，可以理解为质量的转动形式。它的定义如下：<span class="math display">\[I=\sum_i m_{i} r_{i}^{2}=\int_{V} \rho(r) r^{2} d V\]</span> 其中，<spanclass="math inline">\(r\)</span>是质点和转轴的垂直距离，它随旋转轴的不同而改变，但反过来说，如果选择轴固定，<spanclass="math inline">\(I\)</span>就是一个<ahref="https://en.wikipedia.org/wiki/List_of_moments_of_inertia">常量</a>。</p><p><span class="math inline">\(I\)</span>类似于平动中的质量<spanclass="math inline">\(m\)</span>，很多平动的公式都有对应的转动公式：</p><ul><li>动量<span class="math inline">\(P=mv\)</span>，角动量<spanclass="math inline">\(L=I\omega\)</span></li><li>冲量<span class="math inline">\(I=Ft=\Delta P\)</span>，角冲量<spanclass="math inline">\(H=\tau t=\Delta L\)</span></li><li>动能<span class="math inline">\(E=\frac 1 2 mv^2\)</span>，转动能<span class="math inline">\(E_K=\frac 1 2 I\omega^2\)</span></li><li>动量守恒：<span class="math inline">\(\sumP\)</span>不变，角动量守恒：<span class="math inline">\(\sumL\)</span>不变</li><li>设角加速度<span class="math inline">\(\beta=\frac {dw}{dt}\)</span>，则有<spanclass="math inline">\(\tau=I\beta\)</span>，再结合<spanclass="math inline">\(\tau=r \times F\)</span>，我们有<spanclass="math inline">\(r \times F = I\beta\)</span>，从而<spanclass="math inline">\(\beta = I^{-1}(r \timesF)=I^{-1}\tau\)</span>。</li></ul><p><strong>转动惯量的平行轴定理</strong>：如果一个质量为<spanclass="math inline">\(m\)</span>的物体，以某条经过质心的轴<spanclass="math inline">\(A\)</span>，其转动惯量为<spanclass="math inline">\(I_A\)</span>。那么在空间取另外一个与轴<spanclass="math inline">\(A\)</span>平行的轴<spanclass="math inline">\(B\)</span> ，<spanclass="math inline">\(AB\)</span>的距离为 <spanclass="math inline">\(d\)</span> ，则<spanclass="math inline">\(I_B=I_A+md^2\)</span> 。</p><p>定理的证明非常简单，我们用质点的形式定义<spanclass="math inline">\(I_B\)</span>，假设<spanclass="math inline">\(A\)</span>到<spanclass="math inline">\(B\)</span>的垂直矢量为<spanclass="math inline">\(D\)</span>，则有： <span class="math display">\[I_B=\sum_i m_{i} (r_{i}+D)^{2}=D^2\sum_i m_i+\sum_i m_i r_i^2 + 2D \cdot\sum_i m_i r_i\]</span> 注意到由于<spanclass="math inline">\(D\)</span>和质心轴垂直，因此最后一项为零，于是可得<spanclass="math inline">\(I_B=I_A+md^2\)</span>。这个定理可以用于在两个平行轴之间进行转动惯量的变换。</p><h1 id="惯性张量">惯性张量</h1><p>选择不同的旋转轴，转动惯量会有所不同。为了完整地描述物体相对于任意轴的转动惯量，我们通常使用一个称为惯性张量（<code>Inertia tensor</code>）的矩阵，它是描述刚体作<strong>定点转动</strong>时的转动惯性的一组惯性量。</p><p>选定任意一个点<spanclass="math inline">\(Q\)</span>，建立直角坐标系<spanclass="math inline">\(xyz\)</span>，物体的惯性张量表示为： <spanclass="math display">\[{I} =\begin{bmatrix} I_{xx}&amp;-I_{xy} &amp;-I_{xz}\\-I_{yx}&amp;I_{yy}&amp;-I_{yz}\\-I_{zx}&amp;-I_{zy}&amp;I_{zz}\end{bmatrix}\]</span> 这里，矩阵的对角元素<spanclass="math inline">\(I_{xx}\,\!、I_{yy}\,\!、I_{zz}\,\!\)</span>分别为对于x-轴、y-轴、z-轴的转动惯量。设定<spanclass="math inline">\((x,\ y,\ z)\,\!\)</span>为质点<spanclass="math inline">\(dm\,\!\)</span>对于点Q的相对位置，则这些转动惯量定义为：<span class="math display">\[\begin{align}I_{xx}\ {=\ \int \ (y^{2}+z^{2})\ dm}\\I_{yy}\ {=\ \int \ (x^{2}+z^{2})\ dm}\\I_{zz}\ {=\ \int \ (x^{2}+y^{2})\ dm}\end{align}\]</span> 矩阵的非对角元素，称为惯量积，定义为： <spanclass="math display">\[\begin{align}I_{xy}=I_{yx} {=}\ \int\ xy\ dm\\I_{xz}=I_{zx} {=}\ \int\ xz\ dm\\I_{yz}=I_{zy} {=}\ \int\ yz\ dm\end{align}\]</span> 从而角动量可以写成如下形式： <span class="math display">\[L=I\omega=\left[    \begin{matrix}    {I}_{xx} &amp; -{I}_{xy} &amp; -{I}_{xz}  \\    -{I}_{yx} &amp; {I}_{yy} &amp; -{I}_{yz}  \\    -{I}_{zx} &amp; -{I}_{zy} &amp; {I}_{zz}  \\    \end{matrix}\right]\left[    \begin{matrix}    {\omega }_{x}  \\    {\omega }_{y}  \\    {\omega }_{z}  \\    \end{matrix}\right]\]</span></p><h2 id="主转动惯量">主转动惯量</h2><p>惯性张量矩阵的特征值是主惯性矩，其对应的特征向量是惯性主轴的方向向量。因为惯性张量<spanclass="math inline">\(I\)</span>是个实值的三维对称矩阵，我们可以将其对角线化，让惯量积变为零，使惯性张量成为一个对角矩阵。所得到的三个特征值必是正实值，并且三个特征矢量必定互相正交。</p><p>设特征值为<spanclass="math inline">\(\lambda\)</span>，我们需要解析特征方程： <spanclass="math display">\[L=I\omega=\lambda\omega\]</span> 也就是以下行列式等于零的的三次方程： <spanclass="math display">\[\mathbf{I} =\begin{vmatrix}I_{xx} - \lambda &amp; I_{xy} &amp; I_{xz} \\I_{yx} &amp; I_{yy} - \lambda &amp; I_{yz} \\I_{zx} &amp; I_{zy} &amp; I_{zz} - \lambda\end{vmatrix}\,\!\]</span> 这方程的三个根<spanclass="math inline">\(\lambda_1\,\!、\lambda_2\,\!、\lambda_3\,\!\)</span>都是正实的特征值。将特征值代入方程<spanclass="math inline">\(I\omega=\lambda\omega\)</span>，再加上方向余弦方程：<span class="math display">\[\omega_x^2+\omega_y^2+\omega_z^2=1\,\!，\]</span> 我们可以求到特征矢量<span class="math inline">\(\hat{\boldsymbol {\omega_1}}、\hat {\boldsymbol {\omega_2}}、\hat{\boldsymbol{\omega_3}}\)</span>。这些特征矢量都是刚体的惯量主轴，而这些特征值则分别是刚体对于惯量主轴的主转动惯量。</p><p>假设x-轴、y-轴、z-轴分别为一个刚体的惯量主轴，这刚体的<strong>主转动惯量</strong>分别为<spanclass="math inline">\(I_{x}、I_{y}、I_{z}\)</span>，角速度是<spanclass="math inline">\(\omega\)</span>。那么，角动量为 <spanclass="math display">\[\mathbf{L}=(I_x\omega_x\;,\;I_y\omega_y\;,\;I_z\omega_z)\,\!。\]</span>其直观意义在于：对于给定的物体，惯性积的值与建立的坐标系的位置及方向有关，如果我们选择的坐标系合适，可使惯性积的值为零。当对于某一坐标轴的惯性积为零时，这种特定的坐标轴称为惯性主轴或主轴（<code>principal axes</code>），相应的质量惯性矩称为主惯性矩（<code>principal moments of inertia</code>）。显然，如果刚体本身具有某种几何对称性，那么它的主轴方向总是沿着它的对称轴的。但是即使是完全没有任何对称性的刚体也是存在惯性主轴的。</p><h2 id="坐标系变换">坐标系变换</h2><p>根据转动惯量的平行轴定理，假设刚体在质心<spanclass="math inline">\(G\)</span> 处的惯性张量为 <spanclass="math inline">\(I_G\)</span> ，相对<spanclass="math inline">\(G\)</span>点偏移为<spanclass="math inline">\(d\)</span>处的惯性张量为： <spanclass="math display">\[\begin{array}{l}I_{x x}=I_{G, x x}+m\left(d_{y}^{2}+d_{z}^{2}\right) \\I_{y y}=I_{G, y y}+m\left(d_{x}^{2}+d_{z}^{2}\right) \\I_{z z}=I_{G, z z}+m\left(d_{x}^{2}+d_{y}^{2}\right) \\I_{x y}=I_{y x}=I_{G, x y}-m d_{x} d_{y} \\I_{x z}=I_{z x}=I_{G, x z}-m d_{x} d_{z} \\I_{y z}=I_{z y}=I_{G, y z}-m d_{y} d_{z}\end{array}\]</span></p><p>另外再考虑从原坐标系进行旋转<spanclass="math inline">\(R\)</span>变到新坐标系的情况，新的惯性张量<spanclass="math inline">\(I\)</span>可以从旧惯性张量<spanclass="math inline">\(I_0\)</span>求出： <span class="math display">\[I=RI_0R\]</span></p><p>结合旋转和平移的变换方法，我们可以将惯性张量变换到任意的新坐标系下，而不用从头开始计算。</p><p>在实现上，我们会先计算刚体在本地坐标系下的惯性张量<spanclass="math inline">\(I_{local}\)</span>并保存起来，需要的时候再通过转换，求得世界坐标系下的惯性张量<spanclass="math inline">\(I_{world}\)</span>，在加上力矩<spanclass="math inline">\(\tau\)</span>，我们可以求得物体的角速度<spanclass="math inline">\(\omega\)</span>。 <span class="math display">\[\begin{align}d\omega &amp;= \beta = I^{-1}\tau dt\\w(t_{i+1}) &amp;= \omega(t_i) + d\omega = \omega(t_i) + (I^{-1}\tau) dt\end{align}\]</span> 有了角速度，我们就可以更新物体的旋转。</p><h1 id="参考">参考</h1><ol type="1"><li><ahref="https://www.toptal.com/game/video-game-physics-part-i-an-introduction-to-rigid-body-dynamics">AnIntroduction to Rigid Body Dynamics</a></li><li><ahref="http://allenchou.net/2013/12/game-physics-motion-dynamics-fundamentals/">MotionDynamics Fundamentals</a></li><li><ahref="http://www.cs.cmu.edu/~baraff/sigcourse/index.html">PhysicallyBased Modeling: Principles and Practice</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Physics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Math</tag>
      
      <tag>Algorithm</tag>
      
      <tag>Physics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>刚体物理引擎实现之碰撞检测</title>
    <link href="/2022/04/03/collision-detection.html"/>
    <url>/2022/04/03/collision-detection.html</url>
    
    <content type="html"><![CDATA[<h1 id="gjk">GJK</h1><p>GJK（<code>Gilbert-Johnson-Keerthi</code>）是一个简洁优雅的算法，用来判断两个凸几何体之间是否发生碰撞，现代物理引擎基本都采用了这个算法作为碰撞检测的基石。在深入之前，我们需要先了解几个前置概念。</p><h2 id="support-function">Support Function</h2><p>Support函数<span class="math inline">\(S_A(d)\)</span>返回形状<spanclass="math inline">\(A\)</span>在给定方向<spanclass="math inline">\(d\)</span>的最远点，返回的这个点称为<code>Support Point</code>。</p><figure><img src="/images/collision-detection/support-function.png"alt="Support Point" /><figcaption aria-hidden="true">Support Point</figcaption></figure><p>对于规则几何体，如胶囊体、球体、长方体等，<code>Support Function</code>有一个解析解。对于不规则多面体/多边形，很容易通过遍历顶点获取到<code>Support Point</code>（可以使用半边（<ahref="https://en.wikipedia.org/wiki/Doubly_connected_edge_list">HalfEdge</a>）数据结构加速这一过程）。</p><p>对于一个仿射变换<spanclass="math inline">\(T(x)=R(x)+c\)</span>，<spanclass="math inline">\(c\)</span>是位移，<spanclass="math inline">\(R\)</span>是旋转，它的Support函数是:</p><p><span class="math display">\[S_{T(A)}(d) = T(S_A(R^Td))\]</span></p><p>即，先对<spanclass="math inline">\(d\)</span>做逆旋转，接着正常求最远点，最后再做仿射变换。</p><h2 id="minkowski-sum">Minkowski Sum</h2><p>几何体<span class="math inline">\(A\)</span>和<spanclass="math inline">\(B\)</span>的闵可夫斯基和（<code>Minkowski Sum</code>）定义如下：<span class="math display">\[A \oplus B = \{ P_A + P_B | P_A \in A,P_B \in B \}\]</span></p><figure><img src="/images/collision-detection/minkowski-sum.png"alt="可理解为两个几何体的并集" /><figcaption aria-hidden="true">可理解为两个几何体的并集</figcaption></figure><p><span class="math inline">\(A\)</span>和<spanclass="math inline">\(B\)</span>的闵可夫斯基差（<code>Minkowski Difference</code>）定义如下：<span class="math display">\[\begin{align}A \ominus B &amp;= \{ P_A - P_B | P_A \in A,P_B \in B \}\\A \ominus B &amp;= A \oplus {-B}\end{align}\]</span></p><figure><img src="/images/collision-detection/minkowski-diff.png"alt="可理解为先对一个几何体取反得到一个镜像，然后再取并集" /><figcaptionaria-hidden="true">可理解为先对一个几何体取反得到一个镜像，然后再取并集</figcaption></figure><p>闵可夫斯基差有一些重要的性质：</p><ol type="1"><li>如果两个几何体重叠或者相交，它们的<code>Minkowski Difference</code>肯定包含原点（因为两个物体必然包含同一个点，而这两个点的差是0）。</li><li>如果A和B是凸多面体，那么他们的<code>Minkowski Sum/Difference</code>也是凸多面体。</li><li>在给定方向<spanclass="math inline">\(d\)</span>时，闵可夫斯基差的<code>Support Function</code>和原几何体各自的<code>Support Function</code>有如下关系：</li></ol><p><span class="math display">\[S_{A \ominus B}(d) = S_A(d) - S_B(-d)\]</span></p><h3 id="距离">距离</h3><p>有了闵可夫斯基差的概念，我们可以重新定义<spanclass="math inline">\(A\)</span>和<spanclass="math inline">\(B\)</span>的最近距离如下：</p><p><span class="math display">\[Distance(A, B) = min \{ || P_A - P_B ||:P_A \in A, P_B \in B \}\]</span></p><p>即，闵可夫斯基差和原点的最近距离，等价于<spanclass="math inline">\(A\)</span>和<spanclass="math inline">\(B\)</span>的最近距离。</p><p>如果<span class="math inline">\(A\)</span>和<spanclass="math inline">\(B\)</span>碰撞，即<spanclass="math inline">\(A\)</span>和<spanclass="math inline">\(B\)</span>相交，那么<spanclass="math inline">\(A\)</span>和<spanclass="math inline">\(B\)</span>的最近距离就是0，于是它们的<strong>闵可夫斯基差就包含原点</strong>。</p><h2 id="simplex">Simplex</h2><p>k阶单纯形（<code>k-Simplex</code>），指的是k维空间中的多胞形，且多胞形是k+1个顶点组成的凸包。</p><figure><img src="/images/collision-detection/simplex.png" alt="simplex" /><figcaption aria-hidden="true">simplex</figcaption></figure><p>例如，<code>0-Simplex</code>就是点，<code>1-Simplex</code>就是线段，<code>2-Simplex</code>就是三角形，<code>3-Simplex</code>就是四面体。简单理解就是，k阶单纯形是k维空间下“最简单”的凸包。</p><p>为了判断两个形状是否碰撞，我们并不需要完整计算出<code>Minkowski Difference</code>的形状，只要我们能在<code>Minkowski Difference</code>的内部找出一个包含原点的单纯形即可。</p><h2 id="gjk算法">GJK算法</h2><p>GJK算法本质就是利用<code>Minkowski Difference</code>来判断两个几何体有没碰撞。也就是上面提到的性质1：如果两个几何体重叠或者相交，它们的<code>Minkowski Difference</code>差肯定包含原点。</p><p>GJK算法迭代搜索与原点最接近的<code>Minkowski Difference</code>上的点，它通过<code>Support Point</code>构建一系列在每次迭代中更接近原点的单纯形来实现：</p><ol type="1"><li>我们可以在<code>Minkowski Difference</code>形成的几何体内迭代的形成一个多面体(或多边形），并使这个多面体包围原点（如果有原点的话）。如果这个多面体包含原点，那么<code>Minkowski Difference</code>形成的多面体也必然包括原点，这个多面体最多就是k阶的单纯形。</li><li>在某个方向上选择最远的点（<code>Support Point</code>）有重要作用，因为这样产生的单纯形包含最大的空间区域，更有可能把原点包含进来，增加了算法快速返回的可能。</li><li>如果我们不能通过一个过原点的方向在单纯形上增加一个点，则<code>Minkowski Difference</code>不过原点，这样在物体不相交的情况下，算法会很快退出。</li></ol><p>要理解整个算法，必须牢记以下两点：</p><ol type="1"><li><code>Minkowski Difference</code>的形状包含原点。</li><li>以原点的视角出发，算法中的坐标位置和（从原点指向此处的）向量可以互换。</li></ol><p>算法的伪码如下： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">function GJK_intersection(shape p, shape q, vector D):<br>    vector  A = Support(p, D) - Support(q, -D)<br>    simplex s = &#123;A&#125;<br>    D = -A<br>    loop:<br>        A = Support(p, D) - Support(q, -D)<br>        <span class="hljs-keyword">if</span> dot(A, D) &lt; <span class="hljs-number">0</span>:<br>          reject<br>        s = s ∪ A<br>        s, D, contains_origin = NearestSimplex(s)<br>        <span class="hljs-keyword">if</span> contains_origin:<br>          accept<br></code></pre></td></tr></table></figure></p><ol type="1"><li>随机选取一个初始方向D，求出<code>Minkowski Difference</code>的<code>Supporting Point</code><spanclass="math inline">\(A\)</span>。</li><li>把<spanclass="math inline">\(A\)</span>输入单纯形s，此时单纯形为<code>0-Simplex</code>。</li><li><span class="math inline">\(D\)</span>设置为<spanclass="math inline">\(-A\)</span>（从原点的视角来看，-A就是D的逆方向），进入循环:<ol type="1"><li>计算<code>Minkowski Difference</code>在D方向的<code>Supporting Point</code>，得到新的<spanclass="math inline">\(A\)</span>。</li><li>判断<span class="math inline">\(A\)</span>和<spanclass="math inline">\(D\)</span>的点积是否小于0，实际上就是判断<spanclass="math inline">\(A\)</span>在<spanclass="math inline">\(D\)</span>方向的投影是不是小于0。<strong>换句话说，<spanclass="math inline">\(A\)</span>已经是<code>Minkowski Difference</code>在<span class="math inline">\(D\)</span>方向最远的点了，原点必须在<spanclass="math inline">\(A\)</span>点的<spanclass="math inline">\(-D\)</span>方向才能保证原点在<code>Minkowski Difference</code>之内，也因此<span class="math inline">\(A\)</span>在<spanclass="math inline">\(D\)</span>的投影必须&gt;=0</strong>。否则，直接返回false。</li><li>让<span class="math inline">\(A\)</span>参与组成新的单纯形。</li><li>通过函数NearestSimplex更新单纯形s，以及给出新的方向<spanclass="math inline">\(D\)</span>。<strong><spanclass="math inline">\(D\)</span>的选取规则是：在已有的simplex内（轮廓边上）找出离原点最近的点，从这个最近点指向原点的方向就是下一次迭代的<spanclass="math inline">\(D\)</span>。</strong>根据最近点，可能要舍弃多余的顶点，保证s还是<code>k- Simplex</code>，舍弃原则是<strong>尽量留下离原点最近的那些点</strong>。</li><li>判断原点是否在新构造的单纯形之内（2D下对应一个三角形，3D下对应一个四面体），如果是，则GJK返回true。</li></ol></li></ol><p>以2D的GJK算法为例，下图椭圆表示<code>Minkowski Difference</code>的形状，<code>+</code>表示原点，箭头表示方向<spanclass="math inline">\(D\)</span>。</p><p><img src="/images/collision-detection/gjk.png" /></p><ol type="1"><li>随机选取方向得到一个<code>Supporting Point</code>。</li><li>取反方向得到一个新的<code>Supporting Point</code>。</li><li>在两个<code>Supporting Point</code>组成的线段上，寻找离原点最近的点，这个点作为起点指向原点得到新的方向。根据新的方向得到一个新的<code>Supporting Point</code>，此时三个<code>Supporting Point</code>组成了一个<code>2-Simplex</code>（三角形）。</li><li>原点不在这个三角形内，但依然有可能在<code>Minkowski Difference</code>的其他地方。舍弃离原点最远的一个<code>Supporting Point</code>，更新（回退）simplex到<code>1-Simplex</code>（线段）。</li><li>在两个<code>Supporting Point</code>组成的线段上，寻找离原点最近的点，这个点作为起点指向原点得到新的方向。根据新的方向得到一个新的<code>Supporting Point</code>，此时三个<code>Supporting Point</code>组成了一个<code>2-Simplex</code>（三角形）。</li><li>原点在这个三角形内，碰撞检测结束，结果为true。</li></ol><h1 id="epa">EPA</h1><p>GJK解决了两个几何体是否碰撞的问题，但没有提供碰撞深度、碰撞法线等碰撞信息，只有获取到这些信息，我们才能正确的模拟物理碰撞反应。</p><p>扩张多面体算法（EPA：<code>Expanding Polytope Algorithm</code>）算法能让我们以GJK为基础继续获取这些必要的信息。EPA算法也使用单纯形、support函数的概念，和GJK不同是，EPA的单纯形可以有任意多个点。</p><p>穿透深度(<code>Penetration Depth</code>)是穿透向量（或者也叫最小位移向量)MTV(<code>Minimum Translation Vector</code>)的长度，MTV是沿着该向量进行位移使得两个几何体分离的最小的向量。</p><p><img src="/images/collision-detection/mtv.png" /></p><p><code>Minkowski Difference</code>的轮廓边上离原点最近的点到原点形成的向量就是MTV。EPA算法本质上就是基于GJK的单纯形结果，进行扩张而寻找这个点的算法。</p><h2 id="d">2D</h2><p>让我们先从2D的EPA算法入手。如下图，从第5步开始进入EPA算法阶段： <imgsrc="/images/collision-detection/epa.png" /></p><ol start="5" type="1"><li>从GJK的单纯形结果出发，找出离原点最近的一条边，然后计算这个边（指向单纯形外部）的法线方向的<code>Support Point</code><spanclass="math inline">\(A\)</span>。</li><li>以<spanclass="math inline">\(A\)</span>为顶点，把上一步用来确定方向的边用两个边替代，多边形因此而扩展。重复5的过程，找到新的<code>Support Point</code>B。</li><li>以B为顶点，再次用两个边替代一个边，继续扩展多边形。</li><li>重复上述过程，直到新的<code>Support Point</code>的朝向和长度基本不变（收敛），那么最后的<code>Support Point</code>就是MTV。</li></ol><h2 id="d-1">3D</h2><p>3D的情况要复杂一些，EPA将找出一个（由<code>Minkowski Difference</code>轮廓上的顶点构成的）三角形，原点在这个三角形上的投影就是MTV的足够好的近似（如果两个形状是有限的凸多面体，那么这个近似就是精确的）。</p><p>和2D的算法流程一样，整个3D的EPA算法也是一个搜寻并收敛的过程，最终目的是要找到<code>Minkowski Difference</code>的轮廓上的所有点中离原点最近的那个点<spanclass="math inline">\(P\)</span>，当然我们不能直接获得<spanclass="math inline">\(P\)</span>，我们会通过原点投影到最接近且尽可能小的覆盖<spanclass="math inline">\(P\)</span>的小三角形上来近似获得这个点：</p><ol type="1"><li>获取从GJK得到的单纯形，如果顶点数少于4个，那么把它扩张成四面体。</li><li>找出离原点最近的一个面。</li><li>如果最近的一个面的距离比之前找到的还要大，那么跳到7。</li><li>移除最近的这个面，使用面法线（朝向多面体外部）的方向寻找<code>Minkowski Difference</code>的<code>Support Point</code><spanclass="math inline">\(A\)</span>。</li><li>移除所有能被<spanclass="math inline">\(A\)</span>“看到”的面，添加新的面把“洞”补上，这些新的面会共享<spanclass="math inline">\(A\)</span>作为新的顶点（面能被A“看到”的意思是，<spanclass="math inline">\(A\)</span>在面的正半空间内）。</li><li>跳到2。</li><li>将原点投影到最近的三角形（这个三角形就是扩展的多面体上的一个面），这就是<code>Minkowski Difference</code>的轮廓上离原点最近的点。</li><li>计算这个投影点的重心坐标，（由<code>Support Point</code>的计算公式可知）这个重心坐标的系数对原来的两个碰撞体也是适用的。这将使我们知道碰撞点在每个碰撞体上的本地坐标，我们后续会将这个坐标转换到世界坐标。</li></ol><h2 id="contact-manifold">Contact Manifold</h2><p>通过碰撞点我们会获得一组碰撞数据，称为碰撞流形（<code>Contact Manifold</code>），一个典型的<code>Contact Manifold</code>包括：</p><ul><li>两个世界空间下的碰撞点，分别对应碰撞体穿透最深的点。</li><li>两个对象空间下的碰撞点，和世界空间下的碰撞点对应。这个信息对于维护持续碰撞(<code>Persistent Contacts</code>)很有用。</li><li>碰撞法线，使碰撞体分离的最小向量（MTV）。</li><li>两个互相垂直的碰撞切线，并且和法线也垂直，用来处理摩擦力。</li><li>穿透深度，标量值。</li></ul><h1 id="broad-phase">Broad-Phase</h1><p>如前所述，GJK和EPA算法都需要很多步骤和迭代，且迭代收敛的步数和几何体形状的复杂度高度相关，是相当耗时的算法，如果每帧都进行两两碰撞检测（<spanclass="math inline">\(O(n^2)\)</span>的复杂度），计算开销将不可接受。</p><p>考虑到很多物体相距较远，且相距较远的两个物体大概率是不会碰撞的，如果能用简单的算法将这部分物体提前剔除，只留下少部分真正有可能发生碰撞的物体做实际的碰撞检测，那么整个碰撞阶段的计算开销将得到极大的降低。于是，自然而然地引入了分阶段的碰撞检测：</p><ul><li>Broad-Phase使用某种空间数据结构（<code>Spatial Data Structure</code>）或者也称空间加速结构（<code>Spatial Acceleration Structure</code>），来快速筛选出可能产生碰撞的潜在物体列表。</li><li>Narrow-Phase对可能碰撞的物体执行真正（耗时）的碰撞检测算法，也就是GJK和EPA。</li></ul><h2 id="bvh">BVH</h2><p>常用的空间数据结构有quad-tree，octree，kd-tree，BSP（<code>Binary Space Partitioning</code>），BVH（<code>Bounding Volume Hierarchy</code>）等等，基本思想都是基于物体占据的空间将整个场景空间划分为递归的子空间，形成一种树状结构，使得理想情况下查询效率接近<spanclass="math inline">\(O(\log n)\)</span>。</p><figure><img src="/images/collision-detection/bvh.png"alt="使用包围球构造BVH" /><figcaption aria-hidden="true">使用包围球构造BVH</figcaption></figure><p>在游戏物理引擎中，物体会在运行时改变位置信息（包括插入、删除、位移旋转等），相对其他基于空间细分的数据结构，BVH是基于物体的划分，它对几何体的动态更新更为友好，因此游戏物理引擎更倾向于使用BVH，最常用的是BVH的一个变种，被称为<ahref="https://box2d.org/files/ErinCatto_DynamicBVH_GDC2019.pdf">DynamicAABB Tree</a>，顾名思义它有两个特点：</p><ol type="1"><li>使用轴对齐包围盒（AABB：<code>Axis-Aligned Bounding Box</code>）作为包围盒，AABB的特点是计算相交非常简单。</li><li>在运行时动态更新AABB节点，同时使用某种启发式算法尽量保持BVH树的平衡（保证各种操作的时间复杂度不至于劣化）。</li></ol><h2 id="fat-aabb">fat AABB</h2><p>一般来讲，游戏中物体的位置在每帧只会有一些微小的变化，这些小位移基本不会改变当前AABB树的结构，如果每次变化一点都要调整树的结构，显然会比较浪费性能，我们希望AABB树能有一些弹性：在微小位移发生时物体依然能被包含在原来的节点内，避免频繁调整树的结构。</p><p>针对上述问题，有一个非常简单的解决方案，称为<code>fat AABB</code>：即，让物体的AABB比它实际的AABB要稍微大（胖）一些。这样，即便物体有一些微小移动，<code>fat AABB</code>也能包含住它，树可以保持原样。</p><p>我们还能更进一步，在构造<code>fat AABB</code>的时候将物体移动的速度考虑进来，让<code>fat AABB</code>在位移方向变得更大一些，如果下一帧物体还是朝上一次的方向移动的话，那么<code>fat AABB</code>有更大的概率还能包住它。</p><h1 id="参考">参考</h1><ol type="1"><li><ahref="https://www.toptal.com/game/video-game-physics-part-i-an-introduction-to-rigid-body-dynamics">VideoGame Physics Tutorial</a></li><li><a href="http://allenchou.net/game-physics-series/">Game PhysicsSeries</a></li><li><a href="https://box2d.org/publications/">box2dpublications</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Physics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Math</tag>
      
      <tag>Algorithm</tag>
      
      <tag>Physics</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并发编程漫谈</title>
    <link href="/2022/03/19/concurrency.html"/>
    <url>/2022/03/19/concurrency.html</url>
    
    <content type="html"><![CDATA[<h1 id="基础知识">基础知识</h1><h2 id="处理器架构演进">处理器架构演进</h2><h3 id="cache">Cache</h3><p>现代处理器的时钟周期通常为0.5 ns，而访问主存的时间为50ns或更长。因此，访问内存是非常昂贵的，超过100个时钟周期。为了获得良好的处理器性能，必须减少从内存中获取指令和访问数据的平均时间，缓存就是为了这个目的而存在，缓存小而快并集成在CPU内部，通常只需几个时钟周期就可以访问数十或数百千字节的大小。</p><p>从<a href="https://gist.github.com/hellerbarde/2843375">LatencyNumbers Every Programmer ShouldKnow</a>可以看出现今各级存储的延迟数据：</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs lasso">L1 <span class="hljs-keyword">cache</span> reference <span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span>. <span class="hljs-number">0.5</span> ns<br>Branch mispredict <span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span>. <span class="hljs-number">5</span> ns<br>L2 <span class="hljs-keyword">cache</span> reference <span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span> <span class="hljs-number">7</span> ns<br>Mutex lock/unlock <span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span> <span class="hljs-number">25</span> ns<br>Main memory reference <span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span>. <span class="hljs-number">100</span> ns             <br>Compress <span class="hljs-number">1</span>K <span class="hljs-built_in">bytes</span> <span class="hljs-keyword">with</span> Zippy <span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span>. <span class="hljs-number">3</span>,<span class="hljs-number">000</span> ns  =   <span class="hljs-number">3</span> µs<br>Send <span class="hljs-number">2</span>K <span class="hljs-built_in">bytes</span> over <span class="hljs-number">1</span> Gbps network <span class="hljs-params">...</span><span class="hljs-params">...</span>. <span class="hljs-number">20</span>,<span class="hljs-number">000</span> ns  =  <span class="hljs-number">20</span> µs<br>SSD random read <span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span> <span class="hljs-number">150</span>,<span class="hljs-number">000</span> ns  = <span class="hljs-number">150</span> µs<br>Read <span class="hljs-number">1</span> MB sequentially from memory <span class="hljs-params">...</span>.. <span class="hljs-number">250</span>,<span class="hljs-number">000</span> ns  = <span class="hljs-number">250</span> µs<br>Round trip within same datacenter <span class="hljs-params">...</span><span class="hljs-params">...</span> <span class="hljs-number">500</span>,<span class="hljs-number">000</span> ns  = <span class="hljs-number">0.5</span> ms<br>Read <span class="hljs-number">1</span> MB sequentially from SSD* <span class="hljs-params">...</span>.. <span class="hljs-number">1</span>,<span class="hljs-number">000</span>,<span class="hljs-number">000</span> ns  =   <span class="hljs-number">1</span> ms<br>Disk seek <span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span><span class="hljs-params">...</span> <span class="hljs-number">10</span>,<span class="hljs-number">000</span>,<span class="hljs-number">000</span> ns  =  <span class="hljs-number">10</span> ms<br>Read <span class="hljs-number">1</span> MB sequentially from disk <span class="hljs-params">...</span>. <span class="hljs-number">20</span>,<span class="hljs-number">000</span>,<span class="hljs-number">000</span> ns  =  <span class="hljs-number">20</span> ms<br>Send packet CA-&gt;Netherlands-&gt;CA <span class="hljs-params">...</span>. <span class="hljs-number">150</span>,<span class="hljs-number">000</span>,<span class="hljs-number">000</span> ns  = <span class="hljs-number">150</span> ms<br></code></pre></td></tr></table></figure><p>如果L1Cache读取的延迟是0.5s的话，那么从主存读取的延迟是100s，SSD随机读取则要4.4小时。</p><p>现代CPU一般都是多级缓存，这是出于速度/容量/成本的综合考虑，x86体系最早在486引入了两级缓存，从PentiumPro开始，L2 Cache和CPU封装到了一起，接着AMD又引入了L3Cache。缓存对处理器性能有巨大的影响，没有缓存，让处理器时钟以千兆赫的频率运行毫无意义，很多时候处理器只是在等待内存访问完成。</p><h3 id="多核处理器">多核处理器</h3><p>在计算机发展的最初几十年里，基本只有单核处理器，随着摩尔定律，单核处理器的性能每两年就会翻一倍。然而最近十几年摩尔定律逐渐失效，单核处理器中晶体管数目增长放缓，性能遇到了瓶颈，硬件厂商转而通过封装多个核心来提升处理器的整体性能。</p><figure><img src="/images/concurrency/moores-law.png" alt="Moore&#39;s Law" /><figcaption aria-hidden="true">Moore's Law</figcaption></figure><p>到如今，软件开发者面对的多核CPU基本都是对称多处理器（SMP：SymmetricMulti-Processor），多个核心处于同等地位，根据内存访问的不同可以分为：</p><ol type="1"><li>一致存储器访问结构（UMA：Uniform MemoryAccess），访问共享的内存/资源，PC、手机等常见设备是这种架构，接下去的讨论也将围绕UMA架构。</li><li>非一致性内存访问（NUMA：Non-Uniform MemoryAccess），由多个CPU模块组成，每个CPU模块又有多个CPU，虽然理论上内存也是共享的，但是有本地内存和远程内存的区别，常见于大型服务器。</li></ol><h2 id="指令重排">指令重排</h2><p>为了更好地利用CPU，编译器和CPU都可能进行指令重排(<code>Instruction Reordering</code>)，这种底层优化行为在单核时代就存在了，但规则是：不管指令如何重排，都不能改变单线程程序的行为，因此这些优化对程序员来讲是透明的。</p><p>到了多核时代，情况稍有变化，虽然遵守的规则依然不变：不管指令如何重排，都不能改变单核上运行的单线程程序的行为。但在多个核上运行的多线程代码的正确性，却没有这样的保证，程序员需要在某些时候对底层的指令重排有所感知，否则将写不出正确的多线程程序。</p><h3 id="编译器重排">编译器重排</h3><p>编译器优化包括：公共子表达式删除（Common SubexpressionElimination）、寄存器分配（Register Allocation）、常量折叠（ConstantFolding）、指令调度（Instruction Scheduling）等等。</p><p>可以使用显式的编译器屏障（<code>compiler barrier</code>）阻止编译器重排，比如：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> A, B;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">foo</span><span class="hljs-params">()</span><br>&#123;<br>    A = B + <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">asm</span> <span class="hljs-title function_">volatile</span><span class="hljs-params">(<span class="hljs-string">&quot;&quot;</span> ::: <span class="hljs-string">&quot;memory&quot;</span>)</span>;<br>    B = <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure></p><p><code>asm volatile("" ::: "memory")</code>只是简单的告诉编译器不要对前后的指令乱序，实际不会生成额外的汇编指令。但是它有一个副作用：编译器将刷新所有寄存器的值到内存，然后（在asm语句之后）重新读取内存中的值，并将它们重新加载到寄存器中，有点类似对所有变量添加了<code>volatile</code>的效果。为了避免这个副作用，可以通过内联汇编命令的input和output操作符明确指定哪些内存操作不能乱序，比如：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c">WRITE(x)<br><span class="hljs-keyword">asm</span> <span class="hljs-title function_">volatile</span><span class="hljs-params">(<span class="hljs-string">&quot;&quot;</span>: <span class="hljs-string">&quot;=m&quot;</span>(y) : <span class="hljs-string">&quot;m&quot;</span>(x):)</span> <span class="hljs-comment">// memory fence</span><br><span class="hljs-title function_">READ</span><span class="hljs-params">(y)</span><br></code></pre></td></tr></table></figure><p>中间的内联汇编告诉编译器插入一条指令（其实是空的），它可能会读x的内存，会写y的内存，因此编译器不会把这两个操作乱序。这种明确的<code>memory fence</code>的好处是：使编译器尽量少的对其他不相关的变量造成影响，避免了额外开销。</p><p>除了显式的编译器屏障之外，还有隐式的编译器屏障。实际上，大多数的函数（非inline函数）不管它们自身是否包含<code>compiler barrier</code>，都可以充当<code>compiler barrier</code>。这是因为，编译器并不清楚函数的副作用，编译器必须要放弃那些对此函数可见的内存上的任何假设。</p><p>顺便说一下，GCC提供了<code>__attribute__((pure))</code>来显式指定一个函数是纯的（无副作用）：该函数除了返回一些值之外，不会产生其他作用和影响；并且它的返回值只依赖于它的输入参数和一些全局变量，比如：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> __attribute__((pure)) <span class="hljs-built_in">strlen</span>(<span class="hljs-type">char</span> *p) <br>&#123; <br><span class="hljs-comment">//…  </span><br>&#125;<br></code></pre></td></tr></table></figure>这类函数不会成为隐式的<code>compiler barrier</code>，编译器可以放开手脚进行优化。</p><h3 id="cpu重排">CPU重排</h3><p>对现代处理器来讲，为了提高流水线的运行效率，乱序执行(<code>Out-of-Order Execution)</code>是常见的优化手段：当前面的指令由于特种类型的功能单元不足、存储器延迟或操作数没有计算出来，必须停顿时，CPU可以发射后续的无关指令，从而乱序执行。这种做法有效的提高了CPU利用率，掩盖了各种停顿。</p><p>对单处理器单线程程序而言，这些优化尽管可能会改变不同内存地址的访问顺序（<code>Memory Ordering</code>），但它们对程序员是透明的，看起来程序仍然是在顺序执行。而到了多处理器时代，这些优化对多线程程序正确性的影响变得不能被忽视了，必须要有一个规范来让程序员在必要时能够控制内存访问顺序，否则只能禁用这些优化，后果将是严重损害性能。</p><p>为最大限度保留编译器和多处理器的优化能力，同时使多线程程序的执行结果是可预测的，系统需要程序员的帮助。最后就得到了一个折中方案，为了性能，硬件继续保留乱序优化的权利，但上层系统提供所谓内存一致性模型（<code>Memory Consistency Model</code>）的规范，程序员通过同步设施：内存屏障（<code>Memory Barrier</code>）和原子操作（<code>Atomic Operation</code>），来标记多个线程间的协作关系，使得系统的优化得以保留的同时，程序的正确性也不受影响。</p><p>内存一致性模型和缓存一致性（<code>Cache Coherence</code>）关注的都是内存和Cache相关的存取操作的正确性问题，理论上它们是各自独立的，实现上却有着千丝万缕的联系，让我们先从Cache一致性模型入手。</p><h1 id="cache一致性">Cache一致性</h1><p>现代SMP的缓存一般分为三级，由每一个核心独享的L1、L2Cache，以及所有的核心共享L3 Cache组成：</p><figure><img src="/images/concurrency/cache.png" alt="Cache" /><figcaption aria-hidden="true">Cache</figcaption></figure><p>Cache以固定大小的线性block缓存数据，称为<code>Cache Line</code>，CPU对Cache操作都是以某个<code>Cache Line</code>为目标，主流的<code>Cache Line</code>大小是64Bytes。</p><p><code>Cache Line</code>中的数据是内存对应数据的一个拷贝，Cache一致性就是要保证一条条<code>Cache Line</code>和内存之间的数据一致性。对于当今的SMP，每个Core有自己私有的Cache，因此它还包括各个Core的Cache之间的一致性。不管怎样，Cache对程序是透明的，其最终结果就是，把内存+Cache看成一个抽象的共享内存，同一时刻，各Core在这个共享内存看到的数据都是一致的。从共享内存读取称为Load，将数据写入到共享内存称为Store。</p><figure><img src="/images/concurrency/shared-memory.png" alt="shared memory" /><figcaption aria-hidden="true">shared memory</figcaption></figure><p>类似分布式系统中的数据一致性问题，我们也需要一个协议来实现Cache一致性，区别在于CPU的硬件设计保证了不会有网络断开的意外，而消息的延迟间隔也基本确定，因此Cache一致性协议只要维护数据的状态即可，比Paxos/Raft协议要简单很多。</p><p>Cache一致性协议的通信机制一般来讲有两种：</p><ul><li><strong>Snooping</strong>采用广播的形式，当一个Core修改了<code>Cache Line</code>之后，将状态通过总线广播通知其他Core。各个Core收到通知后执行既定的动作以及修改<code>Cache Line</code>的状态。缺点是总线带宽压力比较大，核心数目不能太多。</li><li><strong>Directory-based</strong>一个独立的存储单元，把所有Core的<code>Cache Line</code>的信息都记录下来，可以点对点精准投递协议消息，避免了广播带来的带宽压力。最坏情况下（所有共享数据被所有核共享），和Snooping的总线带宽消耗一样。缺点是Directory本身的维护开销，以及每次都要查一下Directory，增大了延迟。</li></ul><p>UMA一般是Snooping机制，NUMA系统中则一般是Directory-Based（否则就要模拟一个CPU总线了）。</p><h2 id="mesi">MESI</h2><p>最简单的Cache一致性协议是MESI协议。MESI分别是：<code>Modified</code>（已修改），<code>Exclusive</code>（独占），<code>Shared</code>（共享），<code>Invalid</code>（无效）的首字母，代表缓存的四种状态。</p><ul><li><strong>Modified</strong>处于该状态的<code>Cache Line</code>持有独占的一份数据，但是是脏的（已修改，和内存不一致），它将负责把数据写回内存或者传递给其他Core。</li><li><strong>Exclusive</strong>类似于Modified，也是独占的，但是数据是干净的（未修改，和内存一致），该状态下Core可以直接修改数据（转变为Modified）。</li><li><strong>Shared</strong>处于该状态表明数据被至少两个Core共享，并且是干净的，它可以随时变为Invalid状态。</li><li><strong>Invalid</strong> 该Cache Line无效，可以随时被替换。</li></ul><p>MESI的状态机表示如下（<ahref="https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm">这里</a>有一个可视化的演示）：</p><figure><img src="/images/concurrency/MESI.png" alt="MESI" /><figcaption aria-hidden="true">MESI</figcaption></figure><p>允许的状态组合有5种：</p><table><thead><tr class="header"><th></th><th><strong>M</strong></th><th><strong>E</strong></th><th><strong>S</strong></th><th><strong>I</strong></th></tr></thead><tbody><tr class="odd"><td><strong>M</strong></td><td></td><td></td><td></td><td>ok</td></tr><tr class="even"><td><strong>E</strong></td><td></td><td></td><td></td><td>ok</td></tr><tr class="odd"><td><strong>S</strong></td><td></td><td></td><td>ok</td><td>ok</td></tr><tr class="even"><td><strong>I</strong></td><td>ok</td><td>ok</td><td>ok</td><td>ok</td></tr></tbody></table><p>状态转换的规则有些复杂，从读写角度出发，大体可以归纳为以下两点：</p><ol type="1"><li>当要修改（Store）数据时，如果是独占的，则本地修改即可；反之，如果是Shared，则需要标记其他共享Cache为Invalid，等待InvalidAck之后才能进行修改；如果是Invalid，则要先Load最新的数据，同时也要修改其他共享Cache的状态为Invalid，然后再修改。</li><li>当读取数据（Load）时，如果是独占或Shared，则本地读即可；反之，如果是Invalid，则会触发CacheMiss，从其他Cache或者内存加载数据。</li></ol><p>和分布式协议一样，为了提高性能和吞吐量，我们总是希望协议的消息请求和回应（通信量）能尽量少一些，同时优化某些频繁执行的操作，降低各种操作的延迟。</p><p>对于Load，没有太多优化的余地，毕竟数据不能凭空捏造，只能老老实实地请求加载。对于Store，因为不论数据的最新副本在哪里，数据最终将以本地写的结果为准，这带来了优化的机会，Store有两个明显的延迟可以考虑优化掉：</p><ol type="1"><li>发出Invalid到收到Invalid Ack之间的延迟。</li><li>收到Invalid请求时，Cache可能正在执行其他操作（正在执行读写或者收到大量Invalid请求），不能马上给Cache做标记，导致响应InvalidAck不及时，从而产生延迟。</li></ol><figure><img src="/images/concurrency/write-stall.png" alt="write stall" /><figcaption aria-hidden="true">write stall</figcaption></figure><p>对于第一个延迟，硬件工程师引入了<code>Store Buffer</code>，对于第二个延迟，引入了<code>Invalidate Queue</code>。</p><h2 id="store-buffer">Store Buffer</h2><p>以上图为例，从CPU0的视角来看，不论<code>Invalidate Ack</code>何时到来，它总是会修改数据成它想要的结果。因此，可以不必等待InvalidAck回应，直接将结果写到一个本地写入队列（这就是所谓的<code>Store Buffer</code>），然后马上执行后续的指令。等待<code>Invalidate Ack</code>回应之后，再从<code>Store Buffer</code>刷新到Cache。本质上就是把一个同步阻塞（等待协议响应）操作，变成了一个异步非阻塞操作。</p><figure><img src="/images/concurrency/store-buffer.png" alt="Store Buffer" /><figcaption aria-hidden="true">Store Buffer</figcaption></figure><p>顾名思义，<code>Store Buffer</code>只缓存Store操作，其大小只有几十个字节。由于<code>Store Buffer</code>是Cache之外的一层结构，这意味着同样的数据多了一个存放的地方，而且这个地方不受MESI协议的约束，因此有可能破坏<code>Cache Coherence</code>。</p><p>首先，一个显而易见的问题是，<code>Store Buffer</code>既然存储了最新修改的数据，如果CPU依然从Cache读取数据，就有可能读到旧值。为此，CPU读取Cache时要先扫描一下<code>Store Buffer</code>，然后才是Cache，这就是所谓的<code>Store Forwarding</code>。</p><p>另外一个问题涉及到多CPU的执行顺序问题，要更复杂一些，不同的硬件设计会有不同的表现。我们先假设不是所有的Store操作都会进入<code>Store Buffer</code>，比如，如果要写入的<code>Cache Line</code>是独占状态，那么Store操作可以绕过<code>Store Buffer</code>直接写入<code>Cache Line</code>，在此基础上考虑如下代码：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> a = <span class="hljs-number">0</span>;<br><span class="hljs-type">int</span> b = <span class="hljs-number">0</span>;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">foo</span><span class="hljs-params">()</span><br>&#123;<br>  a = <span class="hljs-number">1</span>;   <br>  b = <span class="hljs-number">1</span>;  <br>&#125;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">bar</span><span class="hljs-params">()</span><br>&#123;   <br>  <span class="hljs-keyword">while</span> (b == <span class="hljs-number">0</span>) <span class="hljs-keyword">continue</span>;   <br>  assert(a == <span class="hljs-number">1</span>);  <br>&#125;<br></code></pre></td></tr></table></figure> 假设CPU0执行foo，CPU1执行bar，Cache状态如下：</p><table><thead><tr class="header"><th></th><th>a</th><th>b</th></tr></thead><tbody><tr class="odd"><td>CPU0</td><td>Shared</td><td>Modified</td></tr><tr class="even"><td>CPU1</td><td>Shared</td><td>Invalid</td></tr></tbody></table><p>可能出现如下的执行顺序：</p><ol type="1"><li>CPU1执行<code>while(b==0)</code>，由于CPU1的Cache没有b，发出Readb请求。</li><li>CPU0执行<code>a=1</code>，写入数据到<code>Store Buffer</code>（但Cache里仍是0），并发起”ReadInvalidate a“广播。</li><li>CPU0执行<code>b=1</code>，因为b是Modified，直接写入Cache。</li><li>CPU0收到CPU1的"Read b"请求，将Cache中的b返回给CPU1。</li><li>CPU1从CPU0的Cache读到<code>b==1</code>，于是进入下一条assert语句。</li><li>CPU1从本地的Cache读到<code>a==0</code>（因为CPU0的<code>Store Buffer</code>还未刷新到Cache），断言失败。</li><li>CPU1收到“Invalidate a”的广播（已经晚了）。</li></ol><p>在这个例子里，虽然CPU0按照<code>a=1; b=1</code>的顺序执行，但在CPU1的视角下<code>b=1</code>发生在<code>a=1</code>之前，这就是所谓的<code>StoreStore</code>乱序。</p><p>那么，假如所有的Store操作都必须放入<code>Store Buffer</code>会避免这个问题吗？答案是不一定，如果<code>Store Buffer</code>写入到Cache的顺序不是FIFO的，那么CPU1依然有可能会看到<code>StoreStore</code>乱序，反之如果保证FIFO，那么<code>StoreStore</code>乱序就不会发生。</p><h2 id="invalidate-queue">Invalidate Queue</h2><p>和Store类似，既然Cache都是要被Invalid的，那么早一点晚一点又有什么区别呢？因此CPU可以在没有真正Invalidate一个<code>Cache Line</code>之前先发送<code>Invalidate Ack</code>消息，只要将Invalidate的<code>Cache Line</code>信息暂存到<code>Invalidate Queue</code>。后续如果有对<code>Invalidate Queue</code>中涉及到的<code>Cache Line</code>操作，那就先将<code>Invalidate Queue</code>中的数据处理完毕即可，这不会影响Invalid操作的正确性。</p><figure><img src="/images/concurrency/invalidate-queue.png"alt="Invalidate-queue" /><figcaption aria-hidden="true">Invalidate-queue</figcaption></figure><p>然而，和<code>Store Buffer</code>一样，<code>Invalidate Queue</code>也是Cache之外的结构，因此也有可能破坏<code>Cache Coherence</code>，同样以上面的代码为例，可能出现如下的执行顺序：</p><ol type="1"><li>CPU0执行<code>a=1</code>，写入数据到<code>Store Buffer</code>（但Cache里仍是0），并发起”ReadInvalidate a“广播。</li><li>CPU0执行<code>b=1</code>，因为b是Modified，直接写入Cache。</li><li>CPU1收到“Invalidatea“消息，但并不马上标记Cache为Invalid，而是先把消息暂存到<code>Invalidate Queue</code>，并回应“InvalidateAck”。</li><li>CPU1执行<code>while(b==0)</code>，由于CPU1的Cache没有b，发出Readb请求。</li><li>CPU0收到“InvalidateAck”，刷新<code>Store Buffer</code>到Cache，<code>a=1</code>在Cache中生效。</li><li>CPU0收到CPU1的"Read b"请求，将Cache中的b返回给CPU1。</li><li>CPU1从CPU0的Cache读到<code>b==1</code>，于是进入下一条assert语句。</li><li>CPU1读取a的值，因为“Invalidatea“消息还在<code>Invalidate Queue</code>里面，CPU1本地的Cache还未被真正标记为Invalid（还是Shared），于是从本地Cache读到<code>a==0</code>，断言失败。</li></ol><p>和之前的例子一样，CPU1看到的依然是一个<code>StoreStore</code>乱序。</p><p>可以看到，由于<code>Store Buffer</code>和<code>Invalidate Queue</code>的加入，使得MESI协议提供的一致性保证有点类似“最终一致性”，也就是某个时刻之后（<code>Store Buffer</code>刷新Cache了或者<code>Invalidate Queue</code>被处理完毕了）Cache的数据是一致的，但这中间多个数据读写的顺序、以及它们被看到的顺序没有提供任何保证，这些问题都属于内存一致性模型（<code>Memory Consistency Model</code>）的问题。</p><h1 id="内存一致性模型">内存一致性模型</h1><p><code>Memory Consistency Model</code>或者<code>Memory Model</code>是系统和程序员之间的规范，它规定了在一个多线程程序中的内存访问应该表现出怎样的行为。这个规范影响了系统的性能，因为它决定了多处理器/编译器能应用哪些优化；也影响了可编程性(<code>Programmability</code>)，因为多线程程序的正确性取决于<code>Memory Model</code>，从而约束了程序员的编程方式。</p><p><code>Memory Model</code>的规范可以分为两层：</p><ul><li>硬件内存模型，由具体硬件规定和实现。</li><li>软件内存模型，由高级语言标准给出统一的抽象模型，程序员面对这个模型编程即可，硬件实现差异由编译器或标准库抹平。</li></ul><p>先澄清一些概念：</p><ol type="1"><li>显然单处理器单线程程序不需要考虑内存模型问题，虽然编译器/CPU都有可能加入乱序优化，但它们保证程序运行结果会和程序顺序（<code>Program Order</code>）一致。</li><li>从实现层面讲，因为相同地址的读写存在数据相关性（<code>Data Dependence</code>），所以系统实际上只能对不同地址的读写进行乱序。因此<code>Memory Consistency</code>关注的是多个地址，而非单个地址。</li></ol><p>内存一致性模型主要规定不同地址上的读写操作在其他处理器看来会否乱序，以及一个写操作是否同时被其他处理器观察到，它包括<code>Instruction Reordering</code>和<code>Store Atomicity</code>。</p><p><code>Memory Ordering</code>指的是一个CPU上针对不同地址的两个访存操作，在其他CPU看来是怎样的顺序。考虑到Load和Store，总共有4种常规的访存乱序组合，再加上一个依赖读取乱序：</p><ul><li>LoadLoad Order：不同地址上的读操作会否乱序</li><li>LoadStore Order：读操作和不同地址上的写操作会否乱序</li><li>StoreLoad Order：写操作和不同地址上的读操作会否乱序</li><li>StoreStore Order：不同地址上的写操作会否乱序</li><li>Dependent LoadsOrder：当第二条读操作的地址取决于前一条读操作的结果时，会否乱序。比如从内存中读取一个值，然后再用这个值进行一次读取，例如C++代码<code>ptr-&gt;field</code>（读取结构体指针ptr的field字段）。</li></ul><figure><img src="/images/concurrency/memory-ordering.png"alt="Memory Ordering" /><figcaption aria-hidden="true">Memory Ordering</figcaption></figure><p><code>Store Atomicity</code>是指，处理器的写操作是否同时被所有处理器看到。根据写操作的同时性，从弱到强排序：</p><ol type="1"><li>Load Other's Store Early &amp;&amp;Non-Causality：允许写操作被自己及个别其他处理器先看到，不支持Causality。写序列可能以不同顺序被多个处理器观察到。</li><li>Load Other's Store Early &amp;&amp;Causality：允许写操作被自己及个别其他处理器先看到，支持Causality。</li><li>Load Own StoreEarly：只允许写操作被自己先看到。写序列以相同顺序被多个处理器观察到。</li><li>Atomic Store：所有处理器同时看到写操作。</li></ol><p>这上面的每个属性按约束的强弱，又分为强一致性模型（<code>Strong Consistency Model</code>）和弱一致性模型（<code>Relaxed Consistency Model</code>），其中又有一些细分。</p><figure><img src="/images/concurrency/memory-model.png"alt="Memory Model Hardware" /><figcaption aria-hidden="true">Memory Model Hardware</figcaption></figure><h2 id="strong-consistency-model">Strong Consistency Model</h2><h3 id="sequential-consistency">Sequential Consistency</h3><p>顺序一致性是最简单的内存模型，也是约束最强的一种模型，最开始是1979年由Leslie Lamport在<ahref="http://research.microsoft.com/en-us/um/people/lamport/pubs/multi.pdf">Howto Make a Multiprocessor Computer That Correctly Executes MultiprocessPrograms</a>定义的，Lamport定义SC要满足两个要求：</p><div class="note note-info">            <ul><li>Requirement R1: Each processor issues memory requests in the orderspecified by its program.</li><li>Requirement R2: Memory requests from all processors issued to anindividual memory module are serviced from a single FIFO queue. Issuinga memory request consists of entering the request on this queue.</li></ul>          </div><p>简单来讲就是：</p><ol type="1"><li>每个处理器按照程序顺序（<code>Program Order</code>）发出内存请求。</li><li>每个处理器执行的交错顺序可以是任意的，但是所有处理器所看见的程序整体执行顺序都是一样的（整个程序的视角），也就是有一个全局的Order（<code>Global Total Order</code>）。</li></ol><p>它完全不允许任何乱序的存在，对应的属性是：</p><ul><li>LL/LS/SL/SS/DL乱序：不允许</li><li>Store Atomicity：Load Own Store Early</li></ul><p>实现上，可以抽象成多个处理器都按程序的指令顺序进行访存请求，而有一个Switch不停地随机选取下一个将要执行的处理器：</p><figure><img src="/images/concurrency/sequential-consistency.png"alt="Sequential Consistency" /><figcaption aria-hidden="true">Sequential Consistency</figcaption></figure><p>这种模式等价于访存操作被串行化了，一次只能运行一条指令，无法发挥多核并行的好处。更糟糕的是，我们必须等到每条指令完成后才能启动下一条指令ーー在当前指令的效果对其他每个处理器都可见之前，不能再运行任何指令。如今很难找到一个硬件体系结构支持顺序一致性，因为它会严重限制硬件对CPU执行效率的优化(对寄存器/Cache/流水线的使用)。</p><h3 id="total-store-order">Total Store Order</h3><p>在SC的基础上，放开<code>StoreLoad</code>乱序，就是TSO模型。允许<code>StoreLoad</code>乱序带来了Store优化的可能性，可以简单地把它抽象成带写缓冲区(就是<code>Store Buffer</code>)的多处理器架构。</p><figure><img src="/images/concurrency/total-store-order.png" alt="TSO" /><figcaption aria-hidden="true">TSO</figcaption></figure><p>所有处理器仍然连接到一个共享内存（Cache+内存的抽象），但是每个处理器都将对该内存的<code>Store</code>操作放入到本地写入队列。一个处理器上的内存读取在查询主内存之前会查询本地写队列（<code>Store Forwarding</code>），但它看不到其他处理器上的写队列。其效果就是当前处理器比其他处理器会先看到自己的写操作，<code>StoreLoad</code>乱序就发生在此刻：其他处理器从共享内存读到的值依然是旧的，直到写操作到达共享内存时，其他处理器上的读操作才能看到新值，因此在其他处理器看来就是Store跑到了Load之后。</p><p>特别注意所有的<code>Store</code>操作都必须先放入这个队列，并且后续以FIFO的顺序写入Cache，因为<code>StoreStore</code>约束还在，这要求Store和Store之间是有序的。在这种约束条件下，所有处理器看到的<code>Store</code>顺序是全局一致的，因此它被命名为总存储定序或简称TSO——和SC的<code>Global Total Order</code>相比，它只保证了Store操作有一个全局的顺序。</p><p>x86使用的正是一种TSO，但是有许多优化。然而在历史上，x86的设计并没有从一开始就显式地采用TSO，而是历经了不少波折。</p><div class="note note-info">            <p>在20世纪90年代，第一批x86多处理器可用的手册几乎没有提到硬件提供的内存模型。第一个结果是2007年8月出版的<ahref="http://www.cs.cmu.edu/~410-f10/doc/Intel_Reordering_318147.pdf">Intel64 Architecture Memory Ordering WhitePaper</a>，旨在为“软件作者提供对不同顺序的内存访问指令可能产生的结果的清晰理解”。同年晚些时候，AMD在<ahref="https://courses.cs.washington.edu/courses/cse351/12wi/supp-docs/AMD%20Vol%201.pdf">AMD64Architecture Programmer's Manual revision3.14</a>中发布了类似的描述。这些描述基于一个被称为“总锁序+因果一致性”(TLO+CC)的模型，故意弱于TSO。在公开访谈中，英特尔架构师表示，TLO+CC<ahref="http://web.archive.org/web/20080512021617/http://blogs.sun.com/dave/entry/java_memory_model_concerns_on">“像要求的那样强大，但并不足够强大。”</a>特别是，该模型保留了x86处理器在IRIWlitmustest中回答“是”的权利。不幸的是，内存屏障的定义不够强大，不足以重建顺序一致的内存语义，即使每个指令之后都有一个屏障。更糟糕的是，研究人员观察到实际的英特尔x86硬件违反了TLO+CC模型。</p><p>为了解决这些问题，欧文斯等人在<ahref="https://research.swtch.com/sparcv8.pdf">早期SPARCv8TSO模型</a>的基础上提出了<ahref="https://www.cl.cam.ac.uk/~pes20/weakmemory/x86tso-paper.tphols.pdf">x86-TSO模型提案</a>。当时，他们声称“据我们所知，x86-TSO是可靠的，足够强大，可以在上面编程，并且大致符合供应商的意图。“几个月后，英特尔和AMD发布了广泛采用这一模式的的新手册。</p><p>似乎所有英特尔处理器从一开始就实现了x86-TSO，尽管英特尔花了十年时间才决定致力于此。回想起来，很明显，英特尔和AMD的设计师们正在努力解决如何编写一个能够为未来处理器优化留出空间的内存模型，同时仍然为编译器作者和汇编语言程序设计者提供有用的保证。“有多强就有多强，但没有多强”是一个艰难的平衡动作。</p>          </div><p>由于<code>Store Forwarding</code>的存在，x86在单核上实际提供了<code>Sequential Consistency</code>的保证。另外值得一提的是，x86没有<code>Invalidate Queue</code>，因此避免了<code>Invalidate Queue</code>带来的<code>StoreStore</code>乱序。</p><h2 id="relaxed-consistency-model">Relaxed Consistency Model</h2><h3 id="partial-store-order">Partial Store Order</h3><p>在TSO的基础上，放开<code>StoreStore</code>乱序，这就是部分存储定序（PSO）模型。从实现上来讲，本质就是允许了<code>Non-FIFO</code>的<code>Store Buffer</code>的存在，这带来了另一个优化：多个Store操作可以合并或重叠执行。</p><h3 id="weak-with-data-dependency-ordering">Weak With Data DependencyOrdering</h3><p>在PSO的基础上，放开<code>LoadLoad</code>和<code>LoadStore</code>乱序，这就是ARM/PowerPC的内存模型。它允许常规的4种读写乱序，除了DL乱序。</p><p>对于Arm/PowerPC来说，它同样也有<code>Store Buffer</code>，但是并不保证FIFO的写入，另外它可能还会有<code>Invalidate Queue</code>，可见它为自己留的优化余地比x86要大很多（很大可能是为了低功耗）。在这种内存模型下编程，要处处小心，除了存在数据依赖，控制依赖以及地址依赖等的前后指令不能被乱序之外，其余指令间都有可能存在乱序。</p><h3 id="weak-memory-model">Weak Memory Model</h3><p>完全放开所有<code>Memory Ordering</code>的乱序，也包括DL乱序。</p><p>DECAlpha是唯一一款允许<code>Dependent Loads</code>乱序的多处理器，这使得它有几乎最Weak的<code>Memory Model</code>，而这又促成了<code>Linux Kernel</code>的Barrier设计(<code>Data Dependency Barrier</code>)以及C++标准的<code>memory model</code>设计(<code>std::memory_order_consume</code>)，因为后者的目标是尽可能兼容所有的硬件。</p><h1 id="memory-barrier">Memory Barrier</h1><p>如前所述，各个CPU架构定义的内存模型规范中也提供了专门的设施用于手动控制<code>Memory Ordering</code>，从而保证并发程序的正确，这就是所谓的内存屏障（<code>Memory Barrier</code>）。顾名思义，内存屏障隔开了前后两部分指令，使得前/后指令无法跨越屏障调换（但是前/后内部的指令还是可以调换的）。另外，<code>Memory Barrier</code>在约束CPU行为的同时，也约束了编译器的行为，可以理解为<code>Memory Barrier</code>里隐含了<code>Compiler Barrier</code>的语义。</p><p><img src="/images/concurrency/memory-barrier.png"alt="Memory Barrier" />大多数CPU架构将内存屏障分为了读屏障(<code>Read Memory Barrier</code>)和写屏障(<code>Write Memory Barrier</code>):</p><ul><li>读屏障: 任何读屏障前的读操作都会先于读屏障后的读操作完成</li><li>写屏障: 任何写屏障前的写操作都会先于写屏障后的写操作完成</li><li>全屏障: 同时包含读屏障和写屏障的作用</li></ul><p>实际的CPU架构中，出于优化的目的，可能提供多种内存屏障，比如分为四种:</p><ul><li>LoadLoad: 相当于前面说的读屏障</li><li>LoadStore: 任何该屏障前的读操作都会先于该屏障后的写操作完成</li><li>StoreLoad: 任何该屏障前的写操作都会先于该屏障后的读操作完成</li><li>StoreStore: 相当于前面说的写屏障</li></ul><p>实现上完全可以基于<code>Store Buffer</code>和<code>Invalidate Queue</code>来理解。比如：写屏障，等价于刷新本地<code>Store Buffer</code>保证屏障之前的Store指令对全局可见；读屏障，等价于清空本地的<code>Invalidate Queue</code>，保证之前的所有Load都已经生效。</p><p>以x86为例，为了防止<code>StoreLoad</code>乱序，x86提供了<code>mfence</code>（全屏障）指令，作用是：</p><ul><li>保证<code>mfence</code>前后的Store和Load指令的顺序，防止<code>StoreLoad</code>乱序。</li><li>保证了<code>mfence</code>之前的Store要先于之后的Store全局可见。</li></ul><p>理论上x86只存在<code>StoreLoad</code>乱序，<code>mfence</code>已经够用了，但它还提供了<code>sfence</code>和<code>lfence</code>:</p><ul><li>sfence（写屏障）保证<code>sfence</code>之前的Store要先于之后的Store对全局可见，防止Store重排序。</li><li>lfence（读屏障）保证<code>lfence</code>之前的Load要先于之后的Load对全局可见，防止Load重排序。</li></ul><p>这里的吊诡之处在于，<code>sfence</code>和<code>lfence</code>在多核的<code>Memory Consistency</code>中基本等价于NOP，这两个指令基本只影响单核下的程序行为。<code>sfence</code>等价于清空<code>Store Buffer</code>，而<code>lfence</code>它序列化的不止是Load，而是<strong>所有的指令</strong>。<code>lfence</code>之前所有的指令执行完了之后才会被执行，同时，在<code>lfence</code>完成之前其后所有的指令也不能执行(预取是可以的)。具体细节比较复杂，总之<code>sfence/lfence</code>各自有一些特殊用法，但基本和多核的<code>Memory Consistency</code>无关。</p><p>在x86里，除了显式的内存屏障指令，有些指令也会造成指令保序的效果，比如I/O操作的指令、exch等原子交换的指令，任何带有lock前缀的指令以及CPUID等指令都有内存屏障的作用，甚至有人发现，<code>lock addl</code>比<code>mfence</code>效率更高。</p><h1 id="软件内存模型">软件内存模型</h1><p>为了适应最广泛的硬件体系架构，软件的内存模型往往会基于一个<code>Relaxed Consistency</code>的处理器假设，通过编程语言和CPU提供的同步原语，保证多线程程序的执行结果和一个<code>Sequential Consistency</code>的程序一致。</p><h2 id="data-race-free">Data Race Free</h2><p>为了更好的理解软件内存模型，我们需要先了解一下DRF（<code>Data Race Free</code>）的概念，它是现在主流语言的内存模型的基础。它由SaritaAdve和Mark Hill在1990年的论文<ahref="https://ieeexplore.ieee.org/document/134502">Weak ordering-a newdefinition</a>提出，正如标题所言，她对之前的<code>Weak Ordering</code>进行了新的定义，他们把“弱有序”定义为如下：<div class="note note-info">            <p>Let a synchronization model be a set of constraints on memoryaccesses that specify how and when synchronization needs to be done.</p><p>同步模型是对内存访问的一组约束，这些约束指定了何时以及如何进行同步。</p>          </div></p><p>他们首次提出使用<code>Explicit Synchronization Primitives</code>来同步线程，它的保证是，如果程序是<code>Data Race Free</code>的，那么即便在一个<code>Weak Ordering</code>内存模型上运行，也能保证与SC等价。这意味着，程序员在写程序时，能够按SC模型来推断程序的正确性，而程序在底层运行时，也能够享受弱一致性模型带来的种种优化措施。</p><p>Adve和Hill提出了一种同步模型，他们称之为无数据竞争(Data-Race-Free，DRF)。<code>Data Race</code>的定义其实非常简单：<strong>两个对同一地址的非同步内存访问，其中至少有一个写入</strong>。而所谓<code>Data Race Free</code>，本质就是说凡是<code>Data Race</code>的变量，都必须用同步操作进行隔离，这种隔离为本来无序的多线程程序确定了顺序，包括：</p><ol type="1"><li>同步操作之间的顺序</li><li>同步操作之前的操作的顺序</li><li>同步操作之后的操作的顺序</li></ol><p>确定了这三种顺序，就能保证程序在弱一致性模型下和SC执行结果一样。另外，值得注意的是2和3的操作内部的顺序其实是不确定的，这正是DRF留给弱一致性模型的优化空间，因为它们内部的执行顺序并不重要（需要同步的地方都被你同步到了），所以不影响程序逻辑的正确性。简单来讲，DRF的精髓就在于：只保证必要的顺序，不保证没必要的顺序。</p><h2 id="c11内存模型">C++11内存模型</h2><p>C++11提供的就是“Sequential Consistency for data race freeprograms”内存模型，即没有数据竞争（<code>Data Race Free</code>）的程序符合顺序一致性。也就是说我们只要对多线程之间需要同步的变量和操作，使用正确的同步原语（基于<code>Atomic Type</code>）进行同步，就能保证程序的执行符合顺序一致性。反过来，如果<code>Data Race</code>发生在非<code>Atomic Type</code>上，它就不仅不提供SC保证，而且还变成了一个未定义行为。</p><p>在继续之前，我们还要了解一下如何描述程序操作（包括副作用）顺序的同步关系。首先是<code>synchronized-with</code>关系，简单理解就是，假设X是一个atomic变量，如果线程A写了变量X，线程B读了变量X，那么线程A、B间就建立起了<code>synchronized-with</code>关系。</p><p>然后是<code>happens-before</code>关系，操作A<code>happens-before</code>操作B的关系要成立，需要满足以下任一条件：</p><ol type="1"><li>A sequenced-before B（对单线程）</li><li>A inter-thread happens before B（对多线程）</li></ol><p>其中，<code>sequenced-before</code>就是单线程下的顺序操作的关系，而<code>inter-thread happens-before</code>指的是：如果一个线程中的操作A<code>synchronized-with</code>另一个线程中的操作B, 那么 A<code>inter-thread happens-before</code> B。</p><p><code>inter-thread happens-before</code> 关系具有传递性，将它与<code>sequenced-before</code> 关系结合，我们可以得到以下效果：如果A<code>sequenced-before</code> B，B<code>inter-thread happens-before</code> C，那么 A<code>inter-thread happens-before</code>C。这揭示了如果你在一个线程中对数据进行了一系列操作，那么你只需要一个<code>synchronized-with</code> 关系，即可使得数据对于另一个执行操作 C的线程可见。</p><p>用一句话总结就是：我们可以通过<code>synchronized-with</code>建立起多线程之间的<code>happens-before</code>关系。实现<code>synchronizes-with</code>的方式有很多，包括但不限于<code>mutex lock</code>,<code>thread create/join</code>、<code>Aquire and release Semantic</code>。</p><figure><img src="/images/concurrency/happens-before.png"alt="happens-before" /><figcaption aria-hidden="true">happens-before</figcaption></figure><p>C++以原子变量(<code>Atomic Variable</code>)或原子操作(<code>Atomic Operation</code>)的形式提供了建立<code>synchronized-with</code>关系的能力，从而允许程序同步其线程，C++提供了三种内存顺序模型：- Seqential Consistent Ordering（<code>memory_order_seq_cst</code>） -Relaxed Ordering（<code>memory_order_relaxed</code>)。 - Acquire-ReleaseOrdering（<code>memory_order_consume</code>，<code>memory_order_acquire</code>，<code>memory_order_release</code>，<code>memory_order_acq_rel</code>）</p><p><em>C++11还定义了原子栅栏作为原子变量的替代，但是并不太常用，也很容易用错。</em></p><h3 id="sequential-consistent-ordering">sequential consistentordering</h3><p>对应<code>memory_order_seq_cst</code>：</p><ul><li>如果对于一个原子变量的操作都是顺序一致的，那么多线程程序的行为就像是这些操作都以一种交叉顺序被单线程程序执行。</li><li>它意味着将程序看做是一个简单的序列，相对来说符合直觉，容易写出正确的程序，因此作为默认的内存序。代价是性能开销比较大。</li></ul><h3 id="relaxed-ordering">relaxed ordering</h3><p>对应<code>memory_order_relaxed</code>：</p><ul><li>在原子变量上采用 <code>relaxed ordering</code> 的操作不参与<code>synchronized-with</code> 关系。</li><li>在同一线程内对同一变量的操作仍保持<code>happens-before</code>关系，但这是单线程程序正确性的要求，与其他线程无关。</li><li>在 <code>relaxed ordering</code>中唯一的要求是在同一线程中，对同一原子变量的访问不可以被重排（对不同的原子变量的访问依然存在重排的可能性，只要它不改变单线程程序的正确性）。</li><li>没有附加同步的情况下，“对每个变量的修改次序”是唯一一件被多个线程共享的事。</li></ul><p>简单来讲，就是除了提供一个原子操作之外，完全不参与多线程同步。</p><h3 id="acquire-release-ordering">acquire-release ordering</h3><p>这是最常用的构建<code>syncrhonized-with</code>关系的内存顺序模型，对应<code>memory_order_release</code>，<code>memory_order_acquire</code>，<code>memory_order_acq_rel</code>：</p><ul><li>原子 load 操作是 acquire操作(<code>memory_order_acquire</code>)，原子 store 操作是release操作(<code>memory_order_release</code>)</li><li>原子<code>read_modify_write</code>操作(如<code>fetch_add()</code>,<code>exchange()</code>)可以是 acquire, release或两者皆是(<code>memory_order_acq_rel</code>)。</li></ul><p>同步是成对出现的，每一个 acquire 对应一个 release(跨线程的)。对一个原子变量M的 release 操作A <code>syncrhonized-with</code>一个对原子变量M进行 acquire的操作B，结果就是B能够看到A之前（包括A）的所有操作的副作用。</p><p><img src="/images/concurrency/syncrhonized-with.png" /></p><p>需要注意的是<code>syncrhonized-with</code>关系是在运行时建立起来的，它不是一个静态的关系，这意味着release有可能实际发生在acquire之后，此时两个线程就没有建立这种同步关系，因此我们必须推理相关操作之间所有可能发生的顺序，才能保证程序的正确性。</p><p><img src="/images/concurrency/not-syncrhonized-with.png" /></p><h3 id="memory_order_consume">memory_order_consume</h3><p><code>memory_order_consume</code> 是 <code>acquire-release</code>顺序模型中的一种，但它比较特殊，它引入了数据依赖关系（<code>data-dependent</code>）。简单来讲<code>acquire-release</code>对两个同步点前后的所有操作都生效，这个同步粒度有点太大了，在很多时候，线程间只想针对有依赖关系的操作进行同步，除此之外其他操作顺序如何无所谓。</p><blockquote><p>所谓数据依赖，在大多数情况下，它只是说，如果第一个计算的值用作第二个计算的操作数，那么一个计算将带有对另一个计算的依赖性（<code>carry-a-dependency</code>）。在源代码级别，依赖关系链是一系列表达式，它们的求值彼此之间都有一个依赖关系。</p></blockquote><p>这个优化利用了很多硬件的数据依赖性排序特性：数据依赖关系排序保证沿单个数据依赖链执行的所有内存访问将按顺序执行。Itanium、Intelx86、 x86-64、PA-RISC、SPARC和 zSeries都尊重指令级别的数据依赖关系排序，唯一已知的不保留数据依赖关系排序的弱序处理器是DEC Alpha。</p><p>当你使用 consume语义时，你基本上是在尝试让编译器利用这些处理器家族的数据依赖排序特性，也就是利用数据依赖关系排序来避免插入内存障碍的开销。除此以外，你还必须确保在源代码级别上的确存在数据依赖关系链。</p><p><img src="/images/concurrency/carry-a-dependency.png" /></p><p>虽然C++提供了<code>memory_order_consume</code>，但现实有点惨淡，因为编译器很难分析源代码的数据依赖关系，然后输出一个高效的能够免除内存屏障开销的机器指令序列，所以目前所有的编译器都只是把<code>memory_order_consume</code>当做<code>memory_order_acquire</code>来实现。</p><h1 id="解惑">解惑</h1><h2 id="volatile">volatile</h2><p>C/C++中的volatile常常被人错误使用，很多人错误地以为它和Java中的volatile一样，其实不然：</p><ol type="1"><li>它不提供任何的防止乱序的功能。</li><li>它不提供跨线程同步功能。</li><li>它甚至不保证是原子的。</li></ol><p>volatile修饰的变量只是表示该变量可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等。遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。当使用volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据。</p><p>简而言之，编译器优化的前提是编译器完全掌握变量读写的全息图景，但volatile告诉编译器：有些事你不了解，编译器的全息拼图少了一块，于是不敢轻举妄动。</p><p>按照这个<ahref="http://web.archive.org/web/20180120044239/http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2016.html">总结</a>，<code>volatile</code>只在三种场合下是合适的。</p><ul><li>和信号处理（<code>signal handler</code>）相关的场合；</li><li>和内存映射硬件（<code>memory mapped hardware</code>）相关的场合；</li><li>和非本地跳转（<code>setjmp</code> 和<code>longjmp</code>）相关的场合。</li></ul><h2 id="lock-free">lock-free</h2><p><code>lock-free</code>考察的是若干个线程组成的系统，能够确保执行它的所有线程中至少有一个能够继续往下执行（makeprogress），这样的系统或者算法实现就是<code>lock-free</code>的。实现上，使用基于原子操作（如RMW、CAS等）的同步方案解决资源争用的问题，而不使用mutex这种会造成显式阻塞的锁，因此所谓的无锁，本质上只是锁的粒度变小了。</p><p><code>wait-free</code>就更强一点，它是指任意线程的任何操作都可以在有限步之内结束，而不用关心其它线程。所有<code>wait-free</code>的算法都是<code>lock-free</code>的，理论上<code>wait-free</code>是性能最好的，很多算法理论上都可以是<code>wait-free</code>的，但实现难度也是最大的。</p><p>和<code>lock-free</code>相对的就是<code>lock-based</code>，这里的锁指的就是OS的mutex、semaphore等同步设施。当一个线程到达临界区时，可能另外一个线程已经持有访问该共享数据的锁，从而不能获取锁资源而阻塞（进入内核的一个等待队列），直到争用的锁被释放（再被内核唤醒），因此属于阻塞型同步（<code>Blocking Synchronization</code>）。</p><p>与之相对的，<code>lock-free</code>和<code>wait-free</code>属于非阻塞型同步（<code>Non-blocking Synchronization</code>）。如果使用了锁，那么OS可能把一个刚获得锁的线程切换出去，这时候所有依赖这个锁的线程都在等待，而没做有用的事，所以用了锁就不可能是<code>lock-free</code>，更不会是<code>wait-free</code>。</p><figure><img src="/images/concurrency/lock-free.png" alt="lock-free" /><figcaption aria-hidden="true">lock-free</figcaption></figure><p><code>lock-based</code>因为是阻塞式的锁，因此经常和性能低下联系到一起；而<code>lock-free</code>或<code>wait-free</code>的算法因为没用阻塞锁，经常和高性能联系到一起，但事实可能相反，因为：</p><ul><li><code>lock-free</code>和<code>wait-free</code>必须处理更多更复杂的<code>race condition</code>和<code>ABA problem</code>，完成相同目的的代码比用锁更复杂。代码越多，耗时就越长。</li><li>使用mutex的算法变相带后退（backoff）效果：出现竞争时尝试另一个途径以临时避免竞争，mutex出现竞争时会使调用者睡眠，使拿到锁的那个线程可以很快地独占完成一系列流程，总体吞吐可能反而高了。</li></ul><p>mutex导致低性能往往是因为使用不当，比如临界区过大（限制了并发度），或竞争过于激烈（上下文切换开销变得突出）。事实上，现在的mutex实现一般都很高效了，比如基于futex（<code>fast userspace mutex</code>）实现的mutex，在锁空闲时，直接就在用户态返回，即便锁被占用，也会在用户态尝试一段时间，最终才会陷入内核。如无特殊必要，直接用mutex一般来讲并不会拖慢整体执行速度。</p><p><code>lock-free</code>/<code>wait-free</code>算法的价值在于其保证了一个或所有线程始终在做有用的事，而不是绝对的高性能。但在一种情况下<code>lock-free</code>和<code>wait-free</code>算法的性能多半更高：那就是算法本身可以用少量原子指令实现。实现锁也是要用原子指令的，当算法本身用一两条指令就能完成的时候，相比额外用锁肯定是更快了。</p><h2 id="cache-1">cache</h2><h3 id="cache-line-ping-pong">cache-line-ping-pong</h3><p>当某个<code>Cache Line</code>在多个Core之间传递时（也就是快速地在Invalid和独占状态之间反复横跳），这种现象称为<code>cache-line-ping-pong</code>，它会带来性能的严重下降（极端情况下比单个线程执行时的性能更差）。</p><p>引发这个问题的原因在于有一个共享资源被多个Core频繁读写，比如：</p><ol type="1"><li>core1从内存中加载<code>Cache Line</code>进行操作。</li><li>core2也要对这个数据操作，于是它也加载了这个<code>Cache Line</code>，同时让core1的<code>Cache Line</code>失效。</li><li>core1又需要处理这个数据，于是重新从内存中加载这个<code>Cache Line</code>，并导致core2的<code>Cache Line</code>再次失效。</li><li>1-3一直反复下去。</li></ol><p>解决办法当然是能不共享资源就不共享资源，实在不行，尽量让资源的争用程度降低，比如减小临界区的大小，降低争用的频率，甚至拆分共享资源。</p><h3 id="false-sharing">false sharing</h3><p><code>cache-line-ping-ponging</code>有一个特例叫<code>false sharing</code>，指的是虽然看起来多线程之间没有共享资源，只是各自读写不同的数据，但因为这些数据被映射到相同的<code>Cache Line</code>，导致了事实上的<code>cache-line-ping-ponging</code>。</p><p>解决办法就是加padding，隔开一个<code>Cache Line</code>的大小，避免两个变量放入同一个<code>Cache Line</code>，比如：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> CACHE_LINE_SIZE 64</span><br><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">RingBuffer</span> &#123;<br><span class="hljs-comment">//...</span><br>std::atomic&lt;<span class="hljs-type">uint32_t</span>&gt; head_ = <span class="hljs-number">0</span>;<br><span class="hljs-type">uint8_t</span> padding_[CACHE_LINE_SIZE];<br>std::atomic&lt;<span class="hljs-type">uint32_t</span>&gt; tail_ = <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure></p><h3 id="locality">locality</h3><p>由于内存比处理器慢得多，缓存命中率对整体性能至关重要，为此CPU都自带缓存预取技术：每次加载数据到Cache时，总是尽量从当前位置开始多加载一些数据到Cache。理由是，数据访问是在时间和空间上聚集发生的，同一时间和同一位置前后的数据很可能具有比较大的关联性，或者说程序在短时间内只会频繁访问一些局部的数据，这就是所谓的局部性原理(locality)。</p><p>从这个原理出发，我们就知道哪些数据结构是缓存友好的，哪些是不友好的。显然最友好的是数组，就是一段连续内存；而链表、树、哈希表等，访问时内部有很多指针跳转，都对缓存不太友好。</p><p>游戏引擎中ECS架构的流行，很大程度就是因为它对Cache友好，同时有利于多线程并行，从而带来更高的运行性能。</p><h1 id="参考">参考</h1><p>特别推荐<ahref="https://preshing.com/">preshing</a>写的并发编程相关文章，写的深入浅出通俗易懂。</p><ol type="1"><li><ahref="https://assets.bitbashing.io/papers/concurrency-primer.pdf">Whatevery systems programmer should know about concurrency</a></li><li><ahref="https://preshing.com/20140709/the-purpose-of-memory_order_consume-in-cpp11/">ThePurpose of memory_order_consume in C++11</a></li><li><ahref="https://preshing.com/20120930/weak-vs-strong-memory-models/">Weakvs. Strong Memory Models</a></li><li><ahref="http://gavinchou.github.io/summary/c++/memory-ordering/">memoryordering</a></li><li><ahref="https://en.wikipedia.org/wiki/Symmetric_multiprocessing">Symmetricmultiprocessing</a></li><li><ahref="https://github.com/GHScan/TechNotes/blob/master/2017/Memory_Model.md">MemoryModel: 从多处理器到高级语言</a></li><li><a href="https://www.zhihu.com/question/24301047">如何理解 C++11的六种 memory order</a></li><li><ahref="https://book.douban.com/subject/3901836/">多处理器编程的艺术</a></li><li><a href="https://book.douban.com/subject/4130141/">C++ ConcurrencyIn Action</a></li><li><ahref="http://concurrencyfreaks.blogspot.com/2013/05/lock-free-and-wait-free-definition-and.html">Lock-Freeand Wait-Free, definition and examples</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Programming</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C/C++</tag>
      
      <tag>Concurrency</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>矩阵的主序</title>
    <link href="/2021/10/24/matrix-major-order.html"/>
    <url>/2021/10/24/matrix-major-order.html</url>
    
    <content type="html"><![CDATA[<p>有两个独立的概念涉及到行主序和列主序，分别是表示（标记）和存储：</p><ul><li>当拿起纸和笔做数学题的时候，头脑中浮现的矩阵有一个表示上的惯例。</li><li>当实现一个矩阵库的时候，存储的问题冒出来了。</li></ul><p>理解上的混乱都来自于这两个概念的混淆。</p><h1 id="存储">存储</h1><p>首先，不论何种情况，矩阵在计算机中总是以一维数组的形式存储，区别在于：</p><ul><li>行主序:按行优先存储，按照第1行、第2行、第n行的顺序，把元素存放在线性内存地址。</li><li>列主序:按列优先存储，按照第1列、第2列、第n列的顺序，把元素存放在线性内存地址。</li></ul><p><code>OpenGL</code>使用列主序。D3D的情况有些特别，<code>DirectXMath</code>使用行主序（CPU端），但<code>HLSL</code>默认使用列主序（GPU端）。</p><h1 id="表示约定">表示约定</h1><p>此处的主序和存储的主序毫无关联，只是表示形式的审美问题。</p><p>区分行主序和列主序的方法是，考察基向量如何书写，如果是垂直书写，那么是列主序，否则是行主序。假设基向量为<spanclass="math inline">\(i,j,k\)</span>，<spanclass="math inline">\(T\)</span>表示位移向量，则行主序矩阵表示为： <spanclass="math display">\[\begin{bmatrix}i_{x} &amp; i_{y} &amp; i_{z} &amp; 0 \\j_{x} &amp; j_{y} &amp; j_{z} &amp; 0 \\k_{x} &amp; k_{y} &amp; k_{z} &amp; 0 \\T_x &amp; T_y &amp; T_z &amp; 1\end{bmatrix}\]</span></p><p>列主序矩阵表示为： <span class="math display">\[\begin{bmatrix}i_{x} &amp; j_{x} &amp; k_{x} &amp; T_x \\i_{y} &amp; j_{y} &amp; k_{y} &amp; T_y \\i_{z} &amp; j_{z} &amp; k_{z} &amp; T_z \\0 &amp; 0 &amp; 0 &amp; 1\end{bmatrix}\]</span></p><p>另外，在接口设计风格上也隐含一种行/列优先的暗示：</p><ul><li>行优先:使用<code>M[row][col]</code>标记一个元素，即优先指定行，然后指定列。<code>DirectXMath</code>以及<code>HLSL</code>对矩阵采用行优先的标记方式，比如<code>float4x2</code>表示4行2列的矩阵。</li><li>列优先:使用<code>M[col][row]</code>标记一个元素，即优先指定列，然后指定行。<code>OpenGL</code>对矩阵采用列优先的标记方式，<code>mat4x2</code>是4列2行的矩阵。</li></ul><p>这也是混乱的来源之一。实际上，存储/表示/接口风格的主序都是独立的，以<code>Unity</code>为例，其矩阵内部是列主序，表示上也是列主序，但代码<code>M[row,colum]</code>却给人行优先的暗示。</p><p>理论上，不同的矩阵实现可以有不同的存储和表示主序，以及行/列优先的接口风格。作为用户，只要按照代码库的约定写代码即可，如有必要，底层实现会自动处理转置问题。除此以外，确实有一个需要我们关注的问题：乘法顺序。</p><h1 id="左乘和右乘">左乘和右乘</h1><p>让我们先考察矩阵乘法，对于<span class="math inline">\(A \timesB=C\)</span>，数学上的约定是：<spanclass="math inline">\(A\)</span>的行和<spanclass="math inline">\(B\)</span>的列进行点积得到<spanclass="math inline">\(C\)</span>的元素，<spanclass="math inline">\(A\)</span>的行数和<spanclass="math inline">\(B\)</span>的列数必须一致。这个约定和<spanclass="math inline">\(A\)</span>以及<spanclass="math inline">\(B\)</span>是什么存储主序毫无关系，但它确实影响了向量的约定，进而给矩阵带来了表示上的区别。</p><h2 id="行向量列向量">行向量&amp;列向量</h2><p>因为矩阵相乘不满足交换律，因此把n维向量<spanclass="math inline">\(v\)</span>看做一个<span class="math inline">\(1\times n\)</span>的矩阵（<code>行向量</code>）还是<spanclass="math inline">\(n \times1\)</span>的矩阵（<code>列向量</code>），会直接影响矩阵和向量相乘的方式和结果（虽然行/列存储主序下向量的内存布局是完全一样的）。一旦把向量规定为行向量或列向量，向量和矩阵乘法的形式就固定下来了，如你所料有两种形式：</p><ul><li><strong>预乘(pre-multiplication)或者左乘</strong>：<spanclass="math inline">\(vM\)</span>，把向量看做是行向量，此时向量在左，矩阵在右。<code>HLSL</code>采用预乘。</li><li><strong>后乘(post-multiplication)或者右乘</strong>：<spanclass="math inline">\(Mv\)</span>，把向量看做是列向量，此时矩阵在左，向量在右。<code>GLSL</code>采用后乘。</li></ul><p>数学教材一般采用后乘，此时向量被看做<span class="math inline">\(n\times 1\)</span>的矩阵，而矩阵<spanclass="math inline">\(M\)</span>就对应（表示上的）列主序矩阵，<spanclass="math inline">\(Mv\)</span>的结果还是一个列向量。而对于预乘，向量被看成<spanclass="math inline">\(1 \times n\)</span>的矩阵，<spanclass="math inline">\(vM\)</span>的结果还是一个行向量。不管怎样，都符合对向量做一个线性变换得到一个新向量的直观解释。</p><p><strong>常见的误解是：</strong></p><ol type="1"><li>因为<code>OpenGL</code>是列主序并使用列向量，而<code>DirectXMath</code>是行主序并使用行向量，所以存储顺序必须与解释向量的规定相匹配。事实完全不是这样，这是人为约定的结果。</li><li>矩阵和向量的乘法顺序取决于行主序还是列主序。乘法顺序和主序无关，不论采用什么主序，矩阵乘法总是以相同的方式相乘（行和列的点积），而矩阵和向量相乘的含义取决于你如何解释向量类型，而不是哪种存储主序。</li></ol><p>左乘和右乘从性能的角度考虑有一些微妙的地方，因为算术表达式按照从左到右顺序执行，预乘的性能要好一些。比如对向量做两次线性变换，预乘是：<spanclass="math inline">\(v \times A \times B=C\)</span>，向量<spanclass="math inline">\(v\)</span>和矩阵<spanclass="math inline">\(A\)</span>得到的中间结果是向量，合计2次向量和矩阵乘法；而后乘形式：<spanclass="math inline">\(B \times A \timesv=C\)</span>（此处不考虑结果的一致性），合计1次矩阵相乘+1次向量和矩阵乘法。不过这也不是什么大问题，用括号调整优先级可以避免这个劣势（为了结果正确，往往也是必须的）：<spanclass="math inline">\(B \times (A \times v)=C\)</span>。</p><p>虽然本质上两种乘法形式在效果上都是对向量进行一次线性变换，但我们知道矩阵交换律是不成立的，为了保证结果一致，我们必须对其中某一矩阵进行转置。</p><h2 id="转置">转置</h2><p>当转置和存储主序结合到一起的时候，有一个有趣的结论：<strong>转置矩阵</strong>改变主序之后的内存布局恰好和原矩阵的内存布局一致。换句话说，假设原矩阵为行主序存储，在以列主序存储解释的接口看来，它对应的内存布局恰好就是原矩阵的转置矩阵，中间不需要转置操作。</p><p>以一个<span class="math inline">\(2 \times 3\)</span>矩阵为例: <spanclass="math display">\[\begin{bmatrix}1 &amp; 0 &amp; -1\\2 &amp; -3 &amp; 1\\\end{bmatrix}\]</span>它在行主序存储下的内存表示为:<code>1 0 -1 2 -3 1</code>，它的转置矩阵为：<span class="math display">\[\begin{bmatrix}1 &amp; 2 &amp; \\0 &amp; -3 &amp; \\-1 &amp; 1 &amp; \\\end{bmatrix}\]</span>它在列主序下的内存表示是：<code>1 0 -1 2 -3 1</code>，恰好和原矩阵在行主序存储的结果一致。</p><p>这个结论和矩阵乘法联系到一起，又会得出一个有点违反直觉的结论。</p><p>假设<span class="math inline">\(A_r\)</span>和<spanclass="math inline">\(B_r\)</span>为行主序的矩阵，而<spanclass="math inline">\(A_c^T\)</span>和<spanclass="math inline">\(B_c^T\)</span>分别是列主序下<spanclass="math inline">\(A_r\)</span>和<spanclass="math inline">\(B_r\)</span>的转置。根据前面的结论，<spanclass="math inline">\(A_r\)</span>和<spanclass="math inline">\(A_c^T\)</span>，<spanclass="math inline">\(B_r\)</span>和<spanclass="math inline">\(B_c^T\)</span>的内存表示完全一致，更进一步，在行主序视角下的乘积<spanclass="math inline">\(A_r \timesB_r\)</span>，等价于列主序视角下的乘积<span class="math inline">\(B_c^T\timesA_c^T\)</span>（注意，为了满足矩阵乘法的合法性——行和列数量相等，后者的乘法顺序要对调一下）。</p><p>由此，我们可以得到一个结论：对于使用行主序存储的矩阵，可以不经转置直接传递到列主序存储的API中，同时保证矩阵乘法的正确性，反之亦然。前提是向量和矩阵的乘法形式，也符合不同主序表示下的惯例形式，即，列主序：<spanclass="math inline">\(矩阵 \times 列向量\)</span>，行主序：<spanclass="math inline">\(行向量 \times 矩阵\)</span>。</p><h1 id="通用矩阵库">通用矩阵库</h1><p>那么，进行同样的矩阵乘法运算，<code>D3D</code>和<code>OpenGL</code>之间传递矩阵数据时，是否要对矩阵进行一次转置呢？</p><p>答案是不用。前面说过，相同的内存表示，它们互为转置。这就是神奇的地方，虽然矩阵主序不一样，<strong>乘法的顺序不一样</strong>，但是在保证结果一致且正确的情况下，矩阵在内存的布局却是一样的。</p><p>这个特性的一个好处是，你可以写一个通用的矩阵类，同时适配<code>D3D</code>和<code>OpenGL</code>，只要你遵循列向量和后乘，或者行向量和预乘的规则，矩阵的内存表示是完全兼容两边的。</p><h1 id="d3d的惯例">D3D的惯例</h1><p><code>D3D11</code>官方示例代码中，为何传递矩阵到shader前会有一个转置的操作？</p><p>如前所说，<code>DirectXMath</code>使用行主序的存储（CPU端），但<code>HLSL</code>默认对存储使用列主序的解释（GPU端）。有两种方式弥合这种不一致：</p><ol type="1"><li><code>C++</code>代码端进行转置，<code>HLSL</code>中使用<code>matrix</code>(默认列主序矩阵)，<code>mul</code>函数的形式为：<span class="math inline">\(行向量\times矩阵\)</span>。这是官方例程所使用的方式，好处是矩阵的一列数据可以直接放到一个寄存器上，直接用dp4指令（省掉一个转置指令的开销）。</li><li><code>C++</code>代码端不进行转置，HLSL中使用<code>matrix</code>，<code>mul</code>函数的形式为：<spanclass="math inline">\(矩阵 \times列向量\)</span>。<code>OpenGL</code>就是这样的惯例，问题在于和很多遗留的<code>HLSL</code>代码不一致，不能和遗留代码配合。</li></ol><p>用代码表示实际发生的各种情况如下： <figure class="highlight glsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs glsl">mul(row float4, <span class="hljs-keyword">row_major</span> matrix) <span class="hljs-comment">//HLSL会自动转置矩阵然后取列向量到寄存器，有性能损失</span><br>mul(<span class="hljs-keyword">row_major</span> matrix, column float4) <span class="hljs-comment">//HLSL不需要自动转置，没有性能损失，但是注意结果和上面不一致</span><br><br>mul(row float4, matrix) <span class="hljs-comment">//HLSL不需要自动转置，但为了保证结果是正确的，C++需要转置，这是官方做法</span><br>mul(matrix, column float4) <span class="hljs-comment">//为了和上面结果一致，C++可以不转置</span><br></code></pre></td></tr></table></figure>另外，在<code>HLSL</code>中行主矩阵和列主矩阵的区别只影响从着色器输入中加载矩阵时的解释顺序。加载成<code>HLSL</code>矩阵变量后，矩阵顺序不会影响数据在着色器代码中的使用或访问方式。行主和列主的封装顺序对构造函数的封装顺序也没有影响(始终遵循行优先) 。</p><p>参考：</p><ol type="1"><li><ahref="https://www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/geometry/row-major-vs-column-major-vector">RowMajor vs Column Major Vector</a></li><li><ahref="https://fgiesen.wordpress.com/2012/02/12/row-major-vs-column-major-row-vectors-vs-column-vectors/">Rowmajor vs. column major, row vectors vs. column vectors</a></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Math</tag>
      
      <tag>Programming</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
